# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR The FreeBSD Project
# This file is distributed under the same license as the FreeBSD Documentation package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: FreeBSD Documentation VERSION\n"
"POT-Creation-Date: 2023-04-20 20:56-0300\n"
"PO-Revision-Date: 2021-06-12 18:24+0000\n"
"Last-Translator: Anonymous <noreply@weblate.org>\n"
"Language-Team: Chinese (Simplified) <https://translate-dev.freebsd.org/"
"projects/documentation/bookshandbookzfs_index/zh_CN/>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Weblate 4.6.2\n"

#. type: YAML Front Matter: description
#: documentation/content/en/books/handbook/zfs/_index.adoc:1
#, no-wrap
msgid "ZFS is an advanced file system designed to solve major problems found in previous storage subsystem software"
msgstr ""

#. type: YAML Front Matter: part
#: documentation/content/en/books/handbook/zfs/_index.adoc:1
#, no-wrap
msgid "Part III. System Administration"
msgstr ""

#. type: YAML Front Matter: title
#: documentation/content/en/books/handbook/zfs/_index.adoc:1
#, no-wrap
msgid "Chapter 21. The Z File System (ZFS)"
msgstr ""

#. type: Title =
#: documentation/content/en/books/handbook/zfs/_index.adoc:14
#, no-wrap
msgid "The Z File System (ZFS)"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:52
msgid ""
"ZFS is an advanced file system designed to solve major problems found in "
"previous storage subsystem software."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:54
msgid ""
"Originally developed at Sun(TM), ongoing open source ZFS development has "
"moved to the http://open-zfs.org[OpenZFS Project]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:56
msgid "ZFS has three major design goals:"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:58
msgid ""
"Data integrity: All data includes a <<zfs-term-checksum,checksum>> of the "
"data. ZFS calculates checksums and writes them along with the data. When "
"reading that data later, ZFS recalculates the checksums. If the checksums do "
"not match, meaning detecting one or more data errors, ZFS will attempt to "
"automatically correct errors when ditto-, mirror-, or parity-blocks are "
"available."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:59
#, fuzzy
#| msgid ""
#| "Pooled storage: physical storage devices are added to a pool, and storage "
#| "space is allocated from that shared pool. Space is available to all file "
#| "systems, and can be increased by adding new storage devices to the pool."
msgid ""
"Pooled storage: adding physical storage devices to a pool, and allocating "
"storage space from that shared pool. Space is available to all file systems "
"and volumes, and increases by adding new storage devices to the pool."
msgstr ""
"存储池：实体的储存设备都会先被加入到一个存储池（Pool），这个共用的存储池可用"
"来配置储存空间，存储池的空间可被所有的文件系统使用且通过加入新的储存设备来增"
"加空间。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:60
#, fuzzy
msgid ""
"Performance: caching mechanisms provide increased performance. <<zfs-term-"
"arc,ARC>> is an advanced memory-based read cache. ZFS provides a second "
"level disk-based read cache with <<zfs-term-l2arc,L2ARC>>, and a disk-based "
"synchronous write cache named <<zfs-term-zil,ZIL>>."
msgstr ""
"高性能：多级缓存机制提供更好的性能。<link linkend=\"zfs-term-arc\">ARC</"
"link> 是一种高级的基于内存的读取缓存。第二级基于磁盘的读取缓存可以与 <link "
"linkend=\"zfs-term-l2arc\">L2ARC</link> 一起添加，基于磁盘的同步写入缓存可用"
"于 <link linkend=\"zfs-term-zil\">ZIL</link>。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:62
msgid "A complete list of features and terminology is in <<zfs-term>>."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:64
#, no-wrap
msgid "What Makes ZFS Different"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:77
#, fuzzy
msgid ""
"More than a file system, ZFS is fundamentally different from traditional "
"file systems.  Combining the traditionally separate roles of volume manager "
"and file system provides ZFS with unique advantages.  The file system is now "
"aware of the underlying structure of the disks.  Traditional file systems "
"could exist on a single disk alone at a time.  If there were two disks then "
"creating two separate file systems was necessary.  A traditional hardware "
"RAID configuration avoided this problem by presenting the operating system "
"with a single logical disk made up of the space provided by physical disks "
"on top of which the operating system placed a file system.  Even with "
"software RAID solutions like those provided by GEOM, the UFS file system "
"living on top of the RAID believes it's dealing with a single device.  ZFS' "
"combination of the volume manager and the file system solves this and allows "
"the creation of file systems that all share a pool of available storage.  "
"One big advantage of ZFS' awareness of the physical disk layout is that "
"existing file systems grow automatically when adding extra disks to the "
"pool.  This new space then becomes available to the file systems.  ZFS can "
"also apply different properties to each file system. This makes it useful to "
"create separate file systems and datasets instead of a single monolithic "
"file system."
msgstr ""
"<acronym>ZFS</acronym> 与以往任何的文件系统有显著的不同，因为它不只是一个文件"
"系统，<acronym>ZFS</acronym> 的独特优点来自结合了以往被分开的磁盘区管理程序"
"（Volume Manager）及文件系统两个角色，让文件系统也能够察觉磁盘底层结构的变"
"动。传统在一个磁盘上只能建立一个文件系统，若有两个磁盘则会需要建立两个分开的"
"文件系统，在传统要解决这个问题要使用硬 <acronym>RAID</acronym> 来制作一个空间"
"实际上由数颗实体磁盘所组成的单一的逻辑磁盘给文件系统，文件系统便可在这个逻辑"
"磁盘上放置文件系统，即使是在那些使用 <acronym>GEMO</acronym> 提供的软 "
"<acronym>RAID</acronym> 解决方案也是一样，把 <acronym>UFS</acronym> 文件系统"
"放在 <acronym>RAID</acronym> Transform上面当做是一个单一的设备。"
"<acronym>ZFS</acronym> 结合了磁盘区管理程序（Volume Manager）与文件系统来解决"
"这个问题并让建立多个文件系统可以共用一个存储池（Pool）。<acronym>ZFS</"
"acronym> 最大的优点是可以察觉实体磁盘配置的变动，当有额外的磁盘加入到存储池时"
"可以自动扩增现有的文件系统，所有的文件系统便可使用这个新的空间。"
"<acronym>ZFS</acronym> 也有数个不同的属性可以套用到各别文件系统上，比起单一文"
"件系统，对建立数个不同文件系统与数据集（Dataset）时有许多的好处。"

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:79
#, no-wrap
msgid "Quick Start Guide"
msgstr "快速入门"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:83
msgid ""
"FreeBSD can mount ZFS pools and datasets during system initialization.  To "
"enable it, add this line to [.filename]#/etc/rc.conf#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:87
#, fuzzy, no-wrap
msgid "zfs_enable=\"YES\"\n"
msgstr "zfs_enable=\"YES\"\n"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:90
msgid "Then start the service:"
msgstr "然后启动服务："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:94
#, no-wrap
msgid "# service zfs start\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:98
msgid ""
"The examples in this section assume three SCSI disks with the device names [."
"filename]#da0#, [.filename]#da1#, and [.filename]#da2#.  Users of SATA "
"hardware should instead use [.filename]#ada# device names."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:100
#, no-wrap
msgid "Single Disk Pool"
msgstr "单磁盘存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:103
msgid "To create a simple, non-redundant pool using a single disk device:"
msgstr "使用一个磁盘建立一个简单，无备份的存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:107
#, no-wrap
msgid "# zpool create example /dev/da0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:110
msgid "To view the new pool, review the output of `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:119
#, no-wrap
msgid ""
"# df\n"
"Filesystem  1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a   2026030  235230  1628718    13%    /\n"
"devfs               1       1        0   100%    /dev\n"
"/dev/ad0s1d  54098308 1032846 48737598     2%    /usr\n"
"example      17547136       0 17547136     0%    /example\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:123
msgid ""
"This output shows creating and mounting of the `example` pool, and that is "
"now accessible as a file system.  Create files for users to browse:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:134
#, no-wrap
msgid ""
"# cd /example\n"
"# ls\n"
"# touch testfile\n"
"# ls -al\n"
"total 4\n"
"drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .\n"
"drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..\n"
"-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:138
msgid ""
"This pool is not using any advanced ZFS features and properties yet.  To "
"create a dataset on this pool with compression enabled:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:143
#, no-wrap
msgid ""
"# zfs create example/compressed\n"
"# zfs set compression=gzip example/compressed\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:147
msgid ""
"The `example/compressed` dataset is now a ZFS compressed file system.  Try "
"copying some large files to [.filename]#/example/compressed#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:149
msgid "Disable compression with:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:153
#, no-wrap
msgid "# zfs set compression=off example/compressed\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:156
msgid "To unmount a file system, use `zfs umount` and then verify with `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:166
#, no-wrap
msgid ""
"# zfs umount example/compressed\n"
"# df\n"
"Filesystem  1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a   2026030  235232  1628716    13%    /\n"
"devfs               1       1        0   100%    /dev\n"
"/dev/ad0s1d  54098308 1032864 48737580     2%    /usr\n"
"example      17547008       0 17547008     0%    /example\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:169
msgid ""
"To re-mount the file system to make it accessible again, use `zfs mount` and "
"verify with `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:180
#, no-wrap
msgid ""
"# zfs mount example/compressed\n"
"# df\n"
"Filesystem         1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a          2026030  235234  1628714    13%    /\n"
"devfs                      1       1        0   100%    /dev\n"
"/dev/ad0s1d         54098308 1032864 48737580     2%    /usr\n"
"example             17547008       0 17547008     0%    /example\n"
"example/compressed  17547008       0 17547008     0%    /example/compressed\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:183
msgid "Running `mount` shows the pool and file systems:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:192
#, no-wrap
msgid ""
"# mount\n"
"/dev/ad0s1a on / (ufs, local)\n"
"devfs on /dev (devfs, local)\n"
"/dev/ad0s1d on /usr (ufs, local, soft-updates)\n"
"example on /example (zfs, local)\n"
"example/compressed on /example/compressed (zfs, local)\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:198
msgid ""
"Use ZFS datasets like any file system after creation.  Set other available "
"features on a per-dataset basis when needed.  The example below creates a "
"new file system called `data`.  It assumes the file system contains "
"important files and configures it to store two copies of each data block."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:203
#, no-wrap
msgid ""
"# zfs create example/data\n"
"# zfs set copies=2 example/data\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:206
msgid "Use `df` to see the data and space usage:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:217
#, no-wrap
msgid ""
"# df\n"
"Filesystem         1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a          2026030  235234  1628714    13%    /\n"
"devfs                      1       1        0   100%    /dev\n"
"/dev/ad0s1d         54098308 1032864 48737580     2%    /usr\n"
"example             17547008       0 17547008     0%    /example\n"
"example/compressed  17547008       0 17547008     0%    /example/compressed\n"
"example/data        17547008       0 17547008     0%    /example/data\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:222
msgid ""
"Notice that all file systems in the pool have the same available space.  "
"Using `df` in these examples shows that the file systems use the space they "
"need and all draw from the same pool.  ZFS gets rid of concepts such as "
"volumes and partitions, and allows several file systems to share the same "
"pool."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:224
#, fuzzy
#| msgid ""
#| "To destroy the file systems and then destroy the pool as it is no longer "
#| "needed:"
msgid "To destroy the file systems and then the pool that is no longer needed:"
msgstr "当我们不再需要时可以删除卷和存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:230
#, no-wrap
msgid ""
"# zfs destroy example/compressed\n"
"# zfs destroy example/data\n"
"# zpool destroy example\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:233
#, no-wrap
msgid "RAID-Z"
msgstr "RAID-Z"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:239
msgid ""
"Disks fail.  One way to avoid data loss from disk failure is to use RAID.  "
"ZFS supports this feature in its pool design.  RAID-Z pools require three or "
"more disks but provide more usable space than mirrored pools."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:241
msgid ""
"This example creates a RAID-Z pool, specifying the disks to add to the pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:245
#, no-wrap
msgid "# zpool create storage raidz da0 da1 da2\n"
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:253
msgid ""
"Sun(TM) recommends that the number of devices used in a RAID-Z configuration "
"be between three and nine.  For environments requiring a single pool "
"consisting of 10 disks or more, consider breaking it up into smaller RAID-Z "
"groups.  If two disks are available, ZFS mirroring provides redundancy if "
"required.  Refer to man:zpool[8] for more details."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:257
msgid ""
"The previous example created the `storage` zpool.  This example makes a new "
"file system called `home` in that pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:261
#, no-wrap
msgid "# zfs create storage/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:264
#, fuzzy
#| msgid ""
#| "Compression and keeping extra copies of directories and files can be "
#| "enabled:"
msgid "Enable compression and store an extra copy of directories and files:"
msgstr "可以启用压缩功能和保留文件副本功能："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:269
#, no-wrap
msgid ""
"# zfs set copies=2 storage/home\n"
"# zfs set compression=gzip storage/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:272
msgid ""
"To make this the new home directory for users, copy the user data to this "
"directory and create the appropriate symbolic links:"
msgstr ""
"要让这个空间作为使用者的新 home 目录位置，需要复制使用者数据到这个目录并建立"
"适合的符号链接（Symbolic link）："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:279
#, no-wrap
msgid ""
"# cp -rp /home/* /storage/home\n"
"# rm -rf /home /usr/home\n"
"# ln -s /storage/home /home\n"
"# ln -s /storage/home /usr/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:283
#, fuzzy
msgid ""
"Users data is now stored on the freshly-created [.filename]#/storage/home#.  "
"Test by adding a new user and logging in as that user."
msgstr ""
"现在用户的数据会储存在新建立的 <filename>/storage/home</filename>。 可以加入"
"新用户并登入该使用者来测试。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:285
#, fuzzy
#| msgid "Try creating a file system snapshot which can be rolled back later:"
msgid "Create a file system snapshot to roll back to later:"
msgstr "试着建立文件系统快照（Snapshot），稍后可用来还原（Rollback）："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:289
#, no-wrap
msgid "# zfs snapshot storage/home@08-30-08\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:292
#, fuzzy
#| msgid ""
#| "Snapshots can only be made of a full file system, not a single directory "
#| "or file."
msgid "ZFS creates snapshots of a dataset, not a single directory or file."
msgstr "只可以对整个卷进行快照，无法对个别目录使用快照。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:295
#, fuzzy
msgid ""
"The `@` character is a delimiter between the file system name or the volume "
"name.  Before deleting an important directory, back up the file system, then "
"roll back to an earlier snapshot in which the directory still exists:"
msgstr ""
"<literal>@</literal> 字符用来区分文件系统（file system）或磁盘区（卷）名称，"
"若有重要的目录意外被删除，文件系统系统可以备份然后还原到先前目录还存在时的快"
"照："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:299
#, no-wrap
msgid "# zfs rollback storage/home@08-30-08\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:303
msgid ""
"To list all available snapshots, run `ls` in the file system's [.filename]#."
"zfs/snapshot# directory.  For example, to see the snapshot taken:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:307
#, no-wrap
msgid "# ls /storage/home/.zfs/snapshot\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:312
#, fuzzy
#| msgid ""
#| "It is possible to write a script to perform regular snapshots on user "
#| "data. However, over time, snapshots can consume a great deal of disk "
#| "space. The previous snapshot can be removed using the command:"
msgid ""
"Write a script to take regular snapshots of user data.  Over time, snapshots "
"can use up a lot of disk space.  Remove the previous snapshot using the "
"command:"
msgstr ""
"也可以写一个脚本对用户的文件进行定期快照，但随着时间推移可能消耗大量的磁盘空"
"间。先前的快照可以使用以下指令删除："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:316
#, no-wrap
msgid "# zfs destroy storage/home@08-30-08\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:320
msgid ""
"After testing, make [.filename]#/storage/home# the real [.filename]#/home# "
"with this command:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:324
#, no-wrap
msgid "# zfs set mountpoint=/home storage/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:327
msgid ""
"Run `df` and `mount` to confirm that the system now treats the file system "
"as the real [.filename]#/home#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:343
#, no-wrap
msgid ""
"# mount\n"
"/dev/ad0s1a on / (ufs, local)\n"
"devfs on /dev (devfs, local)\n"
"/dev/ad0s1d on /usr (ufs, local, soft-updates)\n"
"storage on /storage (zfs, local)\n"
"storage/home on /home (zfs, local)\n"
"# df\n"
"Filesystem   1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a    2026030  235240  1628708    13%    /\n"
"devfs                1       1        0   100%    /dev\n"
"/dev/ad0s1d   54098308 1032826 48737618     2%    /usr\n"
"storage       26320512       0 26320512     0%    /storage\n"
"storage/home  26320512       0 26320512     0%    /home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:347
msgid ""
"This completes the RAID-Z configuration.  Add daily status updates about the "
"created file systems to the nightly man:periodic[8] runs by adding this line "
"to [.filename]#/etc/periodic.conf#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:351
#, fuzzy, no-wrap
msgid "daily_status_zfs_enable=\"YES\"\n"
msgstr "daily_status_zfs_enable=\"YES\"\n"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:354
#, no-wrap
msgid "Recovering RAID-Z"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:358
msgid ""
"Every software RAID has a method of monitoring its `state`.  View the status "
"of RAID-Z devices using:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:362
#, no-wrap
msgid "# zpool status -x\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:365
msgid ""
"If all pools are <<zfs-term-online,Online>> and everything is normal, the "
"message shows:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:369
#, fuzzy, no-wrap
msgid "all pools are healthy\n"
msgstr "all pools are healthy\n"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:372
msgid ""
"If there is a problem, perhaps a disk being in the <<zfs-term-offline,"
"Offline>> state, the pool state will look like this:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:384
#, no-wrap
msgid ""
"  pool: storage\n"
" state: DEGRADED\n"
"status: One or more devices has been taken offline by the administrator.\n"
"\tSufficient replicas exist for the pool to continue functioning in a\n"
"\tdegraded state.\n"
"action: Online the device using 'zpool online' or replace the device with\n"
"\t'zpool replace'.\n"
" scrub: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:391
#, no-wrap
msgid ""
"\tNAME        STATE     READ WRITE CKSUM\n"
"\tstorage     DEGRADED     0     0     0\n"
"\t  raidz1    DEGRADED     0     0     0\n"
"\t    da0     ONLINE       0     0     0\n"
"\t    da1     OFFLINE      0     0     0\n"
"\t    da2     ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:393
#: documentation/content/en/books/handbook/zfs/_index.adoc:428
#: documentation/content/en/books/handbook/zfs/_index.adoc:474
#: documentation/content/en/books/handbook/zfs/_index.adoc:517
#: documentation/content/en/books/handbook/zfs/_index.adoc:540
#: documentation/content/en/books/handbook/zfs/_index.adoc:572
#: documentation/content/en/books/handbook/zfs/_index.adoc:651
#: documentation/content/en/books/handbook/zfs/_index.adoc:705
#: documentation/content/en/books/handbook/zfs/_index.adoc:742
#: documentation/content/en/books/handbook/zfs/_index.adoc:771
#: documentation/content/en/books/handbook/zfs/_index.adoc:851
#: documentation/content/en/books/handbook/zfs/_index.adoc:924
#: documentation/content/en/books/handbook/zfs/_index.adoc:955
#: documentation/content/en/books/handbook/zfs/_index.adoc:1055
#: documentation/content/en/books/handbook/zfs/_index.adoc:1099
#: documentation/content/en/books/handbook/zfs/_index.adoc:1124
#: documentation/content/en/books/handbook/zfs/_index.adoc:1144
#, no-wrap
msgid "errors: No known data errors\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:396
msgid ""
"\"OFFLINE\" shows the administrator took [.filename]#da1# offline using:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:400
#, no-wrap
msgid "# zpool offline storage da1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:404
msgid ""
"Power down the computer now and replace [.filename]#da1#.  Power up the "
"computer and return [.filename]#da1# to the pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:408
#, no-wrap
msgid "# zpool replace storage da1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:411
msgid ""
"Next, check the status again, this time without `-x` to display all pools:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:419
#, no-wrap
msgid ""
"# zpool status storage\n"
" pool: storage\n"
" state: ONLINE\n"
" scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:426
#: documentation/content/en/books/handbook/zfs/_index.adoc:472
#, no-wrap
msgid ""
"\tNAME        STATE     READ WRITE CKSUM\n"
"\tstorage     ONLINE       0     0     0\n"
"\t  raidz1    ONLINE       0     0     0\n"
"\t    da0     ONLINE       0     0     0\n"
"\t    da1     ONLINE       0     0     0\n"
"\t    da2     ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:431
msgid "In this example, everything is normal."
msgstr "在这个例子中，所有磁盘均正常工作。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:433
#, no-wrap
msgid "Data Verification"
msgstr "数据校验"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:437
msgid ""
"ZFS uses checksums to verify the integrity of stored data.  Creating file "
"systems automatically enables them."
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:444
msgid ""
"Disabling Checksums is possible but _not_ recommended! Checksums take little "
"storage space and provide data integrity.  Most ZFS features will not work "
"properly with checksums disabled.  Disabling these checksums will not "
"increase performance noticeably."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:447
msgid ""
"Verifying the data checksums (called _scrubbing_) ensures integrity of the "
"`storage` pool with:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:451
#, no-wrap
msgid "# zpool scrub storage\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:457
msgid ""
"The duration of a scrub depends on the amount of data stored.  Larger "
"amounts of data will take proportionally longer to verify.  Since scrubbing "
"is I/O intensive, ZFS allows a single scrub to run at a time.  After "
"scrubbing completes, view the status with `zpool status`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:465
#, no-wrap
msgid ""
"# zpool status storage\n"
" pool: storage\n"
" state: ONLINE\n"
" scrub: scrub completed with 0 errors on Sat Jan 26 19:57:37 2013\n"
"config:\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:478
#, fuzzy
#| msgid ""
#| "The completion date of the last scrub operation is displayed to help "
#| "track when another scrub is required. Routine scrubs help protect data "
#| "from silent corruption and ensure the integrity of the pool."
msgid ""
"Displaying the completion date of the last scrubbing helps decide when to "
"start another.  Routine scrubs help protect data from silent corruption and "
"ensure the integrity of the pool."
msgstr ""
"查询结果会显示上次清理时间来协助判断是否还需要清理，定期清理可以确保数据完整"
"性。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:480
msgid "Refer to man:zfs[8] and man:zpool[8] for other ZFS options."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:482
#, no-wrap
msgid "`zpool` Administration"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:487
msgid ""
"ZFS administration uses two main utilities.  The `zpool` utility controls "
"the operation of the pool and allows adding, removing, replacing, and "
"managing disks.  The <<zfs-zfs,`zfs`>> utility allows creating, destroying, "
"and managing datasets, both <<zfs-term-filesystem,file systems>> and <<zfs-"
"term-volume,volumes>>."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:489
#, no-wrap
msgid "Creating and Destroying Storage Pools"
msgstr "创建与删除存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:498
msgid ""
"Creating a ZFS storage pool requires permanent decisions, as the pool "
"structure cannot change after creation.  The most important decision is "
"which types of vdevs to group the physical disks into.  See the list of "
"<<zfs-term-vdev,vdev types>> for details about the possible options.  After "
"creating the pool, most vdev types do not allow adding disks to the vdev.  "
"The exceptions are mirrors, which allow adding new disks to the vdev, and "
"stripes, which upgrade to mirrors by attaching a new disk to the vdev.  "
"Although adding new vdevs expands a pool, the pool layout cannot change "
"after pool creation.  Instead, back up the data, destroy the pool, and "
"recreate it."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:500
msgid "Create a simple mirror pool:"
msgstr "创建一个简单的存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:509
#, no-wrap
msgid ""
"# zpool create mypool mirror /dev/ada1 /dev/ada2\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:515
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada1    ONLINE       0     0     0\n"
"            ada2    ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:520
msgid ""
"To create more than one vdev with a single command, specify groups of disks "
"separated by the vdev type keyword, `mirror` in this example:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:529
#, no-wrap
msgid ""
"# zpool create mypool mirror /dev/ada1 /dev/ada2 mirror /dev/ada3 /dev/ada4\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:538
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada1    ONLINE       0     0     0\n"
"            ada2    ONLINE       0     0     0\n"
"          mirror-1  ONLINE       0     0     0\n"
"            ada3    ONLINE       0     0     0\n"
"            ada4    ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:549
#, fuzzy
msgid ""
"Pools can also use partitions rather than whole disks.  Putting ZFS in a "
"separate partition allows the same disk to have other partitions for other "
"purposes.  In particular, it allows adding partitions with bootcode and file "
"systems needed for booting.  This allows booting from disks that are also "
"members of a pool.  ZFS adds no performance penalty on FreeBSD when using a "
"partition rather than a whole disk.  Using partitions also allows the "
"administrator to _under-provision_ the disks, using less than the full "
"capacity.  If a future replacement disk of the same nominal size as the "
"original actually has a slightly smaller capacity, the smaller partition "
"will still fit, using the replacement disk."
msgstr ""
"存储池也可以不使用整个磁盘而改使用分区来建里。把 <acronym>ZFS</acronym> 放到"
"不同的分区可让其他分区用于其他用途。尤其是有 Bootcode 与文件系统要用来开机的"
"分区，这让磁盘可以用来开机也同样可以做为存储池的一部份。在 FreeBSD 用分区来替"
"代整个磁盘并不会对性能有影响。使用分区也让管理者可以对磁盘容量做 少算的预备，"
"使用比完整容量少的容量，未来若要替换的磁盘号称与原磁盘相同，但实际上却比较小"
"时，也可符合这个较小的分区容量，以使用替换的磁盘。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:551
msgid "Create a <<zfs-term-vdev-raidz,RAID-Z2>> pool using partitions:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:560
#, no-wrap
msgid ""
"# zpool create mypool raidz2 /dev/ada0p3 /dev/ada1p3 /dev/ada2p3 /dev/ada3p3 /dev/ada4p3 /dev/ada5p3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:570
#: documentation/content/en/books/handbook/zfs/_index.adoc:769
#: documentation/content/en/books/handbook/zfs/_index.adoc:953
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          raidz2-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
"            ada3p3  ONLINE       0     0     0\n"
"            ada4p3  ONLINE       0     0     0\n"
"            ada5p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:579
#, fuzzy
msgid ""
"Destroy a pool that is no longer needed to reuse the disks.  Destroying a "
"pool requires unmounting the file systems in that pool first.  If any "
"dataset is in use, the unmount operation fails without destroying the pool.  "
"Force the pool destruction with `-f`.  This can cause undefined behavior in "
"applications which had open files on those datasets."
msgstr ""
"不需要的存储池可以删除以获得更多可用空间。删除一个存储池需要先卸载所有该存储"
"池上的数据集。若数据集在使用中，卸载操作不会完成，存储池也不会被删除。可以使"
"用 <option>-f</option> 选项来强制卸载数据集，但正在运行的应用程序可能会对数据"
"集做出未定义的操作。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:581
#, no-wrap
msgid "Adding and Removing Devices"
msgstr "添加和移除设备"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:585
msgid ""
"Two ways exist for adding disks to a pool: attaching a disk to an existing "
"vdev with `zpool attach`, or adding vdevs to the pool with `zpool add`.  "
"Some <<zfs-term-vdev,vdev types>> allow adding disks to the vdev after "
"creation."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:594
#, fuzzy
msgid ""
"A pool created with a single disk lacks redundancy.  It can detect "
"corruption but can not repair it, because there is no other copy of the "
"data.  The <<zfs-term-copies,copies>> property may be able to recover from a "
"small failure such as a bad sector, but does not provide the same level of "
"protection as mirroring or RAID-Z.  Starting with a pool consisting of a "
"single disk vdev, use `zpool attach` to add a new disk to the vdev, creating "
"a mirror.  Also use `zpool attach` to add new disks to a mirror group, "
"increasing redundancy and read performance.  When partitioning the disks "
"used for the pool, replicate the layout of the first disk on to the second.  "
"Use `gpart backup` and `gpart restore` to make this process easier."
msgstr ""
"由单一磁盘建立的存储池缺乏冗余备份功能，可以检测到数据损坏单无法修复，因为数"
"据没有其他备份。备份（<link linkend=\"zfs-term-copies\">copies</link>）属性可"
"以让您从较小的故障（比如磁盘坏道）。单无法提供与镜像和 <acronym>RAID-Z</"
"acronym> 同样级别的保护。由单一磁盘所建立的存储池可用 <command>zpool attach</"
"command> 加入新设备，建里镜像。<command>zpool attach</command> 也可用来加入额"
"外的磁盘到镜像群组以增加备份和读取速度。若使用的磁盘已有分区，可以复制给磁盘"
"分区到另一个，使用 <command>gpart backup</command> 与 <command>gpart "
"restore</command> 可以让这个过程更简单。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:596
msgid ""
"Upgrade the single disk (stripe) vdev [.filename]#ada0p3# to a mirror by "
"attaching [.filename]#ada1p3#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:604
#: documentation/content/en/books/handbook/zfs/_index.adoc:801
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:608
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          ada0p3    ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:612
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool attach mypool ada0p3 ada1p3\n"
"Make sure to wait until resilvering finishes before rebooting.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:614
#, no-wrap
msgid "If you boot from pool 'mypool', you may need to update boot code on newly attached disk _ada1p3_.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:616
#, no-wrap
msgid "Assuming you use GPT partitioning and _da0_ is your new boot disk you may use the following command:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:630
#, no-wrap
msgid ""
"        gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da0\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada1\n"
"bootcode written to ada1\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: One or more devices is currently being resilvered.  The pool will\n"
"        continue to function, possibly in a degraded state.\n"
"action: Wait for the resilver to complete.\n"
"  scan: resilver in progress since Fri May 30 08:19:19 2014\n"
"        527M scanned out of 781M at 47.9M/s, 0h0m to go\n"
"        527M resilvered, 67.53% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:636
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0  (resilvering)\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:643
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Fri May 30 08:15:58 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:649
#: documentation/content/en/books/handbook/zfs/_index.adoc:682
#: documentation/content/en/books/handbook/zfs/_index.adoc:740
#: documentation/content/en/books/handbook/zfs/_index.adoc:807
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:659
#, fuzzy
msgid ""
"When adding disks to the existing vdev is not an option, as for RAID-Z, an "
"alternative method is to add another vdev to the pool.  Adding vdevs "
"provides higher performance by distributing writes across the vdevs.  Each "
"vdev provides its own redundancy.  Mixing vdev types like `mirror` and `RAID-"
"Z` is possible but discouraged.  Adding a non-redundant vdev to a pool "
"containing mirror or RAID-Z vdevs risks the data on the entire pool.  "
"Distributing writes means a failure of the non-redundant disk will result in "
"the loss of a fraction of every block written to the pool."
msgstr ""
"若不想加入磁盘到现有的vdev，对<acronym>RAID-Z</acronym>来说，可选择另一种方"
"式：加入到另一个vdev存储池。额外的vdev可以提供更好的性能，分散写入数据到vdev"
"之间每个vdev成员负责自己的备份。也可以使用不同的vdev形态，但不建议这么做，例"
"如混合使用<literal>mirror</literal>和<literal>RAID-Z</literal>加入到另一个无"
"备份的vdev到一个含有mirror或RAID-Z vdev的存储池会让数据损坏的风险扩大整个存储"
"池，由于分散写入数据，若在无备份的磁盘上发生故障的结果便是遗失大半写到存储池"
"的数据。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:664
#, fuzzy
msgid ""
"ZFS stripes data across each of the vdevs.  For example, with two mirror "
"vdevs, this is effectively a RAID 10 that stripes writes across two sets of "
"mirrors.  ZFS allocates space so that each vdev reaches 100% full at the "
"same time.  Having vdevs with different amounts of free space will lower "
"performance, as more data writes go to the less full vdev."
msgstr ""
"在每个vdev 间的数据是串连的，例如，有两个mirror vdev，便跟 <acronym>RAID</"
"acronym> 10 一样在两个mirror 间分散写入数据，且会做空间的分配，因此 vdev 会在"
"同时达到全满100% 的用量。若 vdev 间的可用空间量不同则会影响到效能，因为数据量"
"会不成比例的写入到使用量较少的 vdev。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:666
#, fuzzy
#| msgid ""
#| "When attaching additional devices to a boot pool, remember to update the "
#| "bootcode."
msgid ""
"When attaching new devices to a boot pool, remember to update the bootcode."
msgstr "当连接额外的设备到一个可以开机的存储池，要记得更新 Bootcode。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:668
msgid ""
"Attach a second mirror group ([.filename]#ada2p3# and [.filename]#ada3p3#) "
"to the existing mirror:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:676
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Fri May 30 08:19:35 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:694
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool add mypool mirror ada2p3 ada3p3\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada2\n"
"bootcode written to ada2\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada3\n"
"bootcode written to ada3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 0h0m with 0 errors on Fri May 30 08:29:51 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:703
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
"          mirror-1  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
"            ada3p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:709
#, fuzzy
#| msgid ""
#| "Currently, vdevs cannot be removed from a pool, and disks can only be "
#| "removed from a mirror if there is enough remaining redundancy. If only "
#| "one disk in a mirror group remains, it ceases to be a mirror and reverts "
#| "to being a stripe, risking the entire pool if that remaining disk fails."
msgid ""
"Removing vdevs from a pool is impossible and removal of disks from a mirror "
"is exclusive if there is enough remaining redundancy.  If a single disk "
"remains in a mirror group, that group ceases to be a mirror and becomes a "
"stripe, risking the entire pool if that remaining disk fails."
msgstr ""
"现在已无法从存储上移除 vdev，且磁盘只能够在有足够剩余空间的情况下从 mirror 移"
"除，若在 mirror 群组中只剩下一个磁盘，便会取消 mirror 然后还原为 stripe，若剩"
"下的那个磁盘故障，便会影响到整个存储池。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:711
msgid "Remove a disk from a three-way mirror group:"
msgstr "从一个三方 mirror 群组移除一个磁盘："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:719
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 0h0m with 0 errors on Fri May 30 08:29:51 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:726
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:734
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool detach mypool ada2p3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 0h0m with 0 errors on Fri May 30 08:29:51 2014\n"
"config:\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:745
#, no-wrap
msgid "Checking the Status of a Pool"
msgstr "检擦存储池状态"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:751
#, fuzzy
msgid ""
"Pool status is important.  If a drive goes offline or ZFS detects a read, "
"write, or checksum error, the corresponding error count increases.  The "
"`status` output shows the configuration and status of each device in the "
"pool and the status of the entire pool.  Actions to take and details about "
"the last <<zfs-zpool-scrub,`scrub`>> are also shown."
msgstr ""
"存储池的状态很重要，若有磁盘机离线或侦测到读取、写入或校验码（Checksum）错"
"误，对应的错误计数便会增加。 status 会显示存储池中每一个磁盘机的设定与状态及"
"整个存储池的状态。需要处置的方式与有关最近清洁（Scrub）S的详细资讯也会一并显"
"示。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:759
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 2h25m with 0 errors on Sat Sep 14 04:25:50 2013\n"
"config:\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:774
#, no-wrap
msgid "Clearing Errors"
msgstr "排除错误"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:780
msgid ""
"When detecting an error, ZFS increases the read, write, or checksum error "
"counts.  Clear the error message and reset the counts with `zpool clear "
"_mypool_`.  Clearing the error state can be important for automated scripts "
"that alert the administrator when the pool encounters an error.  Without "
"clearing old errors, the scripts may fail to report further errors."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:782
#, no-wrap
msgid "Replacing a Functioning Device"
msgstr "更换正在运行的设备"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:791
#, fuzzy
msgid ""
"It may be desirable to replace one disk with a different disk.  When "
"replacing a working disk, the process keeps the old disk online during the "
"replacement.  The pool never enters a <<zfs-term-degraded,degraded>> state, "
"reducing the risk of data loss.  Running `zpool replace` copies the data "
"from the old disk to the new one.  After the operation completes, ZFS "
"disconnects the old disk from the vdev.  If the new disk is larger than the "
"old disk, it may be possible to grow the zpool, using the new space.  See "
"<<zfs-zpool-online,Growing a Pool>>."
msgstr ""
"可能有一些情况会需要更换磁盘为另一个磁盘，当要更换运作中的磁盘，此程序会维持"
"旧有的磁盘在更换的过程为上线的状态，存储池不会进入降级（<link linkend=\"zfs-"
"term-degraded\">degraded</link>）的状态，来减少数据遗失的风险。"
"<command>zpool replace</command> 会复制所有旧磁盘的数据到新磁盘，操作完成之后"
"旧磁盘便会与 vdev 中断连线。若新磁盘容量较旧磁盘大，也可以会增加存储池来使用"
"新的空间，请参考 <link linkend=\"zfs-zpool-online\">扩展存储池</link>。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:793
msgid "Replace a functioning device in the pool:"
msgstr "更换存储池中正在运行的设备："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:811
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool replace mypool ada1p3 ada2p3\n"
"Make sure to wait until resilvering finishes before rebooting.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:813
#, no-wrap
msgid "When booting from the pool 'zroot', update the boot code on the newly attached disk 'ada2p3'.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:815
#, no-wrap
msgid "Assuming GPT partitioning is used and [.filename]#da0# is the new boot disk, use the following command:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:828
#, no-wrap
msgid ""
"        gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da0\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada2\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: One or more devices is currently being resilvered.  The pool will\n"
"        continue to function, possibly in a degraded state.\n"
"action: Wait for the resilver to complete.\n"
"  scan: resilver in progress since Mon Jun  2 14:21:35 2014\n"
"        604M scanned out of 781M at 46.5M/s, 0h0m to go\n"
"        604M resilvered, 77.39% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:836
#, no-wrap
msgid ""
"        NAME             STATE     READ WRITE CKSUM\n"
"        mypool           ONLINE       0     0     0\n"
"          mirror-0       ONLINE       0     0     0\n"
"            ada0p3       ONLINE       0     0     0\n"
"            replacing-1  ONLINE       0     0     0\n"
"              ada1p3     ONLINE       0     0     0\n"
"              ada2p3     ONLINE       0     0     0  (resilvering)\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:843
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Mon Jun  2 14:21:52 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:849
#: documentation/content/en/books/handbook/zfs/_index.adoc:922
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:854
#, no-wrap
msgid "Dealing with Failed Devices"
msgstr "处理故障设备"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:862
msgid ""
"When a disk in a pool fails, the vdev to which the disk belongs enters the "
"<<zfs-term-degraded,degraded>> state.  The data is still available, but with "
"reduced performance because ZFS computes missing data from the available "
"redundancy.  To restore the vdev to a fully functional state, replace the "
"failed physical device.  ZFS is then instructed to begin the <<zfs-term-"
"resilver,resilver>> operation.  ZFS recomputes data on the failed device "
"from available redundancy and writes it to the replacement device.  After "
"completion, the vdev returns to <<zfs-term-online,online>> status."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:865
#, fuzzy
msgid ""
"If the vdev does not have any redundancy, or if devices have failed and "
"there is not enough redundancy to compensate, the pool enters the <<zfs-term-"
"faulted,faulted>> state.  Unless enough devices can reconnect the pool "
"becomes inoperative requiring a data restore from backups."
msgstr ""
"若 vdev 没有任何备份数据或有多个设备故障，没有足够的备援数据可以补偿，存储便"
"会进入故障（<link linkend=\"zfs-term-faulted\">faulted</link>）的状态。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:868
msgid ""
"When replacing a failed disk, the name of the failed disk changes to the "
"GUID of the new disk.  A new device name parameter for `zpool replace` is "
"not required if the replacement device has the same device name."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:870
msgid "Replace a failed disk using `zpool replace`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:882
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: DEGRADED\n"
"status: One or more devices could not be opened.  Sufficient replicas exist for\n"
"        the pool to continue functioning in a degraded state.\n"
"action: Attach the missing device and online it using 'zpool online'.\n"
"   see: http://illumos.org/msg/ZFS-8000-2Q\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:888
#, no-wrap
msgid ""
"        NAME                    STATE     READ WRITE CKSUM\n"
"        mypool                  DEGRADED     0     0     0\n"
"          mirror-0              DEGRADED     0     0     0\n"
"            ada0p3              ONLINE       0     0     0\n"
"            316502962686821739  UNAVAIL      0     0     0  was /dev/ada1p3\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:901
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool replace mypool 316502962686821739 ada2p3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: DEGRADED\n"
"status: One or more devices is currently being resilvered.  The pool will\n"
"        continue to function, possibly in a degraded state.\n"
"action: Wait for the resilver to complete.\n"
"  scan: resilver in progress since Mon Jun  2 14:52:21 2014\n"
"        641M scanned out of 781M at 49.3M/s, 0h0m to go\n"
"        640M resilvered, 82.04% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:909
#, no-wrap
msgid ""
"        NAME                        STATE     READ WRITE CKSUM\n"
"        mypool                      DEGRADED     0     0     0\n"
"          mirror-0                  DEGRADED     0     0     0\n"
"            ada0p3                  ONLINE       0     0     0\n"
"            replacing-1             UNAVAIL      0     0     0\n"
"              15732067398082357289  UNAVAIL      0     0     0  was /dev/ada1p3/old\n"
"              ada2p3                ONLINE       0     0     0  (resilvering)\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:916
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Mon Jun  2 14:52:38 2014\n"
"config:\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:927
#, no-wrap
msgid "Scrubbing a Pool"
msgstr "清理存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:932
msgid ""
"Routinely <<zfs-term-scrub,scrub>> pools, ideally at least once every "
"month.  The `scrub` operation is disk-intensive and will reduce performance "
"while running.  Avoid high-demand periods when scheduling `scrub` or use "
"<<zfs-advanced-tuning-scrub_delay,`vfs.zfs.scrub_delay`>> to adjust the "
"relative priority of the `scrub` to keep it from slowing down other "
"workloads."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:943
#, no-wrap
msgid ""
"# zpool scrub mypool\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub in progress since Wed Feb 19 20:52:54 2014\n"
"        116G scanned out of 8.60T at 649M/s, 3h48m to go\n"
"        0 repaired, 1.32% done\n"
"config:\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:958
msgid "To cancel a scrub operation if needed, run `zpool scrub -s _mypool_`."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:960
#, no-wrap
msgid "Self-Healing"
msgstr "自我修复"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:971
msgid ""
"The checksums stored with data blocks enable the file system to _self-"
"heal_.  This feature will automatically repair data whose checksum does not "
"match the one recorded on another device that is part of the storage pool.  "
"For example, a mirror configuration with two disks where one drive is "
"starting to malfunction and cannot properly store the data any more.  This "
"is worse when the data was not accessed for a long time, as with long term "
"archive storage.  Traditional file systems need to run commands that check "
"and repair the data like man:fsck[8].  These commands take time, and in "
"severe cases, an administrator has to decide which repair operation to "
"perform.  When ZFS detects a data block with a mismatched checksum, it tries "
"to read the data from the mirror disk.  If that disk can provide the correct "
"data, ZFS will give that to the application and correct the data on the disk "
"with the wrong checksum.  This happens without any interaction from a system "
"administrator during normal pool operation."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:973
#, fuzzy
msgid ""
"The next example shows this self-healing behavior by creating a mirrored "
"pool of disks [.filename]#/dev/ada0# and [.filename]#/dev/ada1#."
msgstr ""
"接下来的例子会示范自我修复会如何运作。建立一个使用磁盘 <filename>/dev/ada0</"
"filename> 及<filename>/dev/ada1</filename> 做镜像的存储池。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:982
#, no-wrap
msgid ""
"# zpool create healer mirror /dev/ada0 /dev/ada1\n"
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:988
#: documentation/content/en/books/handbook/zfs/_index.adoc:1142
#, no-wrap
msgid ""
"    NAME        STATE     READ WRITE CKSUM\n"
"    healer      ONLINE       0     0     0\n"
"      mirror-0  ONLINE       0     0     0\n"
"       ada0     ONLINE       0     0     0\n"
"       ada1     ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:993
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool list\n"
"NAME     SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT\n"
"healer   960M  92.5K   960M         -         -     0%    0%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:996
#, fuzzy
msgid ""
"Copy some important data to the pool to protect from data errors using the "
"self-healing feature and create a checksum of the pool for later comparison."
msgstr ""
"将一些需要使用自我修复功能来保护的重要数据复制到该存储池，建立一个存储池的校"
"验码以供日后比对。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1006
#, no-wrap
msgid ""
"# cp /some/important/data /healer\n"
"# zfs list\n"
"NAME     SIZE  ALLOC   FREE    CAP  DEDUP  HEALTH  ALTROOT\n"
"healer   960M  67.7M   892M     7%  1.00x  ONLINE  -\n"
"# sha1 /healer > checksum.txt\n"
"# cat checksum.txt\n"
"SHA1 (/healer) = 2753eff56d77d9a536ece6694bf0a82740344d1f\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1010
#, fuzzy
msgid ""
"Simulate data corruption by writing random data to the beginning of one of "
"the disks in the mirror.  To keep ZFS from healing the data when detected, "
"export the pool before the corruption and import it again afterwards."
msgstr ""
"写入随机的资料到镜像的第一个磁盘来模拟资料损毁的情况。要避免 <acronym>ZFS</"
"acronym> 侦测到错误时马上做修复，接着要将存储池导出，待模拟资料损毁之后再导"
"入。"

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1018
#, fuzzy
#| msgid ""
#| "This is a dangerous operation that can destroy vital data. It is shown "
#| "here for demonstrational purposes only and should not be attempted during "
#| "normal operation of a storage pool. Nor should this intentional "
#| "corruption example be run on any disk with a different file system on it. "
#| "Do not use any other disk device names other than the ones that are part "
#| "of the pool. Make certain that proper backups of the pool are created "
#| "before running the command!"
msgid ""
"This is a dangerous operation that can destroy vital data, shown here for "
"demonstration alone.  *Do not try* it during normal operation of a storage "
"pool.  Nor should this intentional corruption example run on any disk with a "
"file system not using ZFS on another partition in it.  Do not use any other "
"disk device names other than the ones that are part of the pool.  Ensure "
"proper backups of the pool exist and test them before running the command!"
msgstr ""
"这是一个危险的操作，会破坏重要的数据。在这里使用仅为了示范用，不应在存储池正"
"常运作时尝试使用，也不应将这个故意损坏数据的例子用在任何其他的文件系统上，所"
"以请勿使用任何不属于该存储池的其他磁盘设备名称并确定在执行指令前已对存储池做"
"正确的备份！"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1028
#, no-wrap
msgid ""
"# zpool export healer\n"
"# dd if=/dev/random of=/dev/ada1 bs=1m count=200\n"
"200+0 records in\n"
"200+0 records out\n"
"209715200 bytes transferred in 62.992162 secs (3329227 bytes/sec)\n"
"# zpool import healer\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1034
msgid ""
"The pool status shows that one device has experienced an error.  Note that "
"applications reading data from the pool did not receive any incorrect data.  "
"ZFS provided data from the [.filename]#ada0# device with the correct "
"checksums.  To find the device with the wrong checksum, look for one whose "
"`CKSUM` column contains a nonzero value."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1047
#, no-wrap
msgid ""
"# zpool status healer\n"
"    pool: healer\n"
"   state: ONLINE\n"
"  status: One or more devices has experienced an unrecoverable error.  An\n"
"          attempt was made to correct the error.  Applications are unaffected.\n"
"  action: Determine if the device needs to be replaced, and clear the errors\n"
"          using 'zpool clear' or replace the device with 'zpool replace'.\n"
"     see: http://illumos.org/msg/ZFS-8000-4J\n"
"    scan: none requested\n"
"  config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1053
#, no-wrap
msgid ""
"      NAME        STATE     READ WRITE CKSUM\n"
"      healer      ONLINE       0     0     0\n"
"        mirror-0  ONLINE       0     0     0\n"
"         ada0     ONLINE       0     0     0\n"
"         ada1     ONLINE       0     0     1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1059
#, fuzzy
msgid ""
"ZFS detected the error and handled it by using the redundancy present in the "
"unaffected [.filename]#ada0# mirror disk.  A checksum comparison with the "
"original one will reveal whether the pool is consistent again."
msgstr ""
"错误已经被检测到并且由未被影响的 <filename>ada0</filename> 镜像磁盘上的备份提"
"供数据。可与原来的校验码做比较来看存储池是否已修复为一致。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1066
#, no-wrap
msgid ""
"# sha1 /healer >> checksum.txt\n"
"# cat checksum.txt\n"
"SHA1 (/healer) = 2753eff56d77d9a536ece6694bf0a82740344d1f\n"
"SHA1 (/healer) = 2753eff56d77d9a536ece6694bf0a82740344d1f\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1075
msgid ""
"Generate checksums before and after the intentional tampering while the pool "
"data still matches.  This shows how ZFS is capable of detecting and "
"correcting any errors automatically when the checksums differ.  Note this is "
"possible with enough redundancy present in the pool.  A pool consisting of a "
"single device has no self-healing capabilities.  That is also the reason why "
"checksums are so important in ZFS; do not disable them for any reason.  ZFS "
"requires no man:fsck[8] or similar file system consistency check program to "
"detect and correct this, and keeps the pool available while there is a "
"problem.  A scrub operation is now required to overwrite the corrupted data "
"on [.filename]#ada1#."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1091
#, no-wrap
msgid ""
"# zpool scrub healer\n"
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"status: One or more devices has experienced an unrecoverable error.  An\n"
"            attempt was made to correct the error.  Applications are unaffected.\n"
"action: Determine if the device needs to be replaced, and clear the errors\n"
"            using 'zpool clear' or replace the device with 'zpool replace'.\n"
"   see: http://illumos.org/msg/ZFS-8000-4J\n"
"  scan: scrub in progress since Mon Dec 10 12:23:30 2012\n"
"        10.4M scanned out of 67.0M at 267K/s, 0h3m to go\n"
"        9.63M repaired, 15.56% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1097
#, no-wrap
msgid ""
"    NAME        STATE     READ WRITE CKSUM\n"
"    healer      ONLINE       0     0     0\n"
"      mirror-0  ONLINE       0     0     0\n"
"       ada0     ONLINE       0     0     0\n"
"       ada1     ONLINE       0     0   627  (repairing)\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1103
msgid ""
"The scrub operation reads data from [.filename]#ada0# and rewrites any data "
"with a wrong checksum on [.filename]#ada1#, shown by the `(repairing)` "
"output from `zpool status`.  After the operation is complete, the pool "
"status changes to:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1116
#, no-wrap
msgid ""
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"status: One or more devices has experienced an unrecoverable error.  An\n"
"        attempt was made to correct the error.  Applications are unaffected.\n"
"action: Determine if the device needs to be replaced, and clear the errors\n"
"             using 'zpool clear' or replace the device with 'zpool replace'.\n"
"   see: http://illumos.org/msg/ZFS-8000-4J\n"
"  scan: scrub repaired 66.5M in 0h2m with 0 errors on Mon Dec 10 12:26:25 2012\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1122
#, no-wrap
msgid ""
"    NAME        STATE     READ WRITE CKSUM\n"
"    healer      ONLINE       0     0     0\n"
"      mirror-0  ONLINE       0     0     0\n"
"       ada0     ONLINE       0     0     0\n"
"       ada1     ONLINE       0     0 2.72K\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1127
msgid ""
"After the scrubbing operation completes with all the data synchronized from "
"[.filename]#ada0# to [.filename]#ada1#, <<zfs-zpool-clear,clear>> the error "
"messages from the pool status by running `zpool clear`."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1136
#, no-wrap
msgid ""
"# zpool clear healer\n"
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"  scan: scrub repaired 66.5M in 0h2m with 0 errors on Mon Dec 10 12:26:25 2012\n"
"config:\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1147
#, fuzzy
#| msgid ""
#| "The pool is now back to a fully working state and all the errors have "
#| "been cleared."
msgid ""
"The pool is now back to a fully working state, with all error counts now "
"zero."
msgstr ""
"The pool is now back to a fully working state and all the errors have been "
"cleared."

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1149
#, no-wrap
msgid "Growing a Pool"
msgstr "扩增存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1158
#, fuzzy
msgid ""
"The smallest device in each vdev limits the usable size of a redundant "
"pool.  Replace the smallest device with a larger device.  After completing a "
"<<zfs-zpool-replace,replace>> or <<zfs-term-resilver,resilver>> operation, "
"the pool can grow to use the capacity of the new device.  For example, "
"consider a mirror of a 1 TB drive and a 2 TB drive.  The usable space is 1 "
"TB.  When replacing the 1 TB drive with another 2 TB drive, the resilvering "
"process copies the existing data onto the new drive.  As both of the devices "
"now have 2 TB capacity, the mirror's available space grows to 2 TB."
msgstr ""
"可用的备援存储池大小会受到每个 vdev 中容量最小的设备限制。最小的设备可以替换"
"成较大的设备，在更换（<link linkend=\"zfs-zpool-replace\">Replace</link>）或"
"修复（<link linkend=\"zfs-term-resilver\">Resilver</link>）作业后，存储池可以"
"成长到该新设备的可用容量。例如，要做一个 1 TB 磁盘机与一个 2 TB 磁盘机的镜"
"像，可用的空间会是1 TB，当1 TB 磁盘机备更换成另一个 2 TB 的磁盘机时，修复程序"
"会复制既有的资料到新的磁盘机，由于现在两个设备都有 2 TB 的容量，所以镜像的可"
"用空间便会成长到 2 TB。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1161
msgid ""
"Start expansion by using `zpool online -e` on each device.  After expanding "
"all devices, the extra space becomes available to the pool."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1163
#, no-wrap
msgid "Importing and Exporting Pools"
msgstr "导入与导出存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1171
msgid ""
"_Export_ pools before moving them to another system.  ZFS unmounts all "
"datasets, marking each device as exported but still locked to prevent use by "
"other disks.  This allows pools to be _imported_ on other machines, other "
"operating systems that support ZFS, and even different hardware "
"architectures (with some caveats, see man:zpool[8]).  When a dataset has "
"open files, use `zpool export -f` to force exporting the pool.  Use this "
"with caution.  The datasets are forcibly unmounted, potentially resulting in "
"unexpected behavior by the applications which had open files on those "
"datasets."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1173
msgid "Export a pool that is not in use:"
msgstr "导出未使用的存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1177
#, no-wrap
msgid "# zpool export mypool\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1185
#, fuzzy
msgid ""
"Importing a pool automatically mounts the datasets.  If this is undesired "
"behavior, use `zpool import -N` to prevent it.  `zpool import -o` sets "
"temporary properties for this specific import.  `zpool import altroot=` "
"allows importing a pool with a base mount point instead of the root of the "
"file system.  If the pool was last used on a different system and was not "
"properly exported, force the import using `zpool import -f`.  `zpool import -"
"a` imports all pools that do not appear to be in use by another system."
msgstr ""
"导入存储池会自动挂载数据集，若不想自动挂载，可以使用 <command>zpool import -"
"N</command>。<command>zpool import -o</command> 可以设定在导入时暂时使用的属"
"性。<command>zpool import altroot=</command> 允许导入时指定基础挂载点（Base "
"mount point）来替换文件系统根目录。若存储池先前用在不同的系统且不正常导出，可"
"能会需要使用 <command>zpool import -f</command> 来强制导入。<command>zpool "
"import -a</command> 会导入所有没有被其他系统使用的存储池。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1187
msgid "List all available pools for import:"
msgstr "列出所有可导入的存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1196
#, no-wrap
msgid ""
"# zpool import\n"
"   pool: mypool\n"
"     id: 9930174748043525076\n"
"  state: ONLINE\n"
" action: The pool can be imported using its name or numeric identifier.\n"
" config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1199
#, no-wrap
msgid ""
"        mypool      ONLINE\n"
"          ada2p3    ONLINE\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1202
msgid "Import the pool with an alternative root directory:"
msgstr "使用替代的根目录导入存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1210
#, no-wrap
msgid ""
"# zpool import -o altroot=/mnt mypool\n"
"# zfs list\n"
"zfs list\n"
"NAME                 USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool               110K  47.0G    31K  /mnt/mypool\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1213
#, no-wrap
msgid "Upgrading a Storage Pool"
msgstr "升级存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1219
#, fuzzy
msgid ""
"After upgrading FreeBSD, or if importing a pool from a system using an older "
"version, manually upgrade the pool to the latest ZFS version to support "
"newer features.  Consider whether the pool may ever need importing on an "
"older system before upgrading.  Upgrading is a one-way process.  Upgrade "
"older pools is possible, but downgrading pools with newer features is not."
msgstr ""
"在升级 FreeBSD 之后或存储池是由其他使用旧版 <acronym>ZFS</acronym> 的系统汇"
"入，存储池可以手动升级到最新版本的 <acronym>ZFS</acronym> 来支持新的功能。在"
"升级前请评估存储池是否还要在旧的系统做汇入，由于升级是一个单向的程序，旧的存"
"储池可以升级，但有新功能的存储池无法降级。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1221
msgid "Upgrade a v28 pool to support `Feature Flags`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1234
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: The pool is formatted using a legacy on-disk format.  The pool can\n"
"        still be used, but some features are unavailable.\n"
"action: Upgrade the pool using 'zpool upgrade'.  Once this is done, the\n"
"        pool will no longer be accessible on software that does not support feat\n"
"        flags.\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1240
#: documentation/content/en/books/handbook/zfs/_index.adoc:1288
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"\t    ada0    ONLINE       0     0     0\n"
"\t    ada1    ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1244
#: documentation/content/en/books/handbook/zfs/_index.adoc:1292
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool upgrade\n"
"This system supports ZFS pool feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1247
#, no-wrap
msgid ""
"The following pools are formatted with legacy version numbers and are upgraded to use feature flags.\n"
"After being upgraded, these pools will no longer be accessible by software that does not support feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1251
#, no-wrap
msgid ""
"VER  POOL\n"
"---  ------------\n"
"28   mypool\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1256
#, no-wrap
msgid ""
"Use 'zpool upgrade -v' for a list of available legacy versions.\n"
"Every feature flags pool has all supported features enabled.\n"
"# zpool upgrade mypool\n"
"This system supports ZFS pool feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1263
#, no-wrap
msgid ""
"Successfully upgraded 'mypool' from version 28 to feature flags.\n"
"Enabled the following features on 'mypool':\n"
"  async_destroy\n"
"  empty_bpobj\n"
"  lz4_compress\n"
"  multi_vdev_crash_dump\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1267
msgid ""
"The newer features of ZFS will not be available until `zpool upgrade` has "
"completed.  Use `zpool upgrade -v` to see what new features the upgrade "
"provides, as well as which features are already supported."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1269
#, fuzzy
#| msgid "Upgrade a pool to support additional feature flags:"
msgid "Upgrade a pool to support new feature flags:"
msgstr "升级存储池支持新版的功能旗标（Feature flags）："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1282
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: Some supported features are not enabled on the pool. The pool can\n"
"        still be used, but some features are unavailable.\n"
"action: Enable all features using 'zpool upgrade'. Once this is done,\n"
"        the pool may no longer be accessible by software that does not support\n"
"        the features. See zpool-features(7) for details.\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1294
#, no-wrap
msgid "All pools are formatted using feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1298
#, no-wrap
msgid ""
"Some supported features are not enabled on the following pools. Once a\n"
"feature is enabled the pool may become incompatible with software\n"
"that does not support the feature. See zpool-features(7) for details.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1311
#, no-wrap
msgid ""
"POOL  FEATURE\n"
"---------------\n"
"zstore\n"
"      multi_vdev_crash_dump\n"
"      spacemap_histogram\n"
"      enabled_txg\n"
"      hole_birth\n"
"      extensible_dataset\n"
"      bookmarks\n"
"      filesystem_limits\n"
"# zpool upgrade mypool\n"
"This system supports ZFS pool feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1319
#, no-wrap
msgid ""
"Enabled the following features on 'mypool':\n"
"  spacemap_histogram\n"
"  enabled_txg\n"
"  hole_birth\n"
"  extensible_dataset\n"
"  bookmarks\n"
"  filesystem_limits\n"
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1326
msgid ""
"Update the boot code on systems that boot from a pool to support the new "
"pool version.  Use `gpart bootcode` on the partition that contains the boot "
"code.  Two types of bootcode are available, depending on way the system "
"boots: GPT (the most common option) and EFI (for more modern systems)."
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1328
msgid "For legacy boot using GPT, use the following command:"
msgstr "对使用GPT分区的boot，使用以下命令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1332
#, no-wrap
msgid "# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1335
msgid "For systems using EFI to boot, execute the following command:"
msgstr "对使用EFI的启动方式，请执行以下命令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1339
#, no-wrap
msgid "# gpart bootcode -p /boot/boot1.efifat -i 1 ada1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1343
msgid ""
"Apply the bootcode to all bootable disks in the pool.  See man:gpart[8] for "
"more information."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1346
#, no-wrap
msgid "Displaying Recorded Pool History"
msgstr "显示已记录的存储池历史日志"

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1352
#, fuzzy
msgid ""
"ZFS records commands that change the pool, including creating datasets, "
"changing properties, or replacing a disk.  Reviewing history about a pool's "
"creation is useful, as is checking which user performed a specific action "
"and when.  History is not kept in a log file, but is part of the pool "
"itself.  The command to review this history is aptly named `zpool history`:"
msgstr ""
"修改存储池的指令会被记录下来，会记录的动作包含数据集的建立，属性更改或更换磁"
"盘。这个历史记录用来查看存储池是如何建立、由谁执行、什么动作及何时。历史记录"
"并非储存在日志档（Log file），而是储存在存储池。查看这个历史记录的指令名称为 "
"<command>zpool history</command>："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1361
#, no-wrap
msgid ""
"# zpool history\n"
"History for 'tank':\n"
"2013-02-26.23:02:35 zpool create tank mirror /dev/ada0 /dev/ada1\n"
"2013-02-27.18:50:58 zfs set atime=off tank\n"
"2013-02-27.18:51:09 zfs set checksum=fletcher4 tank\n"
"2013-02-27.18:51:18 zfs create tank/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1366
#, fuzzy
msgid ""
"The output shows `zpool` and `zfs` commands altering the pool in some way "
"along with a timestamp.  Commands like `zfs list` are not included.  When "
"specifying no pool name, ZFS displays history of all pools."
msgstr ""
"输出结果显示曾在该存储池上执行的 <command>zpool</command> 与 <command>zfs</"
"command> 指令以及时间戳记。只有会修改存储池或类似的指令会被记录下来，像是 "
"<command>zfs list</command> 这种指令并不会被记录。当不指定存储池名称时，会列"
"出所有存储池的历史记录。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1369
msgid ""
"`zpool history` can show even more information when providing the options `-"
"i` or `-l`.  `-i` displays user-initiated events as well as internally "
"logged ZFS events."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1381
#, no-wrap
msgid ""
"# zpool history -i\n"
"History for 'tank':\n"
"2013-02-26.23:02:35 [internal pool create txg:5] pool spa 28; zfs spa 28; zpl 5;uts  9.1-RELEASE 901000 amd64\n"
"2013-02-27.18:50:53 [internal property set txg:50] atime=0 dataset = 21\n"
"2013-02-27.18:50:58 zfs set atime=off tank\n"
"2013-02-27.18:51:04 [internal property set txg:53] checksum=7 dataset = 21\n"
"2013-02-27.18:51:09 zfs set checksum=fletcher4 tank\n"
"2013-02-27.18:51:13 [internal create txg:55] dataset = 39\n"
"2013-02-27.18:51:18 zfs create tank/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1385
#, fuzzy
msgid ""
"Show more details by adding `-l`.  Showing history records in a long format, "
"including information like the name of the user who issued the command and "
"the hostname on which the change happened."
msgstr ""
"更多详细的资讯可加上 <option>-l</option> 来取得，历史记录会以较长的格式显示，"
"包含的资讯有执行指令的使用者名称、主机名称以及更改的项目。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1394
#, no-wrap
msgid ""
"# zpool history -l\n"
"History for 'tank':\n"
"2013-02-26.23:02:35 zpool create tank mirror /dev/ada0 /dev/ada1 [user 0 (root) on :global]\n"
"2013-02-27.18:50:58 zfs set atime=off tank [user 0 (root) on myzfsbox:global]\n"
"2013-02-27.18:51:09 zfs set checksum=fletcher4 tank [user 0 (root) on myzfsbox:global]\n"
"2013-02-27.18:51:18 zfs create tank/backup [user 0 (root) on myzfsbox:global]\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1400
msgid ""
"The output shows that the `root` user created the mirrored pool with disks [."
"filename]#/dev/ada0# and [.filename]#/dev/ada1#.  The hostname `myzfsbox` is "
"also shown in the commands after the pool's creation.  The hostname display "
"becomes important when exporting the pool from one system and importing on "
"another.  It's possible to distinguish the commands issued on the other "
"system by the hostname recorded for each command."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1403
#, fuzzy
msgid ""
"Combine both options to `zpool history` to give the most detailed "
"information possible for any given pool.  Pool history provides valuable "
"information when tracking down the actions performed or when needing more "
"detailed output for debugging."
msgstr ""
"两个 <command>zpool history</command> 选项可以合并使用来取得最完整的存储池详"
"细资讯。存储池历史记录在追踪执行什么动作或要取得除错所需的输出结果提供了非常"
"有用的资讯。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1405
#, no-wrap
msgid "Performance Monitoring"
msgstr "性能监控"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1412
#, fuzzy
msgid ""
"A built-in monitoring system can display pool I/O statistics in real time.  "
"It shows the amount of free and used space on the pool, read and write "
"operations performed per second, and I/O bandwidth used.  By default, ZFS "
"monitors and displays all pools in the system.  Provide a pool name to limit "
"monitoring to that pool.  A basic example:"
msgstr ""
"内建的监视系统可以即时显示存储池的 <acronym>I/O</acronym> 统计资讯。它会显示"
"存储池剩余的空间与使用的空间，每秒执行了多少读取与写入的操作，有多少 "
"<acronym>I/O</acronym> 带宽被使用。预设会监视所有在系统中的存储池都并显示出"
"来，可以提供存储池名称来只显示该存储池的监视资讯。举一个简单的例子："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1420
#, no-wrap
msgid ""
"# zpool iostat\n"
"               capacity     operations    bandwidth\n"
"pool        alloc   free   read  write   read  write\n"
"----------  -----  -----  -----  -----  -----  -----\n"
"data         288G  1.53T      2     11  11.3K  57.1K\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1426
msgid ""
"To continuously see I/O activity, specify a number as the last parameter, "
"indicating an interval in seconds to wait between updates.  The next "
"statistic line prints after each interval.  Press kbd:[Ctrl+C] to stop this "
"continuous monitoring.  Give a second number on the command line after the "
"interval to specify the total number of statistics to display."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1431
#, fuzzy
msgid ""
"Display even more detailed I/O statistics with `-v`.  Each device in the "
"pool appears with a statistics line.  This is useful for seeing read and "
"write operations performed on each device, and can help determine if any "
"individual device is slowing down the pool.  This example shows a mirrored "
"pool with two devices:"
msgstr ""
"使用 <option>-v</option> 可以显示更详细的 <acronym>I/O</acronym> 统计资讯。每"
"个在存储池中的设备会以一行统计资讯显示。这可以帮助了解每一个设备做了多少读取"
"与写入的操作，并可协助确认是否有各别设备拖慢了整个存储池的速度。以下范例会显"
"示有两个设备的镜像存储池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1443
#, no-wrap
msgid ""
"# zpool iostat -v \n"
"                            capacity     operations    bandwidth\n"
"pool                     alloc   free   read  write   read  write\n"
"-----------------------  -----  -----  -----  -----  -----  -----\n"
"data                      288G  1.53T      2     12  9.23K  61.5K\n"
"  mirror                  288G  1.53T      2     12  9.23K  61.5K\n"
"    ada1                     -      -      0      4  5.61K  61.7K\n"
"    ada2                     -      -      1      4  5.04K  61.7K\n"
"-----------------------  -----  -----  -----  -----  -----  -----\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1446
#, no-wrap
msgid "Splitting a Storage Pool"
msgstr "分割存储池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1453
#, fuzzy
msgid ""
"ZFS can split a pool consisting of one or more mirror vdevs into two pools.  "
"Unless otherwise specified, ZFS detaches the last member of each mirror and "
"creates a new pool containing the same data.  Be sure to make a dry run of "
"the operation with `-n` first.  This displays the details of the requested "
"operation without actually performing it.  This helps confirm that the "
"operation will do what the user intends."
msgstr ""
"由一个或多个镜像 vdev 所组成的存储池可以切分开成两个存储池。除非有另外指定，"
"否则每个镜像的最后一个成员会被分离来然用来建立一个含有相同资料的新存储池。在"
"做这个操作的第一次应先使用 <option>-n</option>，会显示预计会做的操作而不会真"
"的执行，这可以协助确认操作是否与使用者所要的相同。"

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:1455
#, no-wrap
msgid "`zfs` Administration"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1459
msgid ""
"The `zfs` utility can create, destroy, and manage all existing ZFS datasets "
"within a pool.  To manage the pool itself, use <<zfs-zpool,`zpool`>>."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1461
#, no-wrap
msgid "Creating and Destroying Datasets"
msgstr "创建和删除数据集"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1471
#, fuzzy
msgid ""
"Unlike traditional disks and volume managers, space in ZFS is _not_ "
"preallocated.  With traditional file systems, after partitioning and "
"assigning the space, there is no way to add a new file system without adding "
"a new disk.  With ZFS, creating new file systems is possible at any time.  "
"Each <<zfs-term-dataset,_dataset_>> has properties including features like "
"compression, deduplication, caching, and quotas, as well as other useful "
"properties like readonly, case sensitivity, network file sharing, and a "
"mount point.  Nesting datasets within each other is possible and child "
"datasets will inherit properties from their ancestors.  <<zfs-zfs-allow,"
"Delegate>>, <<zfs-zfs-send,replicate>>, <<zfs-zfs-snapshot,snapshot>>, <<zfs-"
"zfs-jail,jail>> allows administering and destroying each dataset as a unit.  "
"Creating a separate dataset for each different type or set of files has "
"advantages.  The drawbacks to having a large number of datasets are that "
"some commands like `zfs list` will be slower, and that mounting of hundreds "
"or even thousands of datasets will slow the FreeBSD boot process."
msgstr ""
"不同于传统的磁盘与磁盘区管理程序（Volume manager），在 <acronym>ZFS</"
"acronym> 中的空间并<emphasis>不</emphasis>会预先分配。传统的文件系统在分割与"
"分配空间完后，若没有增加新的磁盘便无法再增加额外的文件系统。在 <acronym>ZFS</"
"acronym>，可以随时建立新的文件系统，每个数据集（<link linkend=\"zfs-term-"
"dataset\"><emphasis>Dataset</emphasis></link>）都有自己的属性，包含压缩"
"（Compression）、去重复（Deduplication）、快取（Caching）与配额（Quota）功能"
"以及其他有用的属性如只读（Readonly）、区分大小写（Case sensitivity）、网路文"
"件分享（Network file sharing）以及挂载点（Mount point）。数据集可以存在于其他"
"数据集中，且子数据集会继承其父数据集的属性。每个数据集都可以作为一个单位来管"
"理、委托（<link linkend=\"zfs-zfs-allow\">Delegate</link>）、备份（<link "
"linkend=\"zfs-zfs-send\">Replicate</link>）、快照（<link linkend=\"zfs-zfs-"
"snapshot\">Snapshot</link>）、监禁（<link linkend=\"zfs-zfs-jail\">Jail</"
"link>） 与摧毁（Destroy），替每种不同类型或集合的文件建立各别的数据集还有许多"
"的好处。唯一的缺点是在当有非常大数量的数据集时，部份指令例如 <command>zfs "
"list</command> 会变的较缓慢，且挂载上百个或其至上千个数据集可能会使 FreeBSD "
"的开机程序变慢。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1473
msgid ""
"Create a new dataset and enable <<zfs-term-compression-lz4,LZ4 compression>> "
"on it:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1508
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                  USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                781M  93.2G   144K  none\n"
"mypool/ROOT           777M  93.2G   144K  none\n"
"mypool/ROOT/default   777M  93.2G   777M  /\n"
"mypool/tmp            176K  93.2G   176K  /tmp\n"
"mypool/usr            616K  93.2G   144K  /usr\n"
"mypool/usr/home       184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports      144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src        144K  93.2G   144K  /usr/src\n"
"mypool/var           1.20M  93.2G   608K  /var\n"
"mypool/var/crash      148K  93.2G   148K  /var/crash\n"
"mypool/var/log        178K  93.2G   178K  /var/log\n"
"mypool/var/mail       144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp        152K  93.2G   152K  /var/tmp\n"
"# zfs create -o compress=lz4 mypool/usr/mydataset\n"
"# zfs list\n"
"NAME                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                 781M  93.2G   144K  none\n"
"mypool/ROOT            777M  93.2G   144K  none\n"
"mypool/ROOT/default    777M  93.2G   777M  /\n"
"mypool/tmp             176K  93.2G   176K  /tmp\n"
"mypool/usr             704K  93.2G   144K  /usr\n"
"mypool/usr/home        184K  93.2G   184K  /usr/home\n"
"mypool/usr/mydataset  87.5K  93.2G  87.5K  /usr/mydataset\n"
"mypool/usr/ports       144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src         144K  93.2G   144K  /usr/src\n"
"mypool/var            1.20M  93.2G   610K  /var\n"
"mypool/var/crash       148K  93.2G   148K  /var/crash\n"
"mypool/var/log         178K  93.2G   178K  /var/log\n"
"mypool/var/mail        144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp         152K  93.2G   152K  /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1511
#, fuzzy
#| msgid ""
#| "Destroying a dataset is much quicker than deleting all of the files that "
#| "reside on the dataset, as it does not involve scanning all of the files "
#| "and updating all of the corresponding metadata."
msgid ""
"Destroying a dataset is much quicker than deleting the files on the dataset, "
"as it does not involve scanning the files and updating the corresponding "
"metadata."
msgstr ""
"摧毁数据集会比删除所有在数据集上所残留的文件来的快，由于摧毁数据集并不会扫描"
"所有文件并更新所有相关的 Metadata。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1513
#, fuzzy
#| msgid "Destroy the previously-created dataset:"
msgid "Destroy the created dataset:"
msgstr "删除先前建立的数据集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1548
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                 880M  93.1G   144K  none\n"
"mypool/ROOT            777M  93.1G   144K  none\n"
"mypool/ROOT/default    777M  93.1G   777M  /\n"
"mypool/tmp             176K  93.1G   176K  /tmp\n"
"mypool/usr             101M  93.1G   144K  /usr\n"
"mypool/usr/home        184K  93.1G   184K  /usr/home\n"
"mypool/usr/mydataset   100M  93.1G   100M  /usr/mydataset\n"
"mypool/usr/ports       144K  93.1G   144K  /usr/ports\n"
"mypool/usr/src         144K  93.1G   144K  /usr/src\n"
"mypool/var            1.20M  93.1G   610K  /var\n"
"mypool/var/crash       148K  93.1G   148K  /var/crash\n"
"mypool/var/log         178K  93.1G   178K  /var/log\n"
"mypool/var/mail        144K  93.1G   144K  /var/mail\n"
"mypool/var/tmp         152K  93.1G   152K  /var/tmp\n"
"# zfs destroy mypool/usr/mydataset\n"
"# zfs list\n"
"NAME                  USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                781M  93.2G   144K  none\n"
"mypool/ROOT           777M  93.2G   144K  none\n"
"mypool/ROOT/default   777M  93.2G   777M  /\n"
"mypool/tmp            176K  93.2G   176K  /tmp\n"
"mypool/usr            616K  93.2G   144K  /usr\n"
"mypool/usr/home       184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports      144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src        144K  93.2G   144K  /usr/src\n"
"mypool/var           1.21M  93.2G   612K  /var\n"
"mypool/var/crash      148K  93.2G   148K  /var/crash\n"
"mypool/var/log        178K  93.2G   178K  /var/log\n"
"mypool/var/mail       144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp        152K  93.2G   152K  /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1556
msgid ""
"In modern versions of ZFS, `zfs destroy` is asynchronous, and the free space "
"might take minutes to appear in the pool.  Use `zpool get freeing "
"_poolname_` to see the `freeing` property, that shows which datasets are "
"having their blocks freed in the background.  If there are child datasets, "
"like <<zfs-term-snapshot,snapshots>> or other datasets, destroying the "
"parent is impossible.  To destroy a dataset and its children, use `-r` to "
"recursively destroy the dataset and its children.  Use `-n -v` to list "
"datasets and snapshots destroyed by this operation, without actually destroy "
"anything.  Space reclaimed by destroying snapshots is also shown."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1558
#, no-wrap
msgid "Creating and Destroying Volumes"
msgstr "创建与删除卷"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1563
msgid ""
"A volume is a special dataset type.  Rather than mounting as a file system, "
"expose it as a block device under [.filename]#/dev/zvol/poolname/dataset#.  "
"This allows using the volume for other file systems, to back the disks of a "
"virtual machine, or to make it available to other network hosts using "
"protocols like iSCSI or HAST."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1568
msgid ""
"Format a volume with any file system or without a file system to store raw "
"data.  To the user, a volume appears to be a regular disk.  Putting ordinary "
"file systems on these _zvols_ provides features that ordinary disks or file "
"systems do not have.  For example, using the compression property on a 250 "
"MB volume allows creation of a compressed FAT file system."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1582
#, no-wrap
msgid ""
"# zfs create -V 250m -o compression=on tank/fat32\n"
"# zfs list tank\n"
"NAME USED AVAIL REFER MOUNTPOINT\n"
"tank 258M  670M   31K /tank\n"
"# newfs_msdos -F32 /dev/zvol/tank/fat32\n"
"# mount -t msdosfs /dev/zvol/tank/fat32 /mnt\n"
"# df -h /mnt | grep fat32\n"
"Filesystem           Size Used Avail Capacity Mounted on\n"
"/dev/zvol/tank/fat32 249M  24k  249M     0%   /mnt\n"
"# mount | grep fat32\n"
"/dev/zvol/tank/fat32 on /mnt (msdosfs, local)\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1586
#, fuzzy
#| msgid ""
#| "Destroying a volume is much the same as destroying a regular file system "
#| "dataset. The operation is nearly instantaneous, but it may take several "
#| "minutes for the free space to be reclaimed in the background."
msgid ""
"Destroying a volume is much the same as destroying a regular file system "
"dataset.  The operation is nearly instantaneous, but it may take minutes to "
"reclaim the free space in the background."
msgstr ""
"摧毁一个磁盘区与摧毁一个一般的文件系统数据集差不多。操作上几乎是即时的，但在"
"背景会需要花费数分钟来让摧毁一个磁盘区与摧毁一个一般的文件系统数据集差不多。"
"操作上几乎是即时的，但在背景会需要花费数分钟来让释放空间再次可用。释放空间再"
"次可用。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1588
#, no-wrap
msgid "Renaming a Dataset"
msgstr "重命名数据集"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1595
#, fuzzy
msgid ""
"To change the name of a dataset, use `zfs rename`.  To change the parent of "
"a dataset, use this command as well.  Renaming a dataset to have a different "
"parent dataset will change the value of those properties inherited from the "
"parent dataset.  Renaming a dataset unmounts then remounts it in the new "
"location (inherited from the new parent dataset).  To prevent this behavior, "
"use `-u`."
msgstr ""
"数据集的名称可以使用 <command>zfs rename</command> 更改。父数据集也同样可以使"
"用这个指令来更改名称。重新命名一个数据集到另一个父数据集也会更改自父数据集继"
"承的属性值。重新命名数据集后，会被卸载然后重新挂载到新的位置（依继承的新父数"
"据集而定，可使用 <option>-u</option> 来避免重新挂载。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1597
msgid "Rename a dataset and move it to be under a different parent dataset:"
msgstr "重新命名一个数据集并移动该数据集到另一个父数据集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1633
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                 780M  93.2G   144K  none\n"
"mypool/ROOT            777M  93.2G   144K  none\n"
"mypool/ROOT/default    777M  93.2G   777M  /\n"
"mypool/tmp             176K  93.2G   176K  /tmp\n"
"mypool/usr             704K  93.2G   144K  /usr\n"
"mypool/usr/home        184K  93.2G   184K  /usr/home\n"
"mypool/usr/mydataset  87.5K  93.2G  87.5K  /usr/mydataset\n"
"mypool/usr/ports       144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src         144K  93.2G   144K  /usr/src\n"
"mypool/var            1.21M  93.2G   614K  /var\n"
"mypool/var/crash       148K  93.2G   148K  /var/crash\n"
"mypool/var/log         178K  93.2G   178K  /var/log\n"
"mypool/var/mail        144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp         152K  93.2G   152K  /var/tmp\n"
"# zfs rename mypool/usr/mydataset mypool/var/newname\n"
"# zfs list\n"
"NAME                  USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                780M  93.2G   144K  none\n"
"mypool/ROOT           777M  93.2G   144K  none\n"
"mypool/ROOT/default   777M  93.2G   777M  /\n"
"mypool/tmp            176K  93.2G   176K  /tmp\n"
"mypool/usr            616K  93.2G   144K  /usr\n"
"mypool/usr/home       184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports      144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src        144K  93.2G   144K  /usr/src\n"
"mypool/var           1.29M  93.2G   614K  /var\n"
"mypool/var/crash      148K  93.2G   148K  /var/crash\n"
"mypool/var/log        178K  93.2G   178K  /var/log\n"
"mypool/var/mail       144K  93.2G   144K  /var/mail\n"
"mypool/var/newname   87.5K  93.2G  87.5K  /var/newname\n"
"mypool/var/tmp        152K  93.2G   152K  /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1638
msgid ""
"Renaming snapshots uses the same command.  Due to the nature of snapshots, "
"rename cannot change their parent dataset.  To rename a recursive snapshot, "
"specify `-r`; this will also rename all snapshots with the same name in "
"child datasets."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1648
#, no-wrap
msgid ""
"# zfs list -t snapshot\n"
"NAME                                USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/newname@first_snapshot      0      -  87.5K  -\n"
"# zfs rename mypool/var/newname@first_snapshot new_snapshot_name\n"
"# zfs list -t snapshot\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/newname@new_snapshot_name      0      -  87.5K  -\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1651
#, no-wrap
msgid "Setting Dataset Properties"
msgstr "设定数据集属性"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1661
msgid ""
"Each ZFS dataset has properties that control its behavior.  Most properties "
"are automatically inherited from the parent dataset, but can be overridden "
"locally.  Set a property on a dataset with `zfs set _property=value "
"dataset_`.  Most properties have a limited set of valid values, `zfs get` "
"will display each possible property and valid values.  Using `zfs inherit` "
"reverts most properties to their inherited values.  User-defined properties "
"are also possible.  They become part of the dataset configuration and "
"provide further information about the dataset or its contents.  To "
"distinguish these custom properties from the ones supplied as part of ZFS, "
"use a colon (`:`) to create a custom namespace for the property."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1668
#, no-wrap
msgid ""
"# zfs set custom:costcenter=1234 tank\n"
"# zfs get custom:costcenter tank\n"
"NAME PROPERTY           VALUE SOURCE\n"
"tank custom:costcenter  1234  local\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1672
msgid ""
"To remove a custom property, use `zfs inherit` with `-r`.  If the custom "
"property is not defined in any of the parent datasets, this option removes "
"it (but the pool's history still records the change)."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1681
#, no-wrap
msgid ""
"# zfs inherit -r custom:costcenter tank\n"
"# zfs get custom:costcenter tank\n"
"NAME    PROPERTY           VALUE              SOURCE\n"
"tank    custom:costcenter  -                  -\n"
"# zfs get all tank | grep custom:costcenter\n"
"#\n"
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1684
#, no-wrap
msgid "Getting and Setting Share Properties"
msgstr "取得与设定共享属性"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1690
msgid ""
"Two commonly used and useful dataset properties are the NFS and SMB share "
"options.  Setting these defines if and how ZFS shares datasets on the "
"network.  At present, FreeBSD supports setting NFS sharing alone.  To get "
"the current status of a share, enter:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1699
#, no-wrap
msgid ""
"# zfs get sharenfs mypool/usr/home\n"
"NAME             PROPERTY  VALUE    SOURCE\n"
"mypool/usr/home  sharenfs  on       local\n"
"# zfs get sharesmb mypool/usr/home\n"
"NAME             PROPERTY  VALUE    SOURCE\n"
"mypool/usr/home  sharesmb  off      local\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1702
msgid "To enable sharing of a dataset, enter:"
msgstr "开启文件共享，输入："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1706
#, no-wrap
msgid "#  zfs set sharenfs=on mypool/usr/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1710
msgid ""
"Set other options for sharing datasets through NFS, such as `-alldirs`, `-"
"maproot` and `-network`.  To set options on a dataset shared through NFS, "
"enter:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1714
#, no-wrap
msgid "#  zfs set sharenfs=\"-alldirs,-maproot=root,-network=192.168.1.0/24\" mypool/usr/home\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1717
#, no-wrap
msgid "Managing Snapshots"
msgstr "管理快照（Snapshot）"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1731
#, fuzzy
msgid ""
"<<zfs-term-snapshot,Snapshots>> are one of the most powerful features of "
"ZFS.  A snapshot provides a read-only, point-in-time copy of the dataset.  "
"With Copy-On-Write (COW), ZFS creates snapshots fast by preserving older "
"versions of the data on disk.  If no snapshots exist, ZFS reclaims space for "
"future use when data is rewritten or deleted.  Snapshots preserve disk space "
"by recording just the differences between the current dataset and a previous "
"version.  Allowing snapshots on whole datasets, not on individual files or "
"directories.  A snapshot from a dataset duplicates everything contained in "
"it.  This includes the file system properties, files, directories, "
"permissions, and so on.  Snapshots use no extra space when first created, "
"but consume space as the blocks they reference change.  Recursive snapshots "
"taken with `-r` create snapshots with the same name on the dataset and its "
"children, providing a consistent moment-in-time snapshot of the file "
"systems.  This can be important when an application has files on related "
"datasets or that depend upon each other.  Without snapshots, a backup would "
"have copies of the files from different points in time."
msgstr ""
"快照（<link linkend=\"zfs-term-snapshot\">Snapshot</link>）是 <acronym>ZFS</"
"acronym> 最强大的功能之一，快照提供了数据集只读、单一时间点(Point-in-Time）的"
"复制功能，使用了写入时复制（Copy-On-Write, <acronym>COW</acronym>）的技术，可"
"以透过保存在磁盘上的旧版资料快速的建立快照。若没有快照存在，在资料被覆盖或删"
"除时，便回收空间供未来使用。由于只记录前一个版本与目前数据集的差异，因此快照"
"可节省磁盘空间。快照只允许在整个数据集上使用，无法在各别文件或目录。当建立了"
"一个数据集的快照时，便备份了所有内含的资料，这包含了文件系统属性、文件、目"
"录、权限等等。第一次建立快照时只会使用到更改参照到资料区块的空间，不会用到其"
"他额外的空间.使用 <option>-r</option> 可以对使用同名的数据集及其所有子数据集"
"的建立一个递回快照，提供一致且即时（Moment-in-time）的完整文件系统快照功能，"
"这对于那些彼此有相关或相依文件存放在不同数据集的应用程序非常重要。不使用快照"
"所备份的资料其实是分散不同时间点的。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1740
#, fuzzy
msgid ""
"Snapshots in ZFS provide a variety of features that even other file systems "
"with snapshot functionality lack.  A typical example of snapshot use is as a "
"quick way of backing up the current state of the file system when performing "
"a risky action like a software installation or a system upgrade.  If the "
"action fails, rolling back to the snapshot returns the system to the same "
"state when creating the snapshot.  If the upgrade was successful, delete the "
"snapshot to free up space.  Without snapshots, a failed upgrade often "
"requires restoring backups, which is tedious, time consuming, and may "
"require downtime during which the system is unusable.  Rolling back to "
"snapshots is fast, even while the system is running in normal operation, "
"with little or no downtime.  The time savings are enormous with multi-"
"terabyte storage systems considering the time required to copy the data from "
"backup.  Snapshots are not a replacement for a complete backup of a pool, "
"but offer a quick and easy way to store a dataset copy at a specific time."
msgstr ""
"<acronym>ZFS</acronym> 中的快照提供了多种功能，即使是在其他缺乏快照功能的文件"
"系统上。一个使用快照的典型例子是在安装软体或执行系统升级这种有风险的动作时，"
"能有一个快速的方式可以备份文件系统目前的状态，若动作失败，可以使用快照还原"
"（Roll back）到与快照建立时相同的系统状态，若升级成功，便可删除快照来释放空"
"间。若没有快照功能，升级失败通常会需要使用备份来恢复（Restore）系统，而这个动"
"作非常繁琐、耗时且可能会需要停机一段时间系统无法使用。使用快照可以快速的还"
"原，即使系统正在执行一般的运作，只而要短暂或什至不需停机。能够节省大量在有数 "
"TB 的储存系统上从备份复制所需资料的时间.快照并非要用来取代存储池的完整备份，"
"但可以用在快速且简单的保存某个特定时间点的数据集。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1742
#, no-wrap
msgid "Creating Snapshots"
msgstr "创建快照"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1746
msgid ""
"To create snapshots, use `zfs snapshot _dataset_@_snapshotname_`.  Adding `-"
"r` creates a snapshot recursively, with the same name on all child datasets."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1748
msgid "Create a recursive snapshot of the entire pool:"
msgstr "建立一个整个存储池的递回快照："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1786
#, no-wrap
msgid ""
"# zfs list -t all\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                                 780M  93.2G   144K  none\n"
"mypool/ROOT                            777M  93.2G   144K  none\n"
"mypool/ROOT/default                    777M  93.2G   777M  /\n"
"mypool/tmp                             176K  93.2G   176K  /tmp\n"
"mypool/usr                             616K  93.2G   144K  /usr\n"
"mypool/usr/home                        184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports                       144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src                         144K  93.2G   144K  /usr/src\n"
"mypool/var                            1.29M  93.2G   616K  /var\n"
"mypool/var/crash                       148K  93.2G   148K  /var/crash\n"
"mypool/var/log                         178K  93.2G   178K  /var/log\n"
"mypool/var/mail                        144K  93.2G   144K  /var/mail\n"
"mypool/var/newname                    87.5K  93.2G  87.5K  /var/newname\n"
"mypool/var/newname@new_snapshot_name      0      -  87.5K  -\n"
"mypool/var/tmp                         152K  93.2G   152K  /var/tmp\n"
"# zfs snapshot -r mypool@my_recursive_snapshot\n"
"# zfs list -t snapshot\n"
"NAME                                        USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool@my_recursive_snapshot                   0      -   144K  -\n"
"mypool/ROOT@my_recursive_snapshot              0      -   144K  -\n"
"mypool/ROOT/default@my_recursive_snapshot      0      -   777M  -\n"
"mypool/tmp@my_recursive_snapshot               0      -   176K  -\n"
"mypool/usr@my_recursive_snapshot               0      -   144K  -\n"
"mypool/usr/home@my_recursive_snapshot          0      -   184K  -\n"
"mypool/usr/ports@my_recursive_snapshot         0      -   144K  -\n"
"mypool/usr/src@my_recursive_snapshot           0      -   144K  -\n"
"mypool/var@my_recursive_snapshot               0      -   616K  -\n"
"mypool/var/crash@my_recursive_snapshot         0      -   148K  -\n"
"mypool/var/log@my_recursive_snapshot           0      -   178K  -\n"
"mypool/var/mail@my_recursive_snapshot          0      -   144K  -\n"
"mypool/var/newname@new_snapshot_name           0      -  87.5K  -\n"
"mypool/var/newname@my_recursive_snapshot       0      -  87.5K  -\n"
"mypool/var/tmp@my_recursive_snapshot           0      -   152K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1791
msgid ""
"Snapshots are not shown by a normal `zfs list` operation.  To list "
"snapshots, append `-t snapshot` to `zfs list`.  `-t all` displays both file "
"systems and snapshots."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1795
#, fuzzy
msgid ""
"Snapshots are not mounted directly, showing no path in the `MOUNTPOINT` "
"column.  ZFS does not mention available disk space in the `AVAIL` column, as "
"snapshots are read-only after their creation.  Compare the snapshot to the "
"original dataset:"
msgstr ""
"快照并不会直接挂载，因此 <literal>MOUNTPOINT</literal> 栏中没有显示路径。在 "
"<literal>AVAIL</literal> 栏位不会有可用的磁盘空间，因为快照建立之后便无法再写"
"入。比较快照与其原来建立时的数据集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1802
#, no-wrap
msgid ""
"# zfs list -rt all mypool/usr/home\n"
"NAME                                    USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/usr/home                         184K  93.2G   184K  /usr/home\n"
"mypool/usr/home@my_recursive_snapshot      0      -   184K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1808
msgid ""
"Displaying both the dataset and the snapshot together reveals how snapshots "
"work in <<zfs-term-cow,COW>> fashion.  They save the changes (_delta_) made "
"and not the complete file system contents all over again.  This means that "
"snapshots take little space when making changes.  Observe space usage even "
"more by copying a file to the dataset, then creating a second snapshot:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1818
#, no-wrap
msgid ""
"# cp /etc/passwd /var/tmp\n"
"# zfs snapshot mypool/var/tmp@after_cp\n"
"# zfs list -rt all mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp                         206K  93.2G   118K  /var/tmp\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp                   0      -   118K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1823
msgid ""
"The second snapshot contains the changes to the dataset after the copy "
"operation.  This yields enormous space savings.  Notice that the size of the "
"snapshot `_mypool/var/tmp@my_recursive_snapshot_` also changed in the `USED` "
"column to show the changes between itself and the snapshot taken afterwards."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1825
#, no-wrap
msgid "Comparing Snapshots"
msgstr "对比快照"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1831
#, fuzzy
msgid ""
"ZFS provides a built-in command to compare the differences in content "
"between two snapshots.  This is helpful with a lot of snapshots taken over "
"time when the user wants to see how the file system has changed over time.  "
"For example, `zfs diff` lets a user find the latest snapshot that still "
"contains a file deleted by accident.  Doing this for the two snapshots "
"created in the previous section yields this output:"
msgstr ""
"ZFS 提供了内建指令可以用来比对两个快照（Snapshot）之间的差异，在使用者想要查"
"看一段时间之间文件系统所的变更时非常有用。例如 <command>zfs diff</command> 可"
"以让使用者在最后一次快照中找到意外删除的文件。对前面一节所做的两个快照使用这"
"个指令会产生以下结果："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1842
#, no-wrap
msgid ""
"# zfs list -rt all mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp                         206K  93.2G   118K  /var/tmp\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp                   0      -   118K  -\n"
"# zfs diff mypool/var/tmp@my_recursive_snapshot\n"
"M       /var/tmp/\n"
"+       /var/tmp/passwd\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1846
msgid ""
"The command lists the changes between the specified snapshot (in this case "
"`_mypool/var/tmp@my_recursive_snapshot_`) and the live file system.  The "
"first column shows the change type:"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1852
#, no-wrap
msgid "+"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1854
#, no-wrap
msgid "Adding the path or file."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1855
#, no-wrap
msgid "-"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1857
#, no-wrap
msgid "Deleting the path or file."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1858
#, no-wrap
msgid "M"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1860
#, no-wrap
msgid "Modifying the path or file."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1861
#, no-wrap
msgid "R"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1862
#, no-wrap
msgid "Renaming the path or file."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1867
msgid ""
"Comparing the output with the table, it becomes clear that ZFS added [."
"filename]#passwd# after creating the snapshot `_mypool/var/"
"tmp@my_recursive_snapshot_`.  This also resulted in a modification to the "
"parent directory mounted at `_/var/tmp_`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1869
msgid ""
"Comparing two snapshots is helpful when using the ZFS replication feature to "
"transfer a dataset to a different host for backup purposes."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1871
msgid ""
"Compare two snapshots by providing the full dataset name and snapshot name "
"of both datasets:"
msgstr "比对两个快照需要提供两个数据集的完整数据集名称与快照名称："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1883
#, no-wrap
msgid ""
"# cp /var/tmp/passwd /var/tmp/passwd.copy\n"
"# zfs snapshot mypool/var/tmp@diff_snapshot\n"
"# zfs diff mypool/var/tmp@my_recursive_snapshot mypool/var/tmp@diff_snapshot\n"
"M       /var/tmp/\n"
"+       /var/tmp/passwd\n"
"+       /var/tmp/passwd.copy\n"
"# zfs diff mypool/var/tmp@my_recursive_snapshot mypool/var/tmp@after_cp\n"
"M       /var/tmp/\n"
"+       /var/tmp/passwd\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1887
#, fuzzy
msgid ""
"A backup administrator can compare two snapshots received from the sending "
"host and determine the actual changes in the dataset.  See the <<zfs-zfs-"
"send,Replication>> section for more information."
msgstr ""
"备份管理员可以比较从发送主机接收到的两个快照，并确定数据集中的实际更改。有关"
"详细信息，请参阅<link linkend=\"zfs-zfs-send\">Replication</link>。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1889
#, no-wrap
msgid "Snapshot Rollback"
msgstr "使用快照还原"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1902
#, fuzzy
msgid ""
"When at least one snapshot is available, roll back to it at any time.  Most "
"often this is the case when the current state of the dataset is no longer "
"and if preferring an older version.  Scenarios such as local development "
"tests gone wrong, botched system updates hampering the system functionality, "
"or the need to restore deleted files or directories are all too common "
"occurrences.  To roll back a snapshot, use `zfs rollback _snapshotname_`.  "
"If a lot of changes are present, the operation will take a long time.  "
"During that time, the dataset always remains in a consistent state, much "
"like a database that conforms to ACID principles is performing a rollback.  "
"This is happening while the dataset is live and accessible without requiring "
"a downtime.  Once the snapshot rolled back, the dataset has the same state "
"as it had when the snapshot was originally taken.  Rolling back to a "
"snapshot discards all other data in that dataset not part of the snapshot.  "
"Taking a snapshot of the current state of the dataset before rolling back to "
"a previous one is a good idea when requiring some data later.  This way, the "
"user can roll back and forth between snapshots without losing data that is "
"still valuable."
msgstr ""
"只要至少有一个可用的快照便可以随时还原。大多数在已不需要目前数据集，想要改用"
"较旧版的资料的情况，例如，本地开发的测试发生错误、不良的系统更新破坏了系统的"
"整体功能或需要还原意外删除文件或目录。 。。 等，都是非常常见的情形。幸运的，"
"要还原到某个快照只需要简单输入 <command>zfs rollback "
"<replaceable>snapshotname</replaceable></command>。会依快照所做的变更数量来决"
"定处理的时间，还原的操作会在一段时间后完成。在这段时间中，数据集会一直保持一"
"致的状态，类似一个符合 ACID 原则的资料库在做还原。还原可在数据集处于上线及可"
"存取的情况下完成，不需要停机。还原到快照之后，数据集便回到当初执行快照时相同"
"的状态，所有没有在快照中的其他资料便会被丢弃，因此往后若还有可能需要部份资料"
"时，建议在还原到前一个快照之前先对目前的数据集做快照，这样一来，使用者便可以"
"在快照之间来回快换，而不会遗失重要的资料。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1904
msgid ""
"In the first example, roll back a snapshot because of a careless `rm` "
"operation that removes too much data than intended."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1918
#, no-wrap
msgid ""
"# zfs list -rt all mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp                         262K  93.2G   120K  /var/tmp\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp               53.5K      -   118K  -\n"
"mypool/var/tmp@diff_snapshot              0      -   120K  -\n"
"# ls /var/tmp\n"
"passwd          passwd.copy     vi.recover\n"
"# rm /var/tmp/passwd*\n"
"# ls /var/tmp\n"
"vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1923
#, fuzzy
msgid ""
"At this point, the user notices the removal of extra files and wants them "
"back.  ZFS provides an easy way to get them back using rollbacks, when "
"performing snapshots of important data on a regular basis.  To get the files "
"back and start over from the last snapshot, issue the command:"
msgstr ""
"在此时，使用者发现到删除了太多文件并希望能够还原。 <acronym>ZFS</acronym> 提"
"供了简单的方可以取回文件，便是使用还原（Rollback），但这只在有定期对重要的资"
"料使用快照时可用。要拿回文件并从最后一次快照重新开始，可执行以下指令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1929
#, no-wrap
msgid ""
"# zfs rollback mypool/var/tmp@diff_snapshot\n"
"# ls /var/tmp\n"
"passwd          passwd.copy     vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1934
#, fuzzy
msgid ""
"The rollback operation restored the dataset to the state of the last "
"snapshot.  Rolling back to a snapshot taken much earlier with other "
"snapshots taken afterwards is also possible.  When trying to do this, ZFS "
"will issue this warning:"
msgstr ""
"The rollback operation restored the dataset to the state of the last "
"snapshot. It is also possible to roll back to a snapshot that was taken much "
"earlier and has other snapshots that were created after it. When trying to "
"do this, <acronym>ZFS</acronym> will issue this warning:"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1947
#, no-wrap
msgid ""
"# zfs list -rt snapshot mypool/var/tmp\n"
"AME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp               53.5K      -   118K  -\n"
"mypool/var/tmp@diff_snapshot              0      -   120K  -\n"
"# zfs rollback mypool/var/tmp@my_recursive_snapshot\n"
"cannot rollback to 'mypool/var/tmp@my_recursive_snapshot': more recent snapshots exist\n"
"use '-r' to force deletion of the following snapshots:\n"
"mypool/var/tmp@after_cp\n"
"mypool/var/tmp@diff_snapshot\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1954
#, fuzzy
msgid ""
"This warning means that snapshots exist between the current state of the "
"dataset and the snapshot to which the user wants to roll back.  To complete "
"the rollback delete these snapshots.  ZFS cannot track all the changes "
"between different states of the dataset, because snapshots are read-only.  "
"ZFS will not delete the affected snapshots unless the user specifies `-r` to "
"confirm that this is the desired action.  If that is the intention, and "
"understanding the consequences of losing all intermediate snapshots, issue "
"the command:"
msgstr ""
"这个警告是因在该快照与数据集的目前状态之间有其他快照存在，然而使用者想要还原"
"到该快照。要完成这样的还原动作，必须删除在这之间的快照，因为 <acronym>ZFS</"
"acronym> 无法追踪不同数据集状态间的变更。在使用者未指定 <option>-r</option> "
"来确认这个动作前，<acronym>ZFS</acronym> 不会删除受影响的快照。若确定要这么"
"做，那么必须要知道会遗失所有在这之间的快照，然后可执行以下指令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1963
#, no-wrap
msgid ""
"# zfs rollback -r mypool/var/tmp@my_recursive_snapshot\n"
"# zfs list -rt snapshot mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp@my_recursive_snapshot     8K      -   152K  -\n"
"# ls /var/tmp\n"
"vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1966
msgid ""
"The output from `zfs list -t snapshot` confirms the removal of the "
"intermediate snapshots as a result of `zfs rollback -r`."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1968
#, no-wrap
msgid "Restoring Individual Files from Snapshots"
msgstr "从快照还原个别文件"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1975
#, fuzzy
msgid ""
"Snapshots live in a hidden directory under the parent dataset: [.filename]#."
"zfs/snapshots/snapshotname#.  By default, these directories will not show "
"even when executing a standard `ls -a` .  Although the directory doesn't "
"show, access it like any normal directory.  The property named `snapdir` "
"controls whether these hidden directories show up in a directory listing.  "
"Setting the property to `visible` allows them to appear in the output of "
"`ls` and other commands that deal with directory contents."
msgstr ""
"快照会挂载在父数据集下的隐藏目录：<filename>。zfs/snapshots/"
"<replaceable>snapshotname</replaceable></filename>。预设不会显示这些目录，即"
"使是用 <command>ls -a</command> 指令。虽然该目录不会显示，但该目录实际存在，"
"而且可以像一般的目录一样存取。一个名称为 <literal>snapdir</literal> 的属性可"
"以控制是否在目录清单中显示这些隐藏目录，设定该属性为可见（<literal>visible</"
"literal>）可以让这些目录出现在 <command>ls </command> 以及其他处理目录内容的"
"指令中。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1986
#, no-wrap
msgid ""
"# zfs get snapdir mypool/var/tmp\n"
"NAME            PROPERTY  VALUE    SOURCE\n"
"mypool/var/tmp  snapdir   hidden   default\n"
"# ls -a /var/tmp\n"
".               ..              passwd          vi.recover\n"
"# zfs set snapdir=visible mypool/var/tmp\n"
"# ls -a /var/tmp\n"
".               ..              .zfs            passwd          vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1991
#, fuzzy
msgid ""
"Restore individual files to a previous state by copying them from the "
"snapshot back to the parent dataset.  The directory structure below [."
"filename]#.zfs/snapshot# has a directory named like the snapshots taken "
"earlier to make it easier to identify them.  The next example shows how to "
"restore a file from the hidden [.filename]#.zfs# directory by copying it "
"from the snapshot containing the latest version of the file:"
msgstr ""
"通过将单个文件从快照复制到父数据集, 可以轻松地将它们还原到以前的状态。"
"<filename>.zfs/snapshot</filename>具有与前面拍摄的快照完全相同的目录, 以便于"
"识别它们。在下一个示例中, 假定通过从包含该文件最新版本的快照复制文件来从隐藏"
"的<filename>.zfs</filename>目录还原该文件:"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2002
#, no-wrap
msgid ""
"# rm /var/tmp/passwd\n"
"# ls -a /var/tmp\n"
".               ..              .zfs            vi.recover\n"
"# ls /var/tmp/.zfs/snapshot\n"
"after_cp                my_recursive_snapshot\n"
"# ls /var/tmp/.zfs/snapshot/after_cp\n"
"passwd          vi.recover\n"
"# cp /var/tmp/.zfs/snapshot/after_cp/passwd /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2009
#, fuzzy
msgid ""
"Even if the `snapdir` property is set to hidden, running `ls .zfs/snapshot` "
"will still list the contents of that directory.  The administrator decides "
"whether to display these directories.  This is a per-dataset setting.  "
"Copying files or directories from this hidden [.filename]#.zfs/snapshot# is "
"simple enough.  Trying it the other way around results in this error:"
msgstr ""
"执行 <command>ls .zfs/snapshot</command> 时，虽然 <literal>snapdir</literal> "
"可能已经设为隐藏，但仍可能可以显示该目录中的内容，这取决于管理者是否要显示这"
"些目录，可以只显示特定的数据集，而其他的则不显示。从这个隐藏的 <filename>。"
"zfs/snapshot</filename> 复制文件或目录非常简单，除此之外，尝试其他的动作则会"
"出现以下错误："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2014
#, no-wrap
msgid ""
"# cp /etc/rc.conf /var/tmp/.zfs/snapshot/after_cp/\n"
"cp: /var/tmp/.zfs/snapshot/after_cp/rc.conf: Read-only file system\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2018
#, fuzzy
#| msgid ""
#| "The error reminds the user that snapshots are read-only and cannot be "
#| "changed after creation. Files cannot be copied into or removed from "
#| "snapshot directories because that would change the state of the dataset "
#| "they represent."
msgid ""
"The error reminds the user that snapshots are read-only and cannot change "
"after creation.  Copying files into and removing them from snapshot "
"directories are both disallowed because that would change the state of the "
"dataset they represent."
msgstr ""
"这个错误用来提醒使用者快照是只读的，在建立之后不能更改。无法复制文件进去或从"
"该快照目录中移除，因为这会变更该数据集所代表的状态。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2021
msgid ""
"Snapshots consume space based on how much the parent file system has changed "
"since the time of the snapshot.  The `written` property of a snapshot tracks "
"the space the snapshot uses."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2025
msgid ""
"To destroy snapshots and reclaim the space, use `zfs destroy "
"_dataset_@_snapshot_`.  Adding `-r` recursively removes all snapshots with "
"the same name under the parent dataset.  Adding `-n -v` to the command "
"displays a list of the snapshots to be deleted and an estimate of the space "
"it would reclaim without performing the actual destroy operation."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2027
#, no-wrap
msgid "Managing Clones"
msgstr "管理副本"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2036
#, fuzzy
msgid ""
"A clone is a copy of a snapshot treated more like a regular dataset.  Unlike "
"a snapshot, a clone is writeable and mountable, and has its own properties.  "
"After creating a clone using `zfs clone`, destroying the originating "
"snapshot is impossible.  To reverse the child/parent relationship between "
"the clone and the snapshot use `zfs promote`.  Promoting a clone makes the "
"snapshot become a child of the clone, rather than of the original parent "
"dataset.  This will change how ZFS accounts for the space, but not actually "
"change the amount of space consumed.  Mounting the clone anywhere within the "
"ZFS file system hierarchy is possible, not only below the original location "
"of the snapshot."
msgstr ""
"复本（Clone）是快照的复制，但更像是一般的数据集，与快照不同的是，复本是非只读"
"的（可写），且可挂载，可以有自己的属性。使用 <command>zfs clone</command> 建"
"立复本之后，便无法再摧毁用来建立复本的快照。复本与快照的父/子关系可以使用 "
"<command>zfs promote</command> 来对换。提升复本之后 ，快照便会成为复本的子数"
"据集，而不是原来的父数据集，这个动作会改变空间计算的方式，但并不会实际改变空"
"间的使用量。复本可以被挂载到 <acronym>ZFS</acronym> 文件系统阶层中的任何一"
"点，并非只能位于原来快照的位置底下。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2038
#, fuzzy
#| msgid "To demonstrate the clone feature, this example dataset is used:"
msgid "To show the clone feature use this example dataset:"
msgstr "要示范复本功能会用到这个范例数据集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2046
#, no-wrap
msgid ""
"# zfs list -rt all camino/home/joe\n"
"NAME                    USED  AVAIL  REFER  MOUNTPOINT\n"
"camino/home/joe         108K   1.3G    87K  /usr/home/joe\n"
"camino/home/joe@plans    21K      -  85.5K  -\n"
"camino/home/joe@backup    0K      -    87K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2052
#, fuzzy
#| msgid ""
#| "A typical use for clones is to experiment with a specific dataset while "
#| "keeping the snapshot around to fall back to in case something goes wrong. "
#| "Since snapshots cannot be changed, a read/write clone of a snapshot is "
#| "created. After the desired result is achieved in the clone, the clone can "
#| "be promoted to a dataset and the old file system removed. This is not "
#| "strictly necessary, as the clone and dataset can coexist without problems."
msgid ""
"A typical use for clones is to experiment with a specific dataset while "
"keeping the snapshot around to fall back to in case something goes wrong.  "
"Since snapshots cannot change, create a read/write clone of a snapshot.  "
"After achieving the desired result in the clone, promote the clone to a "
"dataset and remove the old file system.  Removing the parent dataset is not "
"strictly necessary, as the clone and dataset can coexist without problems."
msgstr ""
"会使用到复本一般是要在可以保留快照以便出错时可还原的情况下使用指定的数据集做"
"实验，由于快照并无法做更改，所以会建立一个可以读/写的快照复本。当在复本中做完"
"想要执行的动作后，便可以提升复本成数据集，然后移除旧的文件系统。严格来说这并"
"非必要，因为复本与数据集可同时存在，不会有任何问题。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2059
#, no-wrap
msgid ""
"# zfs clone camino/home/joe@backup camino/home/joenew\n"
"# ls /usr/home/joe*\n"
"/usr/home/joe:\n"
"backup.txz     plans.txt\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2066
#, no-wrap
msgid ""
"/usr/home/joenew:\n"
"backup.txz     plans.txt\n"
"# df -h /usr/home\n"
"Filesystem          Size    Used   Avail Capacity  Mounted on\n"
"usr/home/joe        1.3G     31k    1.3G     0%    /usr/home/joe\n"
"usr/home/joenew     1.3G     31k    1.3G     0%    /usr/home/joenew\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2075
msgid ""
"Creating a clone makes it an exact copy of the state the dataset as it was "
"when taking the snapshot.  Changing the clone independently from its "
"originating dataset is possible now.  The connection between the two is the "
"snapshot.  ZFS records this connection in the property `origin`.  Promoting "
"the clone with `zfs promote` makes the clone an independent dataset.  This "
"removes the value of the `origin` property and disconnects the newly "
"independent dataset from the snapshot.  This example shows it:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2085
#, no-wrap
msgid ""
"# zfs get origin camino/home/joenew\n"
"NAME                  PROPERTY  VALUE                     SOURCE\n"
"camino/home/joenew    origin    camino/home/joe@backup    -\n"
"# zfs promote camino/home/joenew\n"
"# zfs get origin camino/home/joenew\n"
"NAME                  PROPERTY  VALUE   SOURCE\n"
"camino/home/joenew    origin    -       -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2090
#, fuzzy
msgid ""
"After making some changes like copying [.filename]#loader.conf# to the "
"promoted clone, for example, the old directory becomes obsolete in this "
"case.  Instead, the promoted clone can replace it.  To do this, `zfs "
"destroy` the old dataset first and then `zfs rename` the clone to the old "
"dataset name (or to an entirely different name)."
msgstr ""
"做为部份更改之后，例如复制 <filename>loader.conf</filename> 到提升后的复本，"
"这个例子中的旧目录便无须保留，取而代之的是提升后的复本，这个动作可以用两个连"
"续的指令来完成：在旧数据集上执行 <command>zfs destroy</command> 并在与旧资料"
"相似名称(也可能用完全不同的名称）的复本上执行 <command>zfs rename</command>。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2101
#, no-wrap
msgid ""
"# cp /boot/defaults/loader.conf /usr/home/joenew\n"
"# zfs destroy -f camino/home/joe\n"
"# zfs rename camino/home/joenew camino/home/joe\n"
"# ls /usr/home/joe\n"
"backup.txz     loader.conf     plans.txt\n"
"# df -h /usr/home\n"
"Filesystem          Size    Used   Avail Capacity  Mounted on\n"
"usr/home/joe        1.3G    128k    1.3G     0%    /usr/home/joe\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2110
#, fuzzy
msgid ""
"The cloned snapshot is now an ordinary dataset.  It contains all the data "
"from the original snapshot plus the files added to it like [."
"filename]#loader.conf#.  Clones provide useful features to ZFS users in "
"different scenarios.  For example, provide jails as snapshots containing "
"different sets of installed applications.  Users can clone these snapshots "
"and add their own applications as they see fit.  Once satisfied with the "
"changes, promote the clones to full datasets and provide them to end users "
"to work with like they would with a real dataset.  This saves time and "
"administrative overhead when providing these jails."
msgstr ""
"快照的复本现在可以如同一般数据集一样使用，它的内容包含了所有来自原始快照的资"
"料以及后来加入的文件，例如 <filename>loader.conf</filename>。复本可以在许多不"
"同的情境下使用提供ZFS 的使用者有用的功能，例如，Jail 可以透过含有已安装了各种"
"应用程序集的快照来提供，使用者可以复制这些快照然后加入自己想要尝试的应用程"
"序，一但更改可以满足需求，便可提升复本为完整的数据集然后提供给终端使用者，让"
"终端使用者可以如同实际拥有数据集一般的使用，这个以节省提供这些Jail 的时间与管"
"理成本。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2112
#, no-wrap
msgid "Replication"
msgstr "备份"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2120
#, fuzzy
msgid ""
"Keeping data on a single pool in one location exposes it to risks like theft "
"and natural or human disasters.  Making regular backups of the entire pool "
"is vital.  ZFS provides a built-in serialization feature that can send a "
"stream representation of the data to standard output.  Using this feature, "
"storing this data on another pool connected to the local system is possible, "
"as is sending it over a network to another system.  Snapshots are the basis "
"for this replication (see the section on <<zfs-zfs-snapshot,ZFS "
"snapshots>>).  The commands used for replicating data are `zfs send` and "
"`zfs receive`."
msgstr ""
"将资料保存在单一地点的单一存储池上会让资料暴露在盗窃、自然或人为的风险之下，"
"定期备份整个存储池非常重要，<acronym>ZFS</acronym> 提供了内建的序列化"
"（Serialization）功能可以将资料以串流传送到标准输出。使用这项技术，不仅可以将"
"资料储存到另一个已连结到本地系统的存储池，也可以透过网路将资料传送到另一个系"
"统，这种备份方式以快照为基础（请参考章节<link linkend =\"zfs-zfs-snapshot"
"\"><acronym>ZFS</acronym> 快照（Snapshot）</link>）。用来备份资料的指令为 "
"<command>zfs send</command> 及 <command>zfs receive</command>。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2122
msgid "These examples show ZFS replication with these two pools:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2129
#, no-wrap
msgid ""
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M    77K   896M         -         -     0%    0%  1.00x  ONLINE  -\n"
"mypool  984M  43.7M   940M         -         -     0%    4%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2137
#, fuzzy
msgid ""
"The pool named _mypool_ is the primary pool where writing and reading data "
"happens on a regular basis.  Using a second standby pool _backup_ in case "
"the primary pool becomes unavailable.  Note that this fail-over is not done "
"automatically by ZFS, but must be manually done by a system administrator "
"when needed.  Use a snapshot to provide a consistent file system version to "
"replicate.  After creating a snapshot of _mypool_, copy it to the _backup_ "
"pool by replicating snapshots.  This does not include changes made since the "
"most recent snapshot."
msgstr ""
"名为 <replaceable>mypool</replaceable> 的存储池为主要的存储池，资料会定期写入"
"与读取的位置。第二个存储池 <replaceable>backup</replaceable> 用来待命"
"（Standby），万一主要存储池无法使用时可替换。注意，<acronym>ZFS</acronym> 并"
"不会自动做容错移转（Fail-over），必须要由系统管理者在需要的时候手动完成。快照"
"会用来提供一个与档系统一致的版本来做备份，<replaceable>mypool</replaceable> "
"的快照建立之后，便可以复制到 <replaceable>backup</replaceable> 存储池，只有快"
"照可以做备份，最近一次快照之后所做的变更不会含在内容里面。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2144
#, no-wrap
msgid ""
"# zfs snapshot mypool@backup1\n"
"# zfs list -t snapshot\n"
"NAME                    USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool@backup1             0      -  43.6M  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2149
#, fuzzy
msgid ""
"Now that a snapshot exists, use `zfs send` to create a stream representing "
"the contents of the snapshot.  Store this stream as a file or receive it on "
"another pool.  Write the stream to standard output, but redirect to a file "
"or pipe or an error appears:"
msgstr ""
"快照存在以后，便可以使用 <command>zfs send</command> 来建立一个代表快照内容的"
"串流，这个串流可以储存成文件或由其他存储池接收。串流会写入到标准输出，但是必"
"须要重新导向到一个文件或转接到其他地方，否则会错误："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2155
#, no-wrap
msgid ""
"# zfs send mypool@backup1\n"
"Error: Stream can not be written to a terminal.\n"
"You must redirect standard output.\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2159
#, fuzzy
msgid ""
"To back up a dataset with `zfs send`, redirect to a file located on the "
"mounted backup pool.  Ensure that the pool has enough free space to "
"accommodate the size of the sent snapshot, which means the data contained in "
"the snapshot, not the changes from the previous snapshot."
msgstr ""
"To back up a dataset with <command>zfs send</command>, redirect to a file "
"located on the mounted backup pool. Ensure that the pool has enough free "
"space to accommodate the size of the snapshot being sent, which means all of "
"the data contained in the snapshot, not just the changes from the previous "
"snapshot."

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2167
#, no-wrap
msgid ""
"# zfs send mypool@backup1 > /backup/backup1\n"
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  63.7M   896M         -         -     0%     6%  1.00x  ONLINE  -\n"
"mypool  984M  43.7M   940M         -         -     0%     4%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2171
msgid ""
"The `zfs send` transferred all the data in the snapshot called _backup1_ to "
"the pool named _backup_.  To create and send these snapshots automatically, "
"use a man:cron[8] job."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2177
#, fuzzy
msgid ""
"Instead of storing the backups as archive files, ZFS can receive them as a "
"live file system, allowing direct access to the backed up data.  To get to "
"the actual data contained in those streams, use `zfs receive` to transform "
"the streams back into files and directories.  The example below combines "
"`zfs send` and `zfs receive` using a pipe to copy the data from one pool to "
"another.  Use the data directly on the receiving pool after the transfer is "
"complete.  It is only possible to replicate a dataset to an empty dataset."
msgstr ""
"若不想将备份以封存文件储存，<acronym>ZFS</acronym> 可用实际的文件系统来接收资"
"料，让备份的资料可以直接被存取。要取得实际包含在串流中的资料可以用 "
"<command>zfs receive</command> 将串流转换回文件与目录。以下例子会以管线符号连"
"接 <command>zfs send</command> 及 <command>zfs receive</command>，将资料从一"
"个存储池复制到另一个，传输完成后可以直接使用接收存储池上的资料。一个数据集只"
"可以被复制到另一个空的数据集。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2185
#, no-wrap
msgid ""
"# zfs snapshot mypool@replica1\n"
"# zfs send -v mypool@replica1 | zfs receive backup/mypool\n"
"send from @ to mypool@replica1 estimated size is 50.1M\n"
"total estimated size is 50.1M\n"
"TIME        SENT   SNAPSHOT\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2190
#, no-wrap
msgid ""
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  63.7M   896M         -         -     0%     6%  1.00x  ONLINE  -\n"
"mypool  984M  43.7M   940M         -         -     0%     4%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2193
#, no-wrap
msgid "Incremental Backups"
msgstr "增量备份"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2198
#, fuzzy
msgid ""
"`zfs send` can also determine the difference between two snapshots and send "
"individual differences between the two.  This saves disk space and transfer "
"time.  For example:"
msgstr ""
"<command>zfs send</command> 也可以比较两个快照之间的差异，并且只传送两者之间"
"的差异，这么做可以节省磁盘空间及传输时间。例如："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2210
#, no-wrap
msgid ""
"# zfs snapshot mypool@replica2\n"
"# zfs list -t snapshot\n"
"NAME                    USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool@replica1         5.72M      -  43.6M  -\n"
"mypool@replica2             0      -  44.1M  -\n"
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  61.7M   898M         -         -     0%    6%  1.00x  ONLINE  -\n"
"mypool  960M  50.2M   910M         -         -     0%    5%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2216
#, fuzzy
msgid ""
"Create a second snapshot called _replica2_.  This second snapshot contains "
"changes made to the file system between now and the previous snapshot, "
"_replica1_.  Using `zfs send -i` and indicating the pair of snapshots "
"generates an incremental replica stream containing the changed data.  This "
"succeeds if the initial snapshot already exists on the receiving side."
msgstr ""
"会建立一个名为 <replaceable>replica2</replaceable> 的第二个快照，这个快照只中"
"只会含有目前与前次快照 <replaceable>replica1</replaceable> 之间文件系统所做的"
"变更。使用 <command>zfs send -i</command> 并指定要用来产生渐进备份串流的快"
"照，串流中只会含有做过更改的资料。这个动作只在接收端已经有初始快照时才可用。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2223
#, no-wrap
msgid ""
"# zfs send -v -i mypool@replica1 mypool@replica2 | zfs receive /backup/mypool\n"
"send from @replica1 to mypool@replica2 estimated size is 5.02M\n"
"total estimated size is 5.02M\n"
"TIME        SENT   SNAPSHOT\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2228
#, no-wrap
msgid ""
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG  CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  80.8M   879M         -         -     0%   8%  1.00x  ONLINE  -\n"
"mypool  960M  50.2M   910M         -         -     0%   5%  1.00x  ONLINE  -\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2234
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                         USED  AVAIL  REFER  MOUNTPOINT\n"
"backup                      55.4M   240G   152K  /backup\n"
"backup/mypool               55.3M   240G  55.2M  /backup/mypool\n"
"mypool                      55.6M  11.6G  55.0M  /mypool\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2241
#, no-wrap
msgid ""
"# zfs list -t snapshot\n"
"NAME                                         USED  AVAIL  REFER  MOUNTPOINT\n"
"backup/mypool@replica1                       104K      -  50.2M  -\n"
"backup/mypool@replica2                          0      -  55.2M  -\n"
"mypool@replica1                             29.9K      -  50.0M  -\n"
"mypool@replica2                                 0      -  55.0M  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2246
#, fuzzy
msgid ""
"The incremental stream replicated the changed data rather than the entirety "
"of _replica1_.  Sending the differences alone took much less time to "
"transfer and saved disk space by not copying the whole pool each time.  This "
"is useful when replicating over a slow network or one charging per "
"transferred byte."
msgstr ""
"如此一来，便成功传输渐进式的串流，只有做过更改的资料会被备份，不会传送完整的 "
"<replaceable>replica1</replaceable>。由于不会备份完整的存储池，只传送差异的部"
"份，所以可以减少传输的时间并节省磁盘空间，特别是在网路缓慢或需要考量每位元传"
"输成本时非常有用。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2251
#, fuzzy
msgid ""
"A new file system, _backup/mypool_, is available with the files and data "
"from the pool _mypool_.  Specifying `-p` copies the dataset properties "
"including compression settings, quotas, and mount points.  Specifying `-R` "
"copies all child datasets of the dataset along with their properties.  "
"Automate sending and receiving to create regular backups on the second pool."
msgstr ""
"从存储池 <replaceable>mypool</replaceable> 复制所有文件与资料的新文件系统 "
"<replaceable>backup/mypool</replaceable> 便可以使用。若指定 <option>-P</"
"option>，会一并复制数据集的属性，这包含压缩（Compression）设定，配额（Quota）"
"及挂载点（Mount point）若指定 <option>-R</option>，会复制所有指定数据集的子数"
"据集，及这些子数据集的所有属性。可将传送与接收自动化来定期使用第二个存储池做"
"备份。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2253
#, no-wrap
msgid "Sending Encrypted Backups over SSH"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2261
msgid ""
"Sending streams over the network is a good way to keep a remote backup, but "
"it does come with a drawback.  Data sent over the network link is not "
"encrypted, allowing anyone to intercept and transform the streams back into "
"data without the knowledge of the sending user.  This is undesirable when "
"sending the streams over the internet to a remote host.  Use SSH to securely "
"encrypt data sent over a network connection.  Since ZFS requires redirecting "
"the stream from standard output, piping it through SSH is easy.  To keep the "
"contents of the file system encrypted in transit and on the remote system, "
"consider using https://wiki.freebsd.org/PEFS[PEFS]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2264
msgid ""
"Change some settings and take security precautions first.  This describes "
"the necessary steps required for the `zfs send` operation; for more "
"information on SSH, see crossref:security[openssh,\"OpenSSH\"]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2266
msgid "Change the configuration as follows:"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2268
msgid ""
"Passwordless SSH access between sending and receiving host using SSH keys"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2269
msgid ""
"ZFS requires the privileges of the `root` user to send and receive streams. "
"This requires logging in to the receiving system as `root`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2270
msgid "Security reasons prevent `root` from logging in by default."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2272
msgid ""
"Use the <<zfs-zfs-allow,ZFS Delegation>> system to allow a non-`root` user "
"on each system to perform the respective send and receive operations.  On "
"the sending system:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2276
#, no-wrap
msgid "# zfs allow -u someuser send,snapshot mypool\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2279
#, fuzzy
#| msgid ""
#| "To mount the pool, the unprivileged user must own the directory, and "
#| "regular users must be allowed to mount file systems. On the receiving "
#| "system:"
msgid ""
"To mount the pool, the unprivileged user must own the directory, and regular "
"users need permission to mount file systems."
msgstr ""
"要挂载存储池，无权限的使用者必须拥有该目录且必须允许一般的使用者挂载文件系"
"统。在接收端系统上："

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2281
#, fuzzy
#| msgid "On the sending system:"
msgid "On the receiving system:"
msgstr "在传送端系统上："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2290
#, no-wrap
msgid ""
"# sysctl vfs.usermount=1\n"
"vfs.usermount: 0 -> 1\n"
"# echo vfs.usermount=1 >> /etc/sysctl.conf\n"
"# zfs create recvpool/backup\n"
"# zfs allow -u someuser create,mount,receive recvpool/backup\n"
"# chown someuser /recvpool/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2293
msgid ""
"The unprivileged user can receive and mount datasets now, and replicates the "
"_home_ dataset to the remote system:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2298
#, no-wrap
msgid ""
"% zfs snapshot -r mypool/home@monday\n"
"% zfs send -R mypool/home@monday | ssh someuser@backuphost zfs recv -dvu recvpool/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2308
msgid ""
"Create a recursive snapshot called _monday_ of the file system dataset "
"_home_ on the pool _mypool_.  Then `zfs send -R` includes the dataset, all "
"child datasets, snapshots, clones, and settings in the stream.  Pipe the "
"output through SSH to the waiting `zfs receive` on the remote host "
"_backuphost_.  Using an IP address or fully qualified domain name is good "
"practice.  The receiving machine writes the data to the _backup_ dataset on "
"the _recvpool_ pool.  Adding `-d` to `zfs recv` overwrites the name of the "
"pool on the receiving side with the name of the snapshot.  `-u` causes the "
"file systems to not mount on the receiving side.  Using `-v` shows more "
"details about the transfer, including the elapsed time and the amount of "
"data transferred."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2310
#, no-wrap
msgid "Dataset, User, and Group Quotas"
msgstr "数据集、用户和组配额"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2315
#, fuzzy
msgid ""
"Use <<zfs-term-quota,Dataset quotas>> to restrict the amount of space "
"consumed by a particular dataset.  <<zfs-term-refquota,Reference Quotas>> "
"work in much the same way, but count the space used by the dataset itself, "
"excluding snapshots and child datasets.  Similarly, use <<zfs-term-userquota,"
"user>> and <<zfs-term-groupquota,group>> quotas to prevent users or groups "
"from using up all the space in the pool or dataset."
msgstr ""
"数据集配额（<link linkend=\"zfs-term-quota\">Dataset quota</link>）可用来限制"
"特定数据集可以使用的的空间量。参考配额（<link linkend=\"zfs-term-refquota"
"\">Reference Quota</link>）的功能也非常相似，差在参考配额只会计算数据集自己使"
"用的空间，不含快照与子数据集。类似的，使用者（<link linkend=\"zfs-term-"
"userquota\">User</link>）与群组（<link linkend=\"zfs-term-groupquota"
"\">Group</link>）配额可以用来避免使用者或群组用掉存储池或数据集的所有空间。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2320
msgid ""
"The following examples assume that the users already exist in the system.  "
"Before adding a user to the system, make sure to create their home dataset "
"first and set the `mountpoint` to `/home/_bob_`.  Then, create the user and "
"make the home directory point to the dataset's `mountpoint` location.  This "
"will properly set owner and group permissions without shadowing any pre-"
"existing home directory paths that might exist."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2322
#, fuzzy
msgid "To enforce a dataset quota of 10 GB for [.filename]#storage/home/bob#:"
msgstr "要设定 <filename>storage/home/bob</filename> 的数据集配额为 10 GB："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2326
#, no-wrap
msgid "# zfs set quota=10G storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2329
#, fuzzy
msgid ""
"To enforce a reference quota of 10 GB for [.filename]#storage/home/bob#:"
msgstr "设定 <filename>storage/home/bob</filename> 的参考配额为 10 GB："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2333
#, no-wrap
msgid "# zfs set refquota=10G storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2336
msgid "To remove a quota of 10 GB for [.filename]#storage/home/bob#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2340
#, no-wrap
msgid "# zfs set quota=none storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2343
msgid ""
"The general format is `userquota@_user_=_size_`, and the user's name must be "
"in one of these formats:"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2345
msgid "POSIX compatible name such as _joe_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2346
msgid "POSIX numeric ID such as _789_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2347
msgid "SID name such as _joe.bloggs@example.com_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2348
msgid "SID numeric ID such as _S-1-123-456-789_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2350
msgid "For example, to enforce a user quota of 50 GB for the user named _joe_:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2354
#, no-wrap
msgid "# zfs set userquota@joe=50G\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2357
msgid "To remove any quota:"
msgstr "要移除所有配额："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2361
#, no-wrap
msgid "# zfs set userquota@joe=none\n"
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2368
msgid ""
"User quota properties are not displayed by `zfs get all`.  Non-`root` users "
"can't see other's quotas unless granted the `userquota` privilege.  Users "
"with this privilege are able to view and set everyone's quota."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2371
msgid ""
"The general format for setting a group quota is: `groupquota@_group_=_size_`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2373
msgid "To set the quota for the group _firstgroup_ to 50 GB, use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2377
#, no-wrap
msgid "# zfs set groupquota@firstgroup=50G\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2380
msgid ""
"To remove the quota for the group _firstgroup_, or to make sure that one is "
"not set, instead use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2384
#, no-wrap
msgid "# zfs set groupquota@firstgroup=none\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2388
msgid ""
"As with the user quota property, non-`root` users can see the quotas "
"associated with the groups to which they belong.  A user with the "
"`groupquota` privilege or `root` can view and set all quotas for all groups."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2392
msgid ""
"To display the amount of space used by each user on a file system or "
"snapshot along with any quotas, use `zfs userspace`.  For group information, "
"use `zfs groupspace`.  For more information about supported options or how "
"to display specific options alone, refer to man:zfs[1]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2394
#, fuzzy
msgid ""
"Privileged users and `root` can list the quota for [.filename]#storage/home/"
"bob# using:"
msgstr "要设定 <filename>storage/home/bob</filename> 的数据集配额为 10 GB："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2398
#, no-wrap
msgid "# zfs get quota storage/home/bob\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2401
#, no-wrap
msgid "Reservations"
msgstr "保留空间"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2406
#, fuzzy
msgid ""
"<<zfs-term-reservation,Reservations>> guarantee an always-available amount "
"of space on a dataset.  The reserved space will not be available to any "
"other dataset.  This useful feature ensures that free space is available for "
"an important dataset or log files."
msgstr ""
"保留空间（<link linkend=\"zfs-term-reservation\">Reservation</link>）可以确保"
"数据集最少可用的空间量，其他任何数据集无法使用保留的空间，这个功能在要确保有"
"足够的可用空间来存放重要的数据集或日志档时特别有用。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2408
msgid ""
"The general format of the `reservation` property is `reservation=_size_`, so "
"to set a reservation of 10 GB on [.filename]#storage/home/bob#, use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2412
#, no-wrap
msgid "# zfs set reservation=10G storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2415
msgid "To clear any reservation:"
msgstr "要清除任何保留空间："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2419
#, no-wrap
msgid "# zfs set reservation=none storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2422
msgid ""
"The same principle applies to the `refreservation` property for setting a "
"<<zfs-term-refreservation,Reference Reservation>>, with the general format "
"`refreservation=_size_`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2424
#, fuzzy
msgid ""
"This command shows any reservations or refreservations that exist on [."
"filename]#storage/home/bob#:"
msgstr ""
"这个指令会显示任何已设定于 <filename>storage/home/bob</filename> 的 "
"reservation 或 refreservation："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2429
#, no-wrap
msgid ""
"# zfs get reservation storage/home/bob\n"
"# zfs get refreservation storage/home/bob\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2432
#, no-wrap
msgid "Compression"
msgstr "压缩（Compression）"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2438
msgid ""
"ZFS provides transparent compression.  Compressing data written at the block "
"level saves space and also increases disk throughput.  If data compresses by "
"25% the compressed data writes to the disk at the same rate as the "
"uncompressed version, resulting in an effective write speed of 125%.  "
"Compression can also be a great alternative to <<zfs-zfs-deduplication,"
"Deduplication>> because it does not require extra memory."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2444
msgid ""
"ZFS offers different compression algorithms, each with different trade-"
"offs.  The introduction of LZ4 compression in ZFS v5000 enables compressing "
"the entire pool without the large performance trade-off of other "
"algorithms.  The biggest advantage to LZ4 is the _early abort_ feature.  If "
"LZ4 does not achieve at least 12.5% compression in the header part of the "
"data, ZFS writes the block uncompressed to avoid wasting CPU cycles trying "
"to compress data that is either already compressed or uncompressible.  For "
"details about the different compression algorithms available in ZFS, see the "
"<<zfs-term-compression,Compression>> entry in the terminology section."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2446
#, fuzzy
#| msgid ""
#| "The administrator can monitor the effectiveness of compression using a "
#| "number of dataset properties."
msgid ""
"The administrator can see the effectiveness of compression using dataset "
"properties."
msgstr "管理者可以使用数据集的属性来监视压缩的效果。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2455
#, no-wrap
msgid ""
"# zfs get used,compressratio,compression,logicalused mypool/compressed_dataset\n"
"NAME        PROPERTY          VALUE     SOURCE\n"
"mypool/compressed_dataset  used              449G      -\n"
"mypool/compressed_dataset  compressratio     1.11x     -\n"
"mypool/compressed_dataset  compression       lz4       local\n"
"mypool/compressed_dataset  logicalused       496G      -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2460
msgid ""
"The dataset is using 449 GB of space (the used property).  Without "
"compression, it would have taken 496 GB of space (the `logicalused` "
"property).  This results in a 1.11:1 compression ratio."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2466
#, fuzzy
msgid ""
"Compression can have an unexpected side effect when combined with <<zfs-term-"
"userquota,User Quotas>>.  User quotas restrict how much actual space a user "
"consumes on a dataset _after compression_.  If a user has a quota of 10 GB, "
"and writes 10 GB of compressible data, they will still be able to store more "
"data.  If they later update a file, say a database, with more or less "
"compressible data, the amount of space available to them will change.  This "
"can result in the odd situation where a user did not increase the actual "
"amount of data (the `logicalused` property), but the change in compression "
"caused them to reach their quota limit."
msgstr ""
"压缩功能在与使用者配额（<link linkend=\"zfs-term-userquota\">User Quota</"
"link>）一并使用时可能会产生无法预期的副作用。使用者配额会限制一个使用者在一个"
"数据集上可以使用多少空间，但衡量的依据是以<emphasis>压缩后</emphasis> 所使用"
"的空间，因此，若一个使用者有10 GB 的配额，写入了10 GB 可压缩的资料，使用者将"
"还会有空间储存额外的资料。若使用者在之后更新了一个文件，例如一个资料库，可能"
"有更多或较少的可压缩资料，那么剩余可用的空间量也会因此而改变，这可能会造成奇"
"怪的现象便是，一个使用者虽然没有增加实际的资料量（于<literal>logicalused</"
"literal> 属性），但因为更改影响了压缩率，导致使用者达到配额的上限。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2470
#, fuzzy
#| msgid ""
#| "Compression can have a similar unexpected interaction with backups. "
#| "Quotas are often used to limit how much data can be stored to ensure "
#| "there is sufficient backup space available. However since quotas do not "
#| "consider compression, more data may be written than would fit with "
#| "uncompressed backups."
msgid ""
"Compression can have a similar unexpected interaction with backups.  Quotas "
"are often used to limit data storage to ensure there is enough backup space "
"available.  Since quotas do not consider compression ZFS may write more data "
"than would fit with uncompressed backups."
msgstr ""
"压缩功能在与备份功能一起使用时也可能会有类似的问题，通常会使用配额功能来限制"
"能够储存的资料量来确保有足够的备份空间可用。但是由于配额功能并不会考量压缩状"
"况，可能会有比未压缩版本备份更多的资料量会被写入到数据集。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2472
#, no-wrap
msgid "Zstandard Compression"
msgstr "Zstandard 压缩"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2476
msgid ""
"OpenZFS 2.0 added a new compression algorithm.  Zstandard (Zstd) offers "
"higher compression ratios than the default LZ4 while offering much greater "
"speeds than the alternative, gzip. OpenZFS 2.0 is available starting with "
"FreeBSD 12.1-RELEASE via package:sysutils/openzfs[] and has been the default "
"in since FreeBSD 13.0-RELEASE."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2480
#, fuzzy
msgid ""
"Zstd provides a large selection of compression levels, providing fine-"
"grained control over performance versus compression ratio.  One of the main "
"advantages of Zstd is that the decompression speed is independent of the "
"compression level.  For data written once but read often, Zstd allows the "
"use of the highest compression levels without a read performance penalty."
msgstr ""
"<acronym>Zstd</acronym>提供了大量的压缩级别选择，可对性能与压缩比进行精细控"
"制。<acronym>Zstd</acronym>的主要优势之一是解压速度与压缩级别无关。对于写入一"
"次但读取多次的数据，<acronym>Zstd</acronym>使用最高的压缩级别时不会影响读取性"
"能。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2485
#, fuzzy
msgid ""
"Even with frequent data updates, enabling compression often provides higher "
"performance.  One of the biggest advantages comes from the compressed ARC "
"feature.  ZFS's Adaptive Replacement Cache (ARC) caches the compressed "
"version of the data in RAM, decompressing it each time.  This allows the "
"same amount of RAM to store more data and metadata, increasing the cache hit "
"ratio."
msgstr ""
"即使数据更新频繁，也常常会因为启用压缩功能而获得性能提升。其中最大的优势来自"
"于压缩的ARC功能。<acronym>ZFS</acronym>的自适应替换缓存(<acronym>ARC</"
"acronym>)将数据的压缩版本缓存在<acronym>RAM</acronym>中，在每次需要时对其进行"
"解压。这使得相同数量的<acronym>RAM</acronym>可以存储更多的数据和元数据，提高"
"了缓存命中率。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2491
msgid ""
"ZFS offers 19 levels of Zstd compression, each offering incrementally more "
"space savings in exchange for slower compression.  The default level is "
"`zstd-3` and offers greater compression than LZ4 without being much slower.  "
"Levels above 10 require large amounts of memory to compress each block and "
"systems with less than 16 GB of RAM should not use them.  ZFS uses a "
"selection of the Zstd_fast_ levels also, which get correspondingly faster "
"but supports lower compression ratios.  ZFS supports `zstd-fast-1` through "
"`zstd-fast-10`, `zstd-fast-20` through `zstd-fast-100` in increments of 10, "
"and `zstd-fast-500` and `zstd-fast-1000` which provide minimal compression, "
"but offer high performance."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2495
msgid ""
"If ZFS is not able to get the required memory to compress a block with Zstd, "
"it will fall back to storing the block uncompressed.  This is unlikely to "
"happen except at the highest levels of Zstd on memory constrained systems.  "
"ZFS counts how often this has occurred since loading the ZFS module with "
"`kstat.zfs.misc.zstd.compress_alloc_fail`."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2497
#, no-wrap
msgid "Deduplication"
msgstr "去重复(Deduplication）"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2503
#, fuzzy
msgid ""
"When enabled, <<zfs-term-deduplication,deduplication>> uses the checksum of "
"each block to detect duplicate blocks.  When a new block is a duplicate of "
"an existing block, ZFS writes a new reference to the existing data instead "
"of the whole duplicate block.  Tremendous space savings are possible if the "
"data contains a lot of duplicated files or repeated information.  Warning: "
"deduplication requires a large amount of memory, and enabling compression "
"instead provides most of the space savings without the extra cost."
msgstr ""
"当开启，去重复（<link linkend=\"zfs-term-deduplication\">Deduplication</"
"link>）功能会使用每个资料区块的校验码(Checksum）来侦测重复的资料区块，当新的"
"资料区块与现有的资料区块重复，<acronym>ZFS</acronym> 便会写入连接到现有资料的"
"参考来替代写入重复的资料区块，这在资料中有大量重复的文件或资讯时可以节省大量"
"的空间，要注意的是：去重复功能需要使用大量的内存且大部份可节省的空间可改开启"
"压缩功能来达成，而压缩功能不需要使用额外的内存。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2505
msgid "To activate deduplication, set the `dedup` property on the target pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2509
#, no-wrap
msgid "# zfs set dedup=on pool\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2514
#, fuzzy
#| msgid ""
#| "Only new data being written to the pool will be deduplicated. Data that "
#| "has already been written to the pool will not be deduplicated merely by "
#| "activating this option. A pool with a freshly activated deduplication "
#| "property will look like this example:"
msgid ""
"Deduplicating only affects new data written to the pool.  Merely activating "
"this option will not deduplicate data already written to the pool.  A pool "
"with a freshly activated deduplication property will look like this example:"
msgstr ""
"只有要被写入到存储池的新资料才会做去重复的动作，先前已被写入到存储池的资料不"
"会因此启动了这个选项而做去重复。查看已开启去重复属性的存储池会如下："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2520
#, no-wrap
msgid ""
"# zpool list\n"
"NAME  SIZE ALLOC  FREE   CKPOINT  EXPANDSZ   FRAG   CAP   DEDUP   HEALTH   ALTROOT\n"
"pool 2.84G 2.19M 2.83G         -         -     0%    0%   1.00x   ONLINE   -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2525
#, fuzzy
msgid ""
"The `DEDUP` column shows the actual rate of deduplication for the pool.  A "
"value of `1.00x` shows that data has not deduplicated yet.  The next example "
"copies some system binaries three times into different directories on the "
"deduplicated pool created above."
msgstr ""
"<literal>DEDUP</literal> 栏位会显示存储池的实际去重复率，数值为 "
"<literal>1.00x</literal> 代表资料尚未被去重复.在下一个例子会在前面所建立的去"
"重复存储池中复制三份 Port 树到不同的目录中。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2531
#, no-wrap
msgid ""
"# for d in dir1 dir2 dir3; do\n"
"> mkdir $d && cp -R /usr/bin $d &\n"
"> done\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2534
msgid "To observe deduplicating of redundant data, use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2540
#, no-wrap
msgid ""
"# zpool list\n"
"NAME SIZE  ALLOC  FREE   CKPOINT  EXPANDSZ   FRAG  CAP   DEDUP   HEALTH   ALTROOT\n"
"pool 2.84G 20.9M 2.82G         -         -     0%   0%   3.00x   ONLINE   -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2545
#, fuzzy
msgid ""
"The `DEDUP` column shows a factor of `3.00x`.  Detecting and deduplicating "
"copies of the data uses a third of the space.  The potential for space "
"savings can be enormous, but comes at the cost of having enough memory to "
"keep track of the deduplicated blocks."
msgstr ""
"<literal>DEDUP</literal> 栏位显示有<literal>3.00x</literal> 的去重复率，这代"
"表已侦测到多份复制的Port 树资料并做了去重复的动作，且只会使用第三份资料所占的"
"空间.去重复能节省空间的潜力可以非常巨大，但会需要消耗大量的内存来持续追踪去重"
"复的资料区块。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2548
msgid ""
"Deduplication is not always beneficial when the data in a pool is not "
"redundant.  ZFS can show potential space savings by simulating deduplication "
"on an existing pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2553
#, no-wrap
msgid ""
"# zdb -S pool\n"
"Simulated DDT histogram:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2569
#, no-wrap
msgid ""
"bucket              allocated                       referenced\n"
"______   ______________________________   ______________________________\n"
"refcnt   blocks   LSIZE   PSIZE   DSIZE   blocks   LSIZE   PSIZE   DSIZE\n"
"------   ------   -----   -----   -----   ------   -----   -----   -----\n"
"     1    2.58M    289G    264G    264G    2.58M    289G    264G    264G\n"
"     2     206K   12.6G   10.4G   10.4G     430K   26.4G   21.6G   21.6G\n"
"     4    37.6K    692M    276M    276M     170K   3.04G   1.26G   1.26G\n"
"     8    2.18K   45.2M   19.4M   19.4M    20.0K    425M    176M    176M\n"
"    16      174   2.83M   1.20M   1.20M    3.33K   48.4M   20.4M   20.4M\n"
"    32       40   2.17M    222K    222K    1.70K   97.2M   9.91M   9.91M\n"
"    64        9     56K   10.5K   10.5K      865   4.96M    948K    948K\n"
"   128        2   9.50K      2K      2K      419   2.11M    438K    438K\n"
"   256        5   61.5K     12K     12K    1.90K   23.0M   4.47M   4.47M\n"
"    1K        2      1K      1K      1K    2.98K   1.49M   1.49M   1.49M\n"
" Total    2.82M    303G    275G    275G    3.20M    319G    287G    287G\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2571
#, no-wrap
msgid "dedup = 1.05, compress = 1.11, copies = 1.00, dedup * compress / copies = 1.16\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2580
msgid ""
"After `zdb -S` finishes analyzing the pool, it shows the space reduction "
"ratio that activating deduplication would achieve.  In this case, `1.16` is "
"a poor space saving ratio mainly provided by compression.  Activating "
"deduplication on this pool would not save any amount of space, and is not "
"worth the amount of memory required to enable deduplication.  Using the "
"formula _ratio = dedup * compress / copies_, system administrators can plan "
"the storage allocation, deciding whether the workload will contain enough "
"duplicate blocks to justify the memory requirements.  If the data is "
"reasonably compressible, the space savings may be good.  Good practice is to "
"enable compression first as compression also provides greatly increased "
"performance.  Enable deduplication in cases where savings are considerable "
"and with enough available memory for the <<zfs-term-deduplication,DDT>>."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2582
#, no-wrap
msgid "ZFS and Jails"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2588
msgid ""
"Use `zfs jail` and the corresponding `jailed` property to delegate a ZFS "
"dataset to a crossref:jails[jails,Jail].  `zfs jail _jailid_` attaches a "
"dataset to the specified jail, and `zfs unjail` detaches it.  To control the "
"dataset from within a jail, set the `jailed` property.  ZFS forbids mounting "
"a jailed dataset on the host because it may have mount points that would "
"compromise the security of the host."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2590
#, no-wrap
msgid "Delegated Administration"
msgstr "委托管理"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2598
#, fuzzy
msgid ""
"A comprehensive permission delegation system allows unprivileged users to "
"perform ZFS administration functions.  For example, if each user's home "
"directory is a dataset, users need permission to create and destroy "
"snapshots of their home directories.  A user performing backups can get "
"permission to use replication features.  ZFS allows a usage statistics "
"script to run with access to only the space usage data for all users.  "
"Delegating the ability to delegate permissions is also possible.  Permission "
"delegation is possible for each subcommand and most properties."
msgstr ""
"一个全面性的权限委托系统可能无权限的使用者执行 <acronym>ZFS</acronym> 的管理"
"功能。例如，若每个使用者的家目录均为一个数据集，便可以给予使用者权限建立与摧"
"毁它们家目录中的快照。可以给予备份使用者使用备份功能的权限。一个使用量统计的 "
"Script 可以允许其在执行时能存取所有使用者的空间利用率资料。甚至可以将委托权限"
"委托给其他人，每个子指令与大多数属性都可使用权限委托。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2600
#, no-wrap
msgid "Delegating Dataset Creation"
msgstr "委托数据集建立"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2606
msgid ""
"`zfs allow _someuser_ create _mydataset_` gives the specified user "
"permission to create child datasets under the selected parent dataset.  A "
"caveat: creating a new dataset involves mounting it.  That requires setting "
"the FreeBSD `vfs.usermount` man:sysctl[8] to `1` to allow non-root users to "
"mount a file system.  Another restriction aimed at preventing abuse: non-"
"`root` users must own the mountpoint where mounting the file system."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2608
#, no-wrap
msgid "Delegating Permission Delegation"
msgstr "委托权限委托"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2612
msgid ""
"`zfs allow _someuser_ allow _mydataset_` gives the specified user the "
"ability to assign any permission they have on the target dataset, or its "
"children, to other users.  If a user has the `snapshot` permission and the "
"`allow` permission, that user can then grant the `snapshot` permission to "
"other users."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2614
#, no-wrap
msgid "Advanced Topics"
msgstr "高级主题"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2617
#, no-wrap
msgid "Tuning"
msgstr "优化调整"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2620
msgid "Adjust tunables to make ZFS perform best for different workloads."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2622
msgid ""
"[[zfs-advanced-tuning-arc_max]] `_vfs.zfs.arc.max_` starting with 13.x (`vfs."
"zfs.arc_max` for 12.x) - Upper size of the <<zfs-term-arc,ARC>>. The default "
"is all RAM but 1 GB, or 5/8 of all RAM, whichever is more. Use a lower value "
"if the system runs any other daemons or processes that may require memory. "
"Adjust this value at runtime with man:sysctl[8] and set it in [.filename]#/"
"boot/loader.conf# or [.filename]#/etc/sysctl.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2623
msgid ""
"[[zfs-advanced-tuning-arc_meta_limit]] `_vfs.zfs.arc.meta_limit_` starting "
"with 13.x (`vfs.zfs.arc_meta_limit` for 12.x)` - Limit the amount of the "
"<<zfs-term-arc,ARC>> used to store metadata. The default is one fourth of "
"`vfs.zfs.arc.max`. Increasing this value will improve performance if the "
"workload involves operations on a large number of files and directories, or "
"frequent metadata operations, at the cost of less file data fitting in the "
"<<zfs-term-arc,ARC>>. Adjust this value at runtime with man:sysctl[8] in [."
"filename]#/boot/loader.conf# or [.filename]#/etc/sysctl.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2624
msgid ""
"[[zfs-advanced-tuning-arc_min]] `_vfs.zfs.arc.min_` starting with 13.x (`vfs."
"zfs.arc_min` for 12.x) - Lower size of the <<zfs-term-arc,ARC>>. The default "
"is one half of `vfs.zfs.arc.meta_limit`. Adjust this value to prevent other "
"applications from pressuring out the entire <<zfs-term-arc,ARC>>. Adjust "
"this value at runtime with man:sysctl[8] and in [.filename]#/boot/loader."
"conf# or [.filename]#/etc/sysctl.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2625
msgid ""
"[[zfs-advanced-tuning-vdev-cache-size]] `_vfs.zfs.vdev.cache.size_` - A "
"preallocated amount of memory reserved as a cache for each device in the "
"pool. The total amount of memory used will be this value multiplied by the "
"number of devices. Set this value at boot time and in [.filename]#/boot/"
"loader.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2626
msgid ""
"[[zfs-advanced-tuning-min-auto-ashift]] `_vfs.zfs.min_auto_ashift_` - Lower "
"`ashift` (sector size) used automatically at pool creation time. The value "
"is a power of two. The default value of `9` represents `2^9 = 512`, a sector "
"size of 512 bytes. To avoid _write amplification_ and get the best "
"performance, set this value to the largest sector size used by a device in "
"the pool."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2632
msgid ""
"Common drives have 4 KB sectors.  Using the default `ashift` of `9` with "
"these drives results in write amplification on these devices.  Data "
"contained in a single 4 KB write is instead written in eight 512-byte "
"writes.  ZFS tries to read the native sector size from all devices when "
"creating a pool, but drives with 4 KB sectors report that their sectors are "
"512 bytes for compatibility.  Setting `vfs.zfs.min_auto_ashift` to `12` "
"(`2^12 = 4096`) before creating a pool forces ZFS to use 4 KB blocks for "
"best performance on these drives."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2635
#, fuzzy
msgid ""
"Forcing 4 KB blocks is also useful on pools with planned disk upgrades.  "
"Future disks use 4 KB sectors, and `ashift` values cannot change after "
"creating a pool."
msgstr ""
"强制使用 4KB 块在计划进行磁盘升级的池中也很有用。将来的磁盘可能会使用 4 KB 扇"
"区，并且在创建池后无法更改<varname>ashift</varname>值。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2639
#, fuzzy
msgid ""
"In some specific cases, the smaller 512-byte block size might be "
"preferable.  When used with 512-byte disks for databases or as storage for "
"virtual machines, less data transfers during small random reads.  This can "
"provide better performance when using a smaller ZFS record size."
msgstr ""
"在某些特定情况下，使用较小的 512 字节块大小可能更合适。当与 512 字节的数据库"
"磁盘一起使用时，或用作虚拟机的存储时，在小型随机读取期间传输的数据较少。这可"
"以提供更好的性能，尤其是在使用较小的<acronym>ZFS</acronym>记录大小时。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2640
msgid ""
"[[zfs-advanced-tuning-prefetch_disable]] `_vfs.zfs.prefetch_disable_` - "
"Disable prefetch. A value of `0` enables and `1` disables it. The default is "
"`0`, unless the system has less than 4 GB of RAM. Prefetch works by reading "
"larger blocks than requested into the <<zfs-term-arc,ARC>> in hopes to soon "
"need the data. If the workload has a large number of random reads, disabling "
"prefetch may actually improve performance by reducing unnecessary reads. "
"Adjust this value at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2641
msgid ""
"[[zfs-advanced-tuning-vdev-trim_on_init]] `_vfs.zfs.vdev.trim_on_init_` - "
"Control whether new devices added to the pool have the `TRIM` command run on "
"them. This ensures the best performance and longevity for SSDs, but takes "
"extra time. If the device has already been secure erased, disabling this "
"setting will make the addition of the new device faster. Adjust this value "
"at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2642
msgid ""
"[[zfs-advanced-tuning-vdev-max_pending]] `_vfs.zfs.vdev.max_pending_` - "
"Limit the number of pending I/O requests per device. A higher value will "
"keep the device command queue full and may give higher throughput. A lower "
"value will reduce latency. Adjust this value at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2643
msgid ""
"[[zfs-advanced-tuning-top_maxinflight]] `_vfs.zfs.top_maxinflight_` - Upper "
"number of outstanding I/Os per top-level <<zfs-term-vdev,vdev>>. Limits the "
"depth of the command queue to prevent high latency. The limit is per top-"
"level vdev, meaning the limit applies to each <<zfs-term-vdev-mirror,"
"mirror>>, <<zfs-term-vdev-raidz,RAID-Z>>, or other vdev independently. "
"Adjust this value at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2644
msgid ""
"[[zfs-advanced-tuning-l2arc_write_max]] `_vfs.zfs.l2arc_write_max_` - Limit "
"the amount of data written to the <<zfs-term-l2arc,L2ARC>> per second. This "
"tunable extends the longevity of SSDs by limiting the amount of data written "
"to the device. Adjust this value at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2645
msgid ""
"[[zfs-advanced-tuning-l2arc_write_boost]] `_vfs.zfs.l2arc_write_boost_` - "
"Adds the value of this tunable to <<zfs-advanced-tuning-l2arc_write_max,`vfs."
"zfs.l2arc_write_max`>> and increases the write speed to the SSD until "
"evicting the first block from the <<zfs-term-l2arc,L2ARC>>. This \"Turbo "
"Warmup Phase\" reduces the performance loss from an empty <<zfs-term-l2arc,"
"L2ARC>> after a reboot. Adjust this value at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2646
msgid ""
"[[zfs-advanced-tuning-scrub_delay]]`_vfs.zfs.scrub_delay_` - Number of ticks "
"to delay between each I/O during a <<zfs-term-scrub,`scrub`>>. To ensure "
"that a `scrub` does not interfere with the normal operation of the pool, if "
"any other I/O is happening the `scrub` will delay between each command. This "
"value controls the limit on the total IOPS (I/Os Per Second) generated by "
"the `scrub`. The granularity of the setting is determined by the value of "
"`kern.hz` which defaults to 1000 ticks per second. Changing this setting "
"results in a different effective IOPS limit.  The default value is `4`, "
"resulting in a limit of: 1000 ticks/sec / 4 = 250 IOPS. Using a value of "
"_20_ would give a limit of: 1000 ticks/sec / 20 = 50 IOPS. Recent activity "
"on the pool limits the speed of `scrub`, as determined by <<zfs-advanced-"
"tuning-scan_idle,`vfs.zfs.scan_idle`>>. Adjust this value at any time with "
"man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2647
msgid ""
"[[zfs-advanced-tuning-resilver_delay]] `_vfs.zfs.resilver_delay_` - Number "
"of milliseconds of delay inserted between each I/O during a <<zfs-term-"
"resilver,resilver>>. To ensure that a resilver does not interfere with the "
"normal operation of the pool, if any other I/O is happening the resilver "
"will delay between each command. This value controls the limit of total IOPS "
"(I/Os Per Second) generated by the resilver. ZFS determins the granularity "
"of the setting by the value of `kern.hz` which defaults to 1000 ticks per "
"second. Changing this setting results in a different effective IOPS limit. "
"The default value is 2, resulting in a limit of: 1000 ticks/sec / 2 = 500 "
"IOPS. Returning the pool to an <<zfs-term-online,Online>> state may be more "
"important if another device failing could <<zfs-term-faulted,Fault>> the "
"pool, causing data loss. A value of 0 will give the resilver operation the "
"same priority as other operations, speeding the healing process. Other "
"recent activity on the pool limits the speed of resilver, as determined by "
"<<zfs-advanced-tuning-scan_idle,`vfs.zfs.scan_idle`>>. Adjust this value at "
"any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2648
msgid ""
"[[zfs-advanced-tuning-scan_idle]] `_vfs.zfs.scan_idle_` - Number of "
"milliseconds since the last operation before considering the pool is idle. "
"ZFS disables the rate limiting for <<zfs-term-scrub,`scrub`>> and <<zfs-term-"
"resilver,resilver>> when the pool is idle. Adjust this value at any time "
"with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2649
msgid ""
"[[zfs-advanced-tuning-txg-timeout]] `_vfs.zfs.txg.timeout_` - Upper number "
"of seconds between <<zfs-term-txg,transaction group>>s. The current "
"transaction group writes to the pool and a fresh transaction group starts if "
"this amount of time elapsed since the previous transaction group. A "
"transaction group may trigger earlier if writing enough data. The default "
"value is 5 seconds. A larger value may improve read performance by delaying "
"asynchronous writes, but this may cause uneven performance when writing the "
"transaction group. Adjust this value at any time with man:sysctl[8]."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2651
#, no-wrap
msgid "ZFS on i386"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2654
msgid ""
"Some of the features provided by ZFS are memory intensive, and may require "
"tuning for upper efficiency on systems with limited RAM."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2655
#, no-wrap
msgid "Memory"
msgstr "内存"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2663
#, fuzzy
msgid ""
"As a lower value, the total system memory should be at least one gigabyte.  "
"The amount of recommended RAM depends upon the size of the pool and which "
"features ZFS uses.  A general rule of thumb is 1 GB of RAM for every 1 TB of "
"storage.  If using the deduplication feature, a general rule of thumb is 5 "
"GB of RAM per TB of storage to deduplicate.  While some users use ZFS with "
"less RAM, systems under heavy load may panic due to memory exhaustion.  ZFS "
"may require further tuning for systems with less than the recommended RAM "
"requirements."
msgstr ""
"最低需求，总系统内存应至少有 1 GB，建议的 <acronym>RAM</acronym> 量需视存储池"
"的大小以及使用的 <acronym>ZFS</acronym> 功能而定。一般的经验法则是每 1 TB 的"
"储存空间需要 1 GB 的 RAM，若有开启去重复的功能，一般的经验法则是每 1 TB 的要"
"做去重复的储存空间需要 5 GB 的 RAM。虽然有部份使用者成功使用较少的 "
"<acronym>RAM</acronym> 来运作 <acronym>ZFS</acronym>，但系统在负载较重时有可"
"能会因为记忆用耗而导致当机，对于要使用低于建议 RAM 需求量来运作的系统可能会需"
"要更进一步的调校。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2664
#, no-wrap
msgid "Kernel Configuration"
msgstr "内核配置"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2667
msgid ""
"Due to the address space limitations of the i386(TM) platform, ZFS users on "
"the i386(TM) architecture must add this option to a custom kernel "
"configuration file, rebuild the kernel, and reboot:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2671
#, fuzzy, no-wrap
msgid "options        KVA_PAGES=512\n"
msgstr "options        KVA_PAGES=512\n"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2676
msgid ""
"This expands the kernel address space, allowing the `vm.kvm_size` tunable to "
"push beyond the imposed limit of 1 GB, or the limit of 2 GB for PAE.  To "
"find the most suitable value for this option, divide the desired address "
"space in megabytes by four.  In this example `512` for 2 GB."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2677
#, no-wrap
msgid "Loader Tunables"
msgstr "载入程序可调参数"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2681
#, fuzzy
msgid ""
"Increases the [.filename]#kmem# address space on all FreeBSD architectures.  "
"A test system with 1 GB of physical memory benefitted from adding these "
"options to [.filename]#/boot/loader.conf# and then restarting:"
msgstr ""
"在所有的FreeBSD 架构上均可增加<filename>kmem</filename> 位址空间，经测试在一"
"个1 GB 实体内存的测试系统上，加入以下选项到<filename>/boot/loader.conf</"
"filename>，重新开启系统，可成功设定："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2688
#, fuzzy, no-wrap
msgid ""
"vm.kmem_size=\"330M\"\n"
"vm.kmem_size_max=\"330M\"\n"
"vfs.zfs.arc.max=\"40M\"\n"
"vfs.zfs.vdev.cache.size=\"5M\"\n"
msgstr ""
"vm.kmem_size=\"330M\"\n"
"vm.kmem_size_max=\"330M\"\n"
"vfs.zfs.arc_max=\"40M\"\n"
"vfs.zfs.vdev.cache.size=\"5M\"\n"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2691
msgid ""
"For a more detailed list of recommendations for ZFS-related tuning, see "
"https://wiki.freebsd.org/ZFSTuningGuide[]."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2693
#, no-wrap
msgid "Further Resources"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2696
msgid "https://openzfs.org/[OpenZFS]"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2697
msgid "https://wiki.freebsd.org/ZFSTuningGuide[FreeBSD Wiki - ZFS Tuning]"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2698
msgid ""
"https://calomel.org/zfs_raid_speed_capacity.html[Calomel Blog - ZFS Raidz "
"Performance, Capacity and Integrity]"
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2700
#, no-wrap
msgid "ZFS Features and Terminology"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2709
#, fuzzy
msgid ""
"More than a file system, ZFS is fundamentally different.  ZFS combines the "
"roles of file system and volume manager, enabling new storage devices to add "
"to a live system and having the new space available on the existing file "
"systems in that pool at once.  By combining the traditionally separate "
"roles, ZFS is able to overcome previous limitations that prevented RAID "
"groups being able to grow.  A _vdev_ is a top level device in a pool and can "
"be a simple disk or a RAID transformation such as a mirror or RAID-Z array.  "
"ZFS file systems (called _datasets_) each have access to the combined free "
"space of the entire pool.  Used blocks from the pool decrease the space "
"available to each file system.  This approach avoids the common pitfall with "
"extensive partitioning where free space becomes fragmented across the "
"partitions."
msgstr ""
"<acronym>ZFS</acronym> 是一个从本质上与众不同的文件系统，由于它并非只是一个文"
"件系统，<acronym>ZFS</acronym> 结合了文件系统及磁盘区管理程序，让额外的储存设"
"备可以即时的加入到系统并可让既有的文件系统立即使用这些在存储池中空间。透过结"
"合传统区分为二的两个角色，<acronym>ZFS</acronym> 能够克服以往 <acronym>RAID</"
"acronym> 磁盘群组无法扩充的限制。每个在存储池顶层的设备称作<emphasis>vdev</"
"emphasis>，其可以是一个简单的磁盘或是一个<acronym>RAID</acronym> 如镜像或"
"<acronym>RAID-Z</acronym > 阵列。 <acronym>ZFS</acronym> 的文件系统（称作"
"<emphasis>数据集（Dataset）</emphasis>）每一个数据集均可存取整个存池所共通的"
"可用空间，随着使用存储池来配置空间区块，存储池能给每个文件系统使用的可用空间"
"就会减少，这个方法可以避免扩大分割区会使的可用空间分散分割区之间的常见问题。"

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2715
#, no-wrap
msgid "[[zfs-term-pool]]pool"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2718
#, no-wrap
msgid ""
"A storage _pool_ is the most basic building block of ZFS. A pool consists of one or more vdevs, the underlying devices that store the data. A pool is then used to create one or more file systems (datasets) or block devices (volumes).\n"
"These datasets and volumes share the pool of remaining free space. Each pool is uniquely identified by a name and a GUID. The ZFS version number on the pool determines the features available."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2719
#, no-wrap
msgid "[[zfs-term-vdev]]vdev Types"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2749
#, no-wrap
msgid ""
"A pool consists of one or more vdevs, which themselves are a single disk or a group of disks, transformed to a RAID. When using a lot of vdevs, ZFS spreads data across the vdevs to increase performance and maximize usable space. All vdevs must be at least 128 MB in size. \n"
"\n"
"* [[zfs-term-vdev-disk]] _Disk_ - The most basic vdev type is a standard block device. This can be an entire disk (such as [.filename]#/dev/ada0# or [.filename]#/dev/da0#) or a partition ([.filename]#/dev/ada0p3#). On FreeBSD, there is no performance penalty for using a partition rather than the entire disk. This differs from recommendations made by the Solaris documentation.\n"
"+\n"
"[CAUTION]\n"
"====\n"
"Using an entire disk as part of a bootable pool is strongly discouraged, as this may render the pool unbootable.\n"
"Likewise, you should not use an entire disk as part of a mirror or RAID-Z vdev.\n"
"Reliably determining the size of an unpartitioned disk at boot time is impossible and there's no place to put in boot code.\n"
"====\n"
"\n"
"* [[zfs-term-vdev-file]] _File_ - Regular files may make up ZFS pools, which is useful for testing and experimentation. Use the full path to the file as the device path in `zpool create`.\n"
"* [[zfs-term-vdev-mirror]] _Mirror_ - When creating a mirror, specify the `mirror` keyword followed by the list of member devices for the mirror. A mirror consists of two or more devices, writing all data to all member devices. A mirror vdev will hold as much data as its smallest member. A mirror vdev can withstand the failure of all but one of its members without losing any data.\n"
"+\n"
"[NOTE]\n"
"====\n"
"To upgrade a regular single disk vdev to a mirror vdev at any time, use `zpool <<zfs-zpool-attach,attach>>`.\n"
"====\n"
"\n"
"* [[zfs-term-vdev-raidz]] _RAID-Z_ - ZFS uses RAID-Z, a variation on standard RAID-5 that offers better distribution of parity and eliminates the \"RAID-5 write hole\" in which the data and parity information become inconsistent after an unexpected restart. ZFS supports three levels of RAID-Z which provide varying levels of redundancy in exchange for decreasing levels of usable storage. ZFS uses RAID-Z1 through RAID-Z3 based on the number of parity devices in the array and the number of disks which can fail before the pool stops  being operational.\n"
"+\n"
"In a RAID-Z1 configuration with four disks, each 1 TB, usable storage is 3 TB and the pool will still be able to operate in degraded mode with one faulted disk. If another disk goes offline before replacing and resilvering the faulted disk would result in losing all pool data.\n"
"+\n"
"In a RAID-Z3 configuration with eight disks of 1 TB, the volume will provide 5 TB of usable space and still be able to operate with three faulted disks. Sun(TM) recommends no more than nine disks in a single vdev. If more disks make up the configuration, the recommendation is to divide them into separate vdevs and stripe the pool data across them.\n"
"+\n"
"A configuration of two RAID-Z2 vdevs consisting of 8 disks each would create something like a RAID-60 array. A RAID-Z group's storage capacity is about the size of the smallest disk multiplied by the number of non-parity disks. Four 1 TB disks in RAID-Z1 has an effective size of about 3 TB, and an array of eight 1 TB disks in RAID-Z3 will yield 5 TB of usable space.\n"
"* [[zfs-term-vdev-spare]] _Spare_ - ZFS has a special pseudo-vdev type for keeping track of available hot spares. Note that installed hot spares are not deployed automatically; manually configure them to replace the failed device using `zfs replace`.\n"
"* [[zfs-term-vdev-log]] _Log_ - ZFS Log Devices, also known as ZFS Intent Log (<<zfs-term-zil,ZIL>>) move the intent log from the regular pool devices to a dedicated device, typically an SSD. Having a dedicated log device improves the performance of applications with a high volume of synchronous writes like databases. Mirroring of log devices is possible, but RAID-Z is not supported. If using a lot of log devices, writes will be load-balanced across them.\n"
"* [[zfs-term-vdev-cache]] _Cache_ - Adding a cache vdev to a pool will add the storage of the cache to the <<zfs-term-l2arc,L2ARC>>. Mirroring cache devices is impossible. Since a cache device stores only new copies of existing data, there is no risk of data loss."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2750
#, no-wrap
msgid "[[zfs-term-txg]] Transaction Group (TXG)"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2756
#, no-wrap
msgid ""
"Transaction Groups are the way ZFS groups blocks changes together and writes them to the pool. Transaction groups are the atomic unit that ZFS uses to ensure consistency. ZFS assigns each transaction group a unique 64-bit consecutive identifier. There can be up to three active transaction groups at a time, one in each of these three states: \n"
"\n"
"* _Open_ - A new transaction group begins in the open state and accepts new writes. There is always a transaction group in the open state, but the transaction group may refuse new writes if it has reached a limit. Once the open transaction group has reached a limit, or reaching the <<zfs-advanced-tuning-txg-timeout,`vfs.zfs.txg.timeout`>>, the transaction group advances to the next state.\n"
"* _Quiescing_ - A short state that allows any pending operations to finish without blocking the creation of a new open transaction group. Once all the transactions in the group have completed, the transaction group advances to the final state.\n"
"* _Syncing_ - Write all the data in the transaction group to stable storage. This process will in turn change other data, such as metadata and space maps, that ZFS will also write to stable storage. The process of syncing involves several passes. On the first and biggest, all the changed data blocks; next come the metadata, which may take several passes to complete. Since allocating space for the data blocks generates new metadata, the syncing state cannot finish until a pass completes that does not use any new space. The syncing state is also where _synctasks_ complete. Synctasks are administrative operations such as creating or destroying snapshots and datasets that complete the uberblock change. Once the sync state completes the transaction group in the quiescing state advances to the syncing state. All administrative functions, such as <<zfs-term-snapshot,`snapshot`>> write as part of the transaction group. ZFS adds a created synctask to the open transaction group, and that group advances as fast as possible to the syncing state to reduce the latency of administrative commands."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2757
#, no-wrap
msgid "[[zfs-term-arc]]Adaptive Replacement Cache (ARC)"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2759
#, no-wrap
msgid "ZFS uses an Adaptive Replacement Cache (ARC), rather than a more traditional Least Recently Used (LRU) cache. An LRU cache is a simple list of items in the cache, sorted by how recently object was used, adding new items to the head of the list. When the cache is full, evicting items from the tail of the list makes room for more active objects. An ARC consists of four lists; the Most Recently Used (MRU) and Most Frequently Used (MFU) objects, plus a ghost list for each. These ghost lists track evicted objects to prevent adding them back to the cache. This increases the cache hit ratio by avoiding objects that have a history of occasional use. Another advantage of using both an MRU and MFU is that scanning an entire file system would evict all data from an MRU or LRU cache in favor of this freshly accessed content. With ZFS, there is also an MFU that tracks the most frequently used objects, and the cache of the most commonly accessed blocks remains."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2760
#, no-wrap
msgid "[[zfs-term-l2arc]]L2ARC"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2762
#, no-wrap
msgid "L2ARC is the second level of the ZFS caching system. RAM stores the primary ARC. Since the amount of available RAM is often limited, ZFS can also use <<zfs-term-vdev-cache,cache vdevs>>. Solid State Disks (SSDs) are often used as these cache devices due to their higher speed and lower latency compared to traditional spinning disks. L2ARC is entirely optional, but having one will increase read speeds for cached files on the SSD instead of having to read from the regular disks. L2ARC can also speed up <<zfs-term-deduplication,deduplication>> because a deduplication table (DDT) that does not fit in RAM but does fit in the L2ARC will be much faster than a DDT that must read from disk. Limits on the data rate added to the cache devices prevents prematurely wearing out SSDs with extra writes. Until the cache is full (the first block evicted to make room), writes to the L2ARC limit to the sum of the write limit and the boost limit, and afterwards limit to the write limit. A pair of man:sysctl[8] values control these rate limits. <<zfs-advanced-tuning-l2arc_write_max,`vfs.zfs.l2arc_write_max`>> controls the number of bytes written to the cache per second, while <<zfs-advanced-tuning-l2arc_write_boost,`vfs.zfs.l2arc_write_boost`>> adds to this limit during the \"Turbo Warmup Phase\" (Write Boost)."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2763
#, no-wrap
msgid "[[zfs-term-zil]]ZIL"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2765
#, no-wrap
msgid "ZIL accelerates synchronous transactions by using storage devices like SSDs that are faster than those used in the main storage pool. When an application requests a synchronous write (a guarantee that the data is stored to disk rather than merely cached for later writes), writing the data to the faster ZIL storage then later flushing it out to the regular disks greatly reduces latency and improves performance. Synchronous workloads like databases will profit from a ZIL alone. Regular asynchronous writes such as copying files will not use the ZIL at all."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2766
#, no-wrap
msgid "[[zfs-term-cow]]Copy-On-Write"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2768
#, no-wrap
msgid "Unlike a traditional file system, ZFS writes a different block rather than overwriting the old data in place. When completing this write the metadata updates to point to the new location. When a shorn write (a system crash or power loss in the middle of writing a file) occurs, the entire original contents of the file are still available and ZFS discards the incomplete write. This also means that ZFS does not require a man:fsck[8] after an unexpected shutdown."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2769
#, no-wrap
msgid "[[zfs-term-dataset]]Dataset"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2771
#, no-wrap
msgid "_Dataset_ is the generic term for a ZFS file system, volume, snapshot or clone. Each dataset has a unique name in the format _poolname/path@snapshot_. The root of the pool is a dataset as well. Child datasets have hierarchical names like directories. For example, _mypool/home_, the home dataset, is a child of _mypool_ and inherits properties from it. Expand this further by creating _mypool/home/user_. This grandchild dataset will inherit properties from the parent and grandparent. Set properties on a child to override the defaults inherited from the parent and grandparent. Administration of datasets and their children can be <<zfs-zfs-allow,delegated>>."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2772
#, no-wrap
msgid "[[zfs-term-filesystem]]File system"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2774
#, no-wrap
msgid "A ZFS dataset is most often used as a file system. Like most other file systems, a ZFS file system mounts somewhere in the systems directory hierarchy and contains files and directories of its own with permissions, flags, and other metadata."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2775
#, no-wrap
msgid "[[zfs-term-volume]]Volume"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2777
#, no-wrap
msgid "ZFS can also create volumes, which appear as disk devices. Volumes have a lot of the same features as datasets, including copy-on-write, snapshots, clones, and checksumming. Volumes can be useful for running other file system formats on top of ZFS, such as UFS virtualization, or exporting iSCSI extents."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2778
#, no-wrap
msgid "[[zfs-term-snapshot]]Snapshot"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2780
#, no-wrap
msgid "The <<zfs-term-cow,copy-on-write>> (COW) design of ZFS allows for nearly instantaneous, consistent snapshots with arbitrary names. After taking a snapshot of a dataset, or a recursive snapshot of a parent dataset that will include all child datasets, new data goes to new blocks, but without reclaiming the old blocks as free space. The snapshot contains the original file system version and the live file system contains any changes made since taking the snapshot using no other space. New data written to the live file system uses new blocks to store this data. The snapshot will grow as the blocks are no longer used in the live file system, but in the snapshot alone. Mount these snapshots read-only allows recovering of previous file versions. A <<zfs-zfs-snapshot,rollback>> of a live file system to a specific snapshot is possible, undoing any changes that took place after taking the snapshot. Each block in the pool has a reference counter which keeps track of the snapshots, clones, datasets, or volumes use that block. As files and snapshots get deleted, the reference count  decreases, reclaiming the free space when no longer referencing a block. Marking snapshots with a <<zfs-zfs-snapshot,hold>> results in any attempt to destroy it will  returns an `EBUSY` error. Each snapshot can have holds with a unique name each. The <<zfs-zfs-snapshot,release>> command removes the hold so the snapshot can deleted. Snapshots, cloning, and rolling back works on volumes, but independently mounting does not."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2781
#, no-wrap
msgid "[[zfs-term-clone]]Clone"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2783
#, no-wrap
msgid "Cloning a snapshot is also possible. A clone is a writable version of a snapshot, allowing the file system to fork as a new dataset. As with a snapshot, a clone initially consumes no new space. As new data written to a clone uses new blocks, the size of the clone grows. When blocks are overwritten in the cloned file system or volume, the reference count on the previous block decreases. Removing the snapshot upon which a clone bases is impossible because the clone depends on it. The snapshot is the parent, and the clone is the child. Clones can be _promoted_, reversing this dependency and making the clone the parent and the previous parent the child. This operation requires no new space. Since the amount of space used by the parent and child reverses, it may affect existing quotas and reservations."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2784
#, no-wrap
msgid "[[zfs-term-checksum]]Checksum"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2791
#, no-wrap
msgid ""
"Every block is also checksummed. The checksum algorithm used is a per-dataset property, see <<zfs-zfs-set,`set`>>. The checksum of each block is transparently validated when read, allowing ZFS to detect silent corruption. If the data read does not match the expected checksum, ZFS will attempt to recover the data from any available redundancy, like mirrors or RAID-Z. Triggering a validation of all checksums with <<zfs-term-scrub,`scrub`>>. Checksum algorithms include:\n"
"\n"
"* `fletcher2`\n"
"* `fletcher4`\n"
"* `sha256`\n"
" The `fletcher` algorithms are faster, but `sha256` is a strong cryptographic hash and has a much lower chance of collisions at the  cost of some performance. Deactivating checksums is possible, but  strongly discouraged."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2792
#, no-wrap
msgid "[[zfs-term-compression]]Compression"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2806
#, no-wrap
msgid ""
"Each dataset has a compression property, which defaults to off. Set this property to an available compression algorithm. This causes compression of all new data written to the dataset. Beyond a reduction in space used, read and write throughput often increases because fewer blocks need reading or writing. \n"
"\n"
"[[zfs-term-compression-lz4]]\n"
"* _LZ4_ - Added in ZFS pool version 5000 (feature flags), LZ4 is now the recommended compression algorithm. LZ4 works about 50% faster than LZJB when operating on compressible data, and is over three times faster when operating on uncompressible data. LZ4 also decompresses about 80% faster than LZJB. On modern CPUs, LZ4 can often compress at over 500 MB/s, and decompress at over 1.5 GB/s (per single CPU core).\n"
"\n"
"[[zfs-term-compression-lzjb]]\n"
"* _LZJB_ - The default compression algorithm. Created by Jeff Bonwick (one of the original creators of ZFS). LZJB offers good compression with less CPU overhead compared to GZIP. In the future, the default compression algorithm will change to LZ4.\n"
"\n"
"[[zfs-term-compression-gzip]]\n"
"* _GZIP_ - A popular stream compression algorithm available in ZFS. One of the main advantages of using GZIP is its configurable level of compression. When setting the `compress` property, the administrator can choose the level of compression, ranging from `gzip1`, the lowest level of compression, to `gzip9`, the highest level of compression. This gives the administrator control over how much CPU time to trade for saved disk space.\n"
"\n"
"[[zfs-term-compression-zle]]\n"
"* _ZLE_ - Zero Length Encoding is a special compression algorithm that compresses continuous runs of zeros alone. This compression algorithm is useful when the dataset contains large blocks of zeros."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2807
#, no-wrap
msgid "[[zfs-term-copies]]Copies"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2809
#, no-wrap
msgid "When set to a value greater than 1, the `copies` property instructs ZFS to maintain copies of each block in the <<zfs-term-filesystem,file system>> or <<zfs-term-volume,volume>>. Setting this property on important datasets provides added redundancy from which to recover a block that does not match its checksum. In pools without redundancy, the copies feature is the single form of redundancy. The copies feature can recover from a single bad sector or other forms of minor corruption, but it does not protect the pool from the loss of an entire disk."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2810
#, no-wrap
msgid "[[zfs-term-deduplication]]Deduplication"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2812
#, no-wrap
msgid "Checksums make it possible to detect duplicate blocks when writing data. With deduplication, the reference count of an existing, identical block increases, saving storage space. ZFS keeps a deduplication table (DDT) in memory to detect duplicate blocks. The table contains a list of unique checksums, the location of those blocks, and a reference count. When writing new data, ZFS calculates checksums and compares them to the list. When finding a match it uses the existing block. Using the SHA256 checksum algorithm with deduplication provides a secure cryptographic hash. Deduplication is tunable. If `dedup` is `on`, then a matching checksum means that the data is identical. Setting `dedup` to `verify`, ZFS performs a byte-for-byte check on the data ensuring they are actually identical. If the data is not identical, ZFS will note the hash collision and store the two blocks separately. As the DDT must store the hash of each unique block, it consumes a large amount of memory. A general rule of thumb is 5-6 GB of ram per 1 TB of deduplicated data). In situations not practical to have enough RAM to keep the entire DDT in memory, performance will suffer greatly as the DDT must read from disk before writing each new block. Deduplication can use L2ARC to store the DDT, providing a middle ground between fast system memory and slower disks. Consider using compression instead, which often provides nearly as much space savings without the increased memory."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2813
#, no-wrap
msgid "[[zfs-term-scrub]]Scrub"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2815
#, no-wrap
msgid "Instead of a consistency check like man:fsck[8], ZFS has `scrub`. `scrub` reads all data blocks stored on the pool and verifies their checksums against the known good checksums stored in the metadata. A periodic check of all the data stored on the pool ensures the recovery of any corrupted blocks before needing them. A scrub is not required after an unclean shutdown, but good practice is at least once every three months. ZFS verifies the checksum of each block during normal use, but a scrub makes certain to check even infrequently used blocks for silent corruption. ZFS improves data security in archival storage situations. Adjust the relative priority of `scrub` with <<zfs-advanced-tuning-scrub_delay,`vfs.zfs.scrub_delay`>> to prevent the scrub from degrading the performance of other workloads on the pool."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2816
#, no-wrap
msgid "[[zfs-term-quota]]Dataset Quota"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2827
#, no-wrap
msgid ""
"ZFS provides fast and accurate dataset, user, and group space accounting as well as quotas and space reservations. This gives the administrator fine grained control over space allocation and allows reserving space for critical file systems. \n"
"\n"
"ZFS supports different types of quotas: the dataset quota, the <<zfs-term-refquota,reference quota (refquota)>>, the <<zfs-term-userquota,user quota>>, and the <<zfs-term-groupquota,group quota>>.\n"
"\n"
"Quotas limit the total size of a dataset and its descendants, including snapshots of the dataset, child datasets, and the snapshots of those datasets.\n"
"\n"
"[NOTE]\n"
"====\n"
"Volumes do not support quotas, as the `volsize` property acts as an implicit quota.\n"
"===="
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2828
#, no-wrap
msgid "[[zfs-term-refquota]]Reference Quota"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2830
#, no-wrap
msgid "A reference quota limits the amount of space a dataset can consume by enforcing a hard limit. This hard limit includes space referenced by the dataset alone and does not include space used by descendants, such as file systems or snapshots."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2831
#, no-wrap
msgid "[[zfs-term-userquota]]User Quota"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2833
#, no-wrap
msgid "User quotas are useful to limit the amount of space used by the specified user."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2834
#, no-wrap
msgid "[[zfs-term-groupquota]]Group Quota"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2836
#, no-wrap
msgid "The group quota limits the amount of space that a specified group can consume."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2837
#, no-wrap
msgid "[[zfs-term-reservation]]Dataset Reservation"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2841
#, no-wrap
msgid ""
"The `reservation` property makes it possible to guarantee an amount of space for a specific dataset and its descendants. This means that setting a 10 GB reservation on [.filename]#storage/home/bob# prevents other datasets from using up all free space, reserving at least 10 GB of space for this dataset. Unlike a regular <<zfs-term-refreservation,`refreservation`>>, space used by snapshots and descendants is not counted against the reservation. For example, if taking a snapshot of [.filename]#storage/home/bob#, enough disk space other than the `refreservation` amount must exist for the operation to succeed. Descendants of the main data set are not counted in the `refreservation` amount and so do not encroach on the space set.\n"
"\n"
"Reservations of any sort are useful in situations such as planning and testing the suitability of disk space allocation in a new system, or ensuring that enough space is available on file systems for audio logs or system recovery procedures and files."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2842
#, no-wrap
msgid "[[zfs-term-refreservation]]Reference Reservation"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2844
#, no-wrap
msgid "The `refreservation` property makes it possible to guarantee an amount of space for the use of a specific dataset _excluding_ its descendants. This means that setting a 10 GB reservation on [.filename]#storage/home/bob#, and another dataset tries to use the free space, reserving at least 10 GB of space  for this dataset. In contrast to a regular <<zfs-term-reservation,reservation>>, space used by snapshots and descendant datasets is not counted against the reservation. For example, if taking a snapshot of [.filename]#storage/home/bob#, enough disk space other than the `refreservation` amount must exist for the operation to succeed. Descendants of the  main data set are not counted in the `refreservation` amount and so do not encroach on the space set."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2845
#, no-wrap
msgid "[[zfs-term-resilver]]Resilver"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2846
#, no-wrap
msgid "When replacing a failed disk, ZFS must fill the new disk with the lost data. _Resilvering_ is the process of using the parity information distributed across the remaining drives to calculate and write the missing data to the new drive."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2847
#, no-wrap
msgid "[[zfs-term-online]]Online"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2849
#, no-wrap
msgid "A pool or vdev in the `Online` state has its member devices connected and fully operational. Individual devices in the `Online` state are functioning."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2850
#, no-wrap
msgid "[[zfs-term-offline]]Offline"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2852
#, no-wrap
msgid "The administrator puts individual devices in an `Offline` state if enough redundancy exists to avoid putting the pool or vdev into a <<zfs-term-faulted,Faulted>> state. An administrator may choose to offline a disk in preparation for replacing it, or to make it easier to identify."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2853
#, no-wrap
msgid "[[zfs-term-degraded]]Degraded"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2855
#, no-wrap
msgid "A pool or vdev in the `Degraded` state has one or more disks that disappeared or failed. The pool is still usable, but if other devices fail, the pool may become unrecoverable. Reconnecting the missing devices or replacing the failed disks will return the pool to an <<zfs-term-online,Online>> state after the reconnected or new device has completed the <<zfs-term-resilver,Resilver>> process."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2856
#, no-wrap
msgid "[[zfs-term-faulted]]Faulted"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2857
#, no-wrap
msgid "A pool or vdev in the `Faulted` state is no longer operational. Accessing the data is no longer possible. A pool or vdev enters the `Faulted` state when the number of missing or failed devices exceeds the level of redundancy in the vdev. If reconnecting missing devices the pool will return to an <<zfs-term-online,Online>> state. Insufficient redundancy to compensate for the number of failed disks loses the pool contents and requires restoring from backups."
msgstr ""

#, fuzzy, no-wrap
#~ msgid ""
#~ "Using an entire disk as part of a bootable pool is strongly discouraged, as this may render the pool unbootable.\n"
#~ "Likewise, you should not use an entire disk as part of a mirror or RAID-Z vdev.\n"
#~ "Reliably determining the size of an unpartitioned disk at boot time is impossible and because there's no place to put in boot code.\n"
#~ "====\n"
#~ msgstr "强烈建议不要将整个磁盘用作可引导存储池的一部分，因为这可能会使存储池无法启动。同样，不应将整个磁盘用作镜像或<acronym>RAID-Z</acronym> vdev 的一部分。这是因为在引导时无法可靠地确定未分区磁盘的大小，并且无法放入引导代码。\n"

#, fuzzy
#~ msgid ""
#~ "In a RAID-Z1 configuration with four disks, each 1 TB, usable storage is "
#~ "3 TB and the pool will still be able to operate in degraded mode with one "
#~ "faulted disk. If another disk goes offline before replacing and "
#~ "resilvering the faulted disk would result in losing all pool data."
#~ msgstr ""
#~ "在<acronym>RAID-Z1</acronym> 配置4 个磁盘，每个磁盘1 TB，可用的储存空间则"
#~ "为3 TB，且若其中一个磁盘故障仍可以降级(Degraded）的模式运作，若在故障磁盘"
#~ "尚未更换并修复(Resilver）之前又有磁盘故障，所有在存储池中的资料便会遗失。"

#, fuzzy
#~ msgid ""
#~ "A configuration of two RAID-Z2 vdevs consisting of 8 disks each would "
#~ "create something like a RAID-60 array. A RAID-Z group's storage capacity "
#~ "is about the size of the smallest disk multiplied by the number of non-"
#~ "parity disks. Four 1 TB disks in RAID-Z1 has an effective size of about 3 "
#~ "TB, and an array of eight 1 TB disks in RAID-Z3 will yield 5 TB of usable "
#~ "space."
#~ msgstr ""
#~ "两个 <acronym>RAID-Z2</acronym> vdev 的配置，每个 vdev 由 8 个硬盘组成，将"
#~ "创建类似于 <acronym>RAID-60</acronym> 的阵列。一个 <acronym>RAID-Z</"
#~ "acronym> 的存储容量大约是最小硬盘的大小乘以非同位硬盘的数量。在"
#~ "<acronym>RAID-Z1</acronym>中，4个1TB的硬盘的有效容量大约为3TB，而在"
#~ "<acronym>RAID-Z3</acronym>中，8个1TB的硬盘组成的阵列可用空间为 5TB。"

#~ msgid "Compression can be disabled with:"
#~ msgstr "可以使用以下命令关闭压缩功能："

#~ msgid ""
#~ "This indicates that the device was previously taken offline by the "
#~ "administrator with this command:"
#~ msgstr "这表示设备在之前已经被管理人员用以下命令下线："

#, fuzzy
#~ msgid ""
#~ "Now the system can be powered down to replace [.filename]#da1#.  When the "
#~ "system is back online, the failed disk can replaced in the pool:"
#~ msgstr ""
#~ "现在系统可以关机然后更换 <filename>da1</filename>，当系统回复上线，就可以"
#~ "替换掉存储池中故障的磁盘："

#~ msgid "This configuration is required:"
#~ msgstr "必要的环境设定："

#~ msgid "Redundant data is detected and deduplicated:"
#~ msgstr "已经侦测到重复的资料并做去重复："

#, no-wrap
#~ msgid "Additional Resources"
#~ msgstr "更多资源"

#, fuzzy
#~ msgid ""
#~ "_Syncing_ - All of the data in the transaction group is written to stable "
#~ "storage. This process will in turn modify other data, such as metadata "
#~ "and space maps, that will also need to be written to stable storage. The "
#~ "process of syncing involves multiple passes. The first, all of the "
#~ "changed data blocks, is the biggest, followed by the metadata, which may "
#~ "take multiple passes to complete. Since allocating space for the data "
#~ "blocks generates new metadata, the syncing state cannot finish until a "
#~ "pass completes that does not allocate any additional space. The syncing "
#~ "state is also where _synctasks_ are completed. Synctasks are "
#~ "administrative operations, such as creating or destroying snapshots and "
#~ "datasets, that modify the uberblock are completed. Once the sync state is "
#~ "complete, the transaction group in the quiescing state is advanced to the "
#~ "syncing state."
#~ msgstr ""
#~ "<emphasis>同步中(Syncing)</emphasis> - 所有在交易群组中的资料会被写任到稳"
#~ "定的储存空间，这个程序会依序修改其他也需同样写入到稳定储存空间的资料，如"
#~ "Metadata 与空间对应表。同步的程多会牵涉多个循环，首先是同步所有更改的资料"
#~ "区块，也是最大的部份，接着是 Metadata，这可能会需要多个循环来完成。由于要"
#~ "配置空间供资料区块使用会产生新的 Metadata，同步中状态在到达循环完成而不再"
#~ "需要分配任何额外空间的状态前无法结束。同步中状态也是完成 "
#~ "<emphasis>synctask</emphasis> 的地方，Synctask 是指管理操作，如：建立或摧"
#~ "毁快照与数据集，会修改 uberblock，也会在此时完成。同步状态完成后，其他处于"
#~ "状态中状态的交易群组便会进入同步中状态。"
