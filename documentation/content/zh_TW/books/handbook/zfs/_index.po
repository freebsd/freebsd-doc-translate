# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR The FreeBSD Project
# This file is distributed under the same license as the FreeBSD Documentation package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
msgid ""
msgstr ""
"Project-Id-Version: FreeBSD Documentation VERSION\n"
"POT-Creation-Date: 2021-06-03 17:02-0300\n"
"PO-Revision-Date: 2021-06-03 00:07+0000\n"
"Last-Translator: Anonymous <noreply@weblate.org>\n"
"Language-Team: Chinese (Traditional) <https://translate-dev.freebsd.org/"
"projects/documentation/bookshandbookzfs_index/zh_TW/>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Weblate 4.6.2\n"

#. type: YAML Front Matter: description
#: documentation/content/en/books/handbook/zfs/_index.adoc:1
#, no-wrap
msgid "The Z File System, or ZFS, is an advanced file system designed to overcome many of the major problems found in previous designs"
msgstr ""

#. type: YAML Front Matter: part
#: documentation/content/en/books/handbook/zfs/_index.adoc:1
#, no-wrap
msgid "Part III. System Administration"
msgstr ""

#. type: YAML Front Matter: title
#: documentation/content/en/books/handbook/zfs/_index.adoc:1
#, no-wrap
msgid "Chapter 20. The Z File System (ZFS)"
msgstr ""

#. type: Title =
#: documentation/content/en/books/handbook/zfs/_index.adoc:11
#, no-wrap
msgid "The Z File System (ZFS)"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:47
msgid ""
"The _Z File System_, or ZFS, is an advanced file system designed to overcome "
"many of the major problems found in previous designs."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:49
msgid ""
"Originally developed at Sun(TM), ongoing open source ZFS development has "
"moved to the http://open-zfs.org[OpenZFS Project]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:51
msgid "ZFS has three major design goals:"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:53
msgid ""
"Data integrity: All data includes a <<zfs-term-checksum,checksum>> of the "
"data. When data is written, the checksum is calculated and written along "
"with it. When that data is later read back, the checksum is calculated "
"again. If the checksums do not match, a data error has been detected. ZFS "
"will attempt to automatically correct errors when data redundancy is "
"available."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:54
msgid ""
"Pooled storage: physical storage devices are added to a pool, and storage "
"space is allocated from that shared pool. Space is available to all file "
"systems, and can be increased by adding new storage devices to the pool."
msgstr ""
"儲存池：實體的儲存裝置都會先被加入到一個儲存池 (Pool)，這個共用的儲存池可用來"
"配置儲存空間，儲存池的空間可被所有的檔案系統使用且透過加入新的儲存裝置來增加"
"空間。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:55
#, fuzzy
msgid ""
"Performance: multiple caching mechanisms provide increased performance. "
"<<zfs-term-arc,ARC>> is an advanced memory-based read cache. A second level "
"of disk-based read cache can be added with <<zfs-term-l2arc,L2ARC>>, and "
"disk-based synchronous write cache is available with <<zfs-term-zil,ZIL>>."
msgstr ""
"效能：提供多個快取機制來增加效能。先進、以記憶體為基礎的讀取快取可使用 <link "
"linkend=\"zfs-term-arc\">ARC</link>。第二層以磁碟為基礎的讀取快取可使用 "
"<link linkend=\"zfs-term-l2arc\">L2ARC</link>，以磁碟為基礎的同步寫入快取則可"
"使用 <link linkend=\"zfs-term-zil\">ZIL</link>。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:57
msgid "A complete list of features and terminology is shown in <<zfs-term>>."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:59
#, no-wrap
msgid "What Makes ZFS Different"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:62
#, fuzzy
msgid ""
"ZFS is significantly different from any previous file system because it is "
"more than just a file system. Combining the traditionally separate roles of "
"volume manager and file system provides ZFS with unique advantages. The file "
"system is now aware of the underlying structure of the disks. Traditional "
"file systems could only be created on a single disk at a time. If there were "
"two disks then two separate file systems would have to be created. In a "
"traditional hardware RAID configuration, this problem was avoided by "
"presenting the operating system with a single logical disk made up of the "
"space provided by a number of physical disks, on top of which the operating "
"system placed a file system. Even in the case of software RAID solutions "
"like those provided by GEOM, the UFS file system living on top of the RAID "
"transform believed that it was dealing with a single device. ZFS's "
"combination of the volume manager and the file system solves this and allows "
"the creation of many file systems all sharing a pool of available storage. "
"One of the biggest advantages to ZFS's awareness of the physical layout of "
"the disks is that existing file systems can be grown automatically when "
"additional disks are added to the pool. This new space is then made "
"available to all of the file systems. ZFS also has a number of different "
"properties that can be applied to each file system, giving many advantages "
"to creating a number of different file systems and datasets rather than a "
"single monolithic file system."
msgstr ""
"<acronym>ZFS</acronym> 與以往任何的檔案系統有顯著的不同，因為它不只是一個檔案"
"系統，<acronym>ZFS</acronym> 的獨特優點來自結合了以往被分開的磁碟區管理程式 "
"(Volume Manager) 及檔案系統兩個角色，讓檔案系統也能夠察覺磁碟底層結構的變動。"
"傳統在一個磁碟上只能建立一個檔案系統，若有兩個磁碟則會需要建立兩個分開的檔案"
"系統，在傳統要解決這個問題要使用硬體 <acronym>RAID</acronym> 來製作一個空間實"
"際上由數顆實體磁碟所組成的單一的邏輯磁碟給作業系統，作業系統便可在這個邏輯磁"
"碟上放置檔案系統，即使是在那些使用 <acronym>GEOM</acronym> 提供的軟體 "
"<acronym>RAID</acronym> 解決方案也是一樣，把 <acronym>UFS</acronym> 檔案系統"
"放在 <acronym>RAID</acronym> Transform 上面當做是一個單一的裝置。"
"<acronym>ZFS</acronym> 結合了磁碟區管理程式 (Volume Manager) 與檔案系統來解決"
"這個問題並讓建立多個檔案系統可以共用一個儲存池 (Pool)。<acronym>ZFS</"
"acronym> 最大的優點是可以察覺實體磁碟配置的變動，當有額外的磁碟加入到儲存池時"
"可以自動擴增現有的檔案系統，所有的檔案系統便可使用這個新的空間。"
"<acronym>ZFS</acronym> 也有數個不同的屬性可以套用到各別檔案系統上，比起單一檔"
"案系統，對建立數個不同檔案系統與資料集 (Dataset) 時有許多的好處。"

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:64
#, no-wrap
msgid "Quick Start Guide"
msgstr "快速入門指南"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:67
msgid ""
"There is a startup mechanism that allows FreeBSD to mount ZFS pools during "
"system initialization. To enable it, add this line to [.filename]#/etc/rc."
"conf#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:71
#, no-wrap
msgid "zfs_enable=\"YES\"\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:74
msgid "Then start the service:"
msgstr "然後啟動服務："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:78
#, no-wrap
msgid "# service zfs start\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:81
msgid ""
"The examples in this section assume three SCSI disks with the device names [."
"filename]#da0#, [.filename]#da1#, and [.filename]#da2#. Users of SATA "
"hardware should instead use [.filename]#ada# device names."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:83
#, no-wrap
msgid "Single Disk Pool"
msgstr "單磁碟儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:86
msgid "To create a simple, non-redundant pool using a single disk device:"
msgstr "要使用一個磁碟裝置建立一個簡單、無備援的儲存池可："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:90
#, no-wrap
msgid "# zpool create example /dev/da0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:93
msgid "To view the new pool, review the output of `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:102
#, no-wrap
msgid ""
"# df\n"
"Filesystem  1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a   2026030  235230  1628718    13%    /\n"
"devfs               1       1        0   100%    /dev\n"
"/dev/ad0s1d  54098308 1032846 48737598     2%    /usr\n"
"example      17547136       0 17547136     0%    /example\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:105
msgid ""
"This output shows that the `example` pool has been created and mounted. It "
"is now accessible as a file system. Files can be created on it and users can "
"browse it:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:116
#, no-wrap
msgid ""
"# cd /example\n"
"# ls\n"
"# touch testfile\n"
"# ls -al\n"
"total 4\n"
"drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .\n"
"drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..\n"
"-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:119
msgid ""
"However, this pool is not taking advantage of any ZFS features. To create a "
"dataset on this pool with compression enabled:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:124
#, no-wrap
msgid ""
"# zfs create example/compressed\n"
"# zfs set compression=gzip example/compressed\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:127
msgid ""
"The `example/compressed` dataset is now a ZFS compressed file system. Try "
"copying some large files to [.filename]#/example/compressed#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:129
msgid "Compression can be disabled with:"
msgstr "壓縮功能也可以使用以下指令關閉："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:133
#, no-wrap
msgid "# zfs set compression=off example/compressed\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:136
msgid "To unmount a file system, use `zfs umount` and then verify with `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:146
#, no-wrap
msgid ""
"# zfs umount example/compressed\n"
"# df\n"
"Filesystem  1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a   2026030  235232  1628716    13%    /\n"
"devfs               1       1        0   100%    /dev\n"
"/dev/ad0s1d  54098308 1032864 48737580     2%    /usr\n"
"example      17547008       0 17547008     0%    /example\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:149
msgid ""
"To re-mount the file system to make it accessible again, use `zfs mount` and "
"verify with `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:160
#, no-wrap
msgid ""
"# zfs mount example/compressed\n"
"# df\n"
"Filesystem         1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a          2026030  235234  1628714    13%    /\n"
"devfs                      1       1        0   100%    /dev\n"
"/dev/ad0s1d         54098308 1032864 48737580     2%    /usr\n"
"example             17547008       0 17547008     0%    /example\n"
"example/compressed  17547008       0 17547008     0%    /example/compressed\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:163
msgid ""
"The pool and file system may also be observed by viewing the output from "
"`mount`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:172
#, no-wrap
msgid ""
"# mount\n"
"/dev/ad0s1a on / (ufs, local)\n"
"devfs on /dev (devfs, local)\n"
"/dev/ad0s1d on /usr (ufs, local, soft-updates)\n"
"example on /example (zfs, local)\n"
"example/compressed on /example/compressed (zfs, local)\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:175
msgid ""
"After creation, ZFS datasets can be used like any file systems. However, "
"many other features are available which can be set on a per-dataset basis. "
"In the example below, a new file system called `data` is created. Important "
"files will be stored here, so it is configured to keep two copies of each "
"data block:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:180
#, no-wrap
msgid ""
"# zfs create example/data\n"
"# zfs set copies=2 example/data\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:183
msgid ""
"It is now possible to see the data and space utilization by issuing `df`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:194
#, no-wrap
msgid ""
"# df\n"
"Filesystem         1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a          2026030  235234  1628714    13%    /\n"
"devfs                      1       1        0   100%    /dev\n"
"/dev/ad0s1d         54098308 1032864 48737580     2%    /usr\n"
"example             17547008       0 17547008     0%    /example\n"
"example/compressed  17547008       0 17547008     0%    /example/compressed\n"
"example/data        17547008       0 17547008     0%    /example/data\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:197
msgid ""
"Notice that each file system on the pool has the same amount of available "
"space. This is the reason for using `df` in these examples, to show that the "
"file systems use only the amount of space they need and all draw from the "
"same pool. ZFS eliminates concepts such as volumes and partitions, and "
"allows multiple file systems to occupy the same pool."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:199
msgid ""
"To destroy the file systems and then destroy the pool as it is no longer "
"needed:"
msgstr "不需要使用時可摧毀檔案系統後再摧毀儲存池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:205
#, no-wrap
msgid ""
"# zfs destroy example/compressed\n"
"# zfs destroy example/data\n"
"# zpool destroy example\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:208
#, no-wrap
msgid "RAID-Z"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:211
msgid ""
"Disks fail. One method of avoiding data loss from disk failure is to "
"implement RAID. ZFS supports this feature in its pool design. RAID-Z pools "
"require three or more disks but provide more usable space than mirrored "
"pools."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:213
msgid ""
"This example creates a RAID-Z pool, specifying the disks to add to the pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:217
#, no-wrap
msgid "# zpool create storage raidz da0 da1 da2\n"
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:222
msgid ""
"Sun(TM) recommends that the number of devices used in a RAID-Z configuration "
"be between three and nine. For environments requiring a single pool "
"consisting of 10 disks or more, consider breaking it up into smaller RAID-Z "
"groups. If only two disks are available and redundancy is a requirement, "
"consider using a ZFS mirror. Refer to man:zpool[8] for more details."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:225
msgid ""
"The previous example created the `storage` zpool. This example makes a new "
"file system called `home` in that pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:229
#, no-wrap
msgid "# zfs create storage/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:232
msgid ""
"Compression and keeping extra copies of directories and files can be enabled:"
msgstr "可以設定開啟壓縮及保留目錄及檔案額外備份的功能："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:237
#, no-wrap
msgid ""
"# zfs set copies=2 storage/home\n"
"# zfs set compression=gzip storage/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:240
msgid ""
"To make this the new home directory for users, copy the user data to this "
"directory and create the appropriate symbolic links:"
msgstr ""
"要讓這個空間作為使用者的新家目錄位置，需複製使用者資料到這個目錄並建立適合的"
"符號連結 (Symbolic link)："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:247
#, no-wrap
msgid ""
"# cp -rp /home/* /storage/home\n"
"# rm -rf /home /usr/home\n"
"# ln -s /storage/home /home\n"
"# ln -s /storage/home /usr/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:250
#, fuzzy
msgid ""
"Users data is now stored on the freshly-created [.filename]#/storage/home#. "
"Test by adding a new user and logging in as that user."
msgstr ""
"現在使用者的資料會儲存在新建立的 <filename>/storage/home</filename>，可以加入"
"新使用者並登入該使用者來測試。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:252
msgid "Try creating a file system snapshot which can be rolled back later:"
msgstr "試著建立檔案系統快照 (Snapshot)，稍後可用來還原 (Rollback)："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:256
#, no-wrap
msgid "# zfs snapshot storage/home@08-30-08\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:259
msgid ""
"Snapshots can only be made of a full file system, not a single directory or "
"file."
msgstr "快照只可以使用整個檔案系統製作，無法使用各別目錄或檔案。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:261
#, fuzzy
msgid ""
"The `@` character is a delimiter between the file system name or the volume "
"name. If an important directory has been accidentally deleted, the file "
"system can be backed up, then rolled back to an earlier snapshot when the "
"directory still existed:"
msgstr ""
"<literal>@</literal> 字元用來區隔檔案系統名稱 (File system) 或磁碟區 "
"(Volume) 名稱，若有重要的目錄意外被刪除，檔案系統可以備份然後還原到先前目錄還"
"存在時的快照 (Snapshot)："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:265
#, no-wrap
msgid "# zfs rollback storage/home@08-30-08\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:268
msgid ""
"To list all available snapshots, run `ls` in the file system's [.filename]#."
"zfs/snapshot# directory. For example, to see the previously taken snapshot:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:272
#, no-wrap
msgid "# ls /storage/home/.zfs/snapshot\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:275
msgid ""
"It is possible to write a script to perform regular snapshots on user data. "
"However, over time, snapshots can consume a great deal of disk space. The "
"previous snapshot can be removed using the command:"
msgstr ""
"也可以寫一個 Script 來對使用者資料做例行性的快照，但隨著時間快照可能消耗大量"
"的磁碟空間。先前的快照可以使用指令移除："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:279
#, no-wrap
msgid "# zfs destroy storage/home@08-30-08\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:282
msgid ""
"After testing, [.filename]#/storage/home# can be made the real [.filename]#/"
"home# using this command:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:286
#, no-wrap
msgid "# zfs set mountpoint=/home storage/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:289
msgid ""
"Run `df` and `mount` to confirm that the system now treats the file system "
"as the real [.filename]#/home#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:305
#, no-wrap
msgid ""
"# mount\n"
"/dev/ad0s1a on / (ufs, local)\n"
"devfs on /dev (devfs, local)\n"
"/dev/ad0s1d on /usr (ufs, local, soft-updates)\n"
"storage on /storage (zfs, local)\n"
"storage/home on /home (zfs, local)\n"
"# df\n"
"Filesystem   1K-blocks    Used    Avail Capacity  Mounted on\n"
"/dev/ad0s1a    2026030  235240  1628708    13%    /\n"
"devfs                1       1        0   100%    /dev\n"
"/dev/ad0s1d   54098308 1032826 48737618     2%    /usr\n"
"storage       26320512       0 26320512     0%    /storage\n"
"storage/home  26320512       0 26320512     0%    /home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:308
msgid ""
"This completes the RAID-Z configuration. Daily status updates about the file "
"systems created can be generated as part of the nightly man:periodic[8] "
"runs. Add this line to [.filename]#/etc/periodic.conf#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:312
#, no-wrap
msgid "daily_status_zfs_enable=\"YES\"\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:315
#, no-wrap
msgid "Recovering RAID-Z"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:318
msgid ""
"Every software RAID has a method of monitoring its `state`. The status of "
"RAID-Z devices may be viewed with this command:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:322
#, no-wrap
msgid "# zpool status -x\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:325
msgid ""
"If all pools are <<zfs-term-online,Online>> and everything is normal, the "
"message shows:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:329
#, no-wrap
msgid "all pools are healthy\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:332
msgid ""
"If there is an issue, perhaps a disk is in the <<zfs-term-offline,Offline>> "
"state, the pool state will look similar to:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:344
#, no-wrap
msgid ""
"  pool: storage\n"
" state: DEGRADED\n"
"status: One or more devices has been taken offline by the administrator.\n"
"\tSufficient replicas exist for the pool to continue functioning in a\n"
"\tdegraded state.\n"
"action: Online the device using 'zpool online' or replace the device with\n"
"\t'zpool replace'.\n"
" scrub: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:351
#, no-wrap
msgid ""
"\tNAME        STATE     READ WRITE CKSUM\n"
"\tstorage     DEGRADED     0     0     0\n"
"\t  raidz1    DEGRADED     0     0     0\n"
"\t    da0     ONLINE       0     0     0\n"
"\t    da1     OFFLINE      0     0     0\n"
"\t    da2     ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:353
#: documentation/content/en/books/handbook/zfs/_index.adoc:387
#: documentation/content/en/books/handbook/zfs/_index.adoc:427
#: documentation/content/en/books/handbook/zfs/_index.adoc:461
#: documentation/content/en/books/handbook/zfs/_index.adoc:484
#: documentation/content/en/books/handbook/zfs/_index.adoc:510
#: documentation/content/en/books/handbook/zfs/_index.adoc:579
#: documentation/content/en/books/handbook/zfs/_index.adoc:625
#: documentation/content/en/books/handbook/zfs/_index.adoc:661
#: documentation/content/en/books/handbook/zfs/_index.adoc:687
#: documentation/content/en/books/handbook/zfs/_index.adoc:760
#: documentation/content/en/books/handbook/zfs/_index.adoc:826
#: documentation/content/en/books/handbook/zfs/_index.adoc:855
#: documentation/content/en/books/handbook/zfs/_index.adoc:940
#: documentation/content/en/books/handbook/zfs/_index.adoc:977
#: documentation/content/en/books/handbook/zfs/_index.adoc:1001
#: documentation/content/en/books/handbook/zfs/_index.adoc:1021
#, no-wrap
msgid "errors: No known data errors\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:356
msgid ""
"This indicates that the device was previously taken offline by the "
"administrator with this command:"
msgstr "這代表著裝置在之前被管理者使用此指令拿下線："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:360
#, no-wrap
msgid "# zpool offline storage da1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:363
#, fuzzy
msgid ""
"Now the system can be powered down to replace [.filename]#da1#. When the "
"system is back online, the failed disk can replaced in the pool:"
msgstr ""
"現在系統可以關機然後更換 <filename>da1</filename>，當系統恢復上線，則可以替換"
"掉儲存池中故障的磁碟："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:367
#, no-wrap
msgid "# zpool replace storage da1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:370
msgid ""
"From here, the status may be checked again, this time without `-x` so that "
"all pools are shown:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:378
#, no-wrap
msgid ""
"# zpool status storage\n"
" pool: storage\n"
" state: ONLINE\n"
" scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:385
#: documentation/content/en/books/handbook/zfs/_index.adoc:425
#, no-wrap
msgid ""
"\tNAME        STATE     READ WRITE CKSUM\n"
"\tstorage     ONLINE       0     0     0\n"
"\t  raidz1    ONLINE       0     0     0\n"
"\t    da0     ONLINE       0     0     0\n"
"\t    da1     ONLINE       0     0     0\n"
"\t    da2     ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:390
msgid "In this example, everything is normal."
msgstr "在這個例子中，所有的磁碟均已正常運作。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:392
#, no-wrap
msgid "Data Verification"
msgstr "資料檢驗"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:395
msgid ""
"ZFS uses checksums to verify the integrity of stored data. These are enabled "
"automatically upon creation of file systems."
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:400
msgid ""
"Checksums can be disabled, but it is _not_ recommended! Checksums take very "
"little storage space and provide data integrity. Many ZFS features will not "
"work properly with checksums disabled. There is no noticeable performance "
"gain from disabling these checksums."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:403
msgid ""
"Checksum verification is known as _scrubbing_. Verify the data integrity of "
"the `storage` pool with this command:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:407
#, no-wrap
msgid "# zpool scrub storage\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:410
msgid ""
"The duration of a scrub depends on the amount of data stored. Larger amounts "
"of data will take proportionally longer to verify. Scrubs are very I/O "
"intensive, and only one scrub is allowed to run at a time. After the scrub "
"completes, the status can be viewed with `status`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:418
#, no-wrap
msgid ""
"# zpool status storage\n"
" pool: storage\n"
" state: ONLINE\n"
" scrub: scrub completed with 0 errors on Sat Jan 26 19:57:37 2013\n"
"config:\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:430
msgid ""
"The completion date of the last scrub operation is displayed to help track "
"when another scrub is required. Routine scrubs help protect data from silent "
"corruption and ensure the integrity of the pool."
msgstr ""
"查詢結果會顯示上次完成清潔的時間來協助追蹤是否要再做清潔。定期清潔可以協助保"
"護資料不會默默損壞且確保儲存池的完整性。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:432
msgid "Refer to man:zfs[8] and man:zpool[8] for other ZFS options."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:434
#, no-wrap
msgid "`zpool` Administration"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:437
msgid ""
"ZFS administration is divided between two main utilities. The `zpool` "
"utility controls the operation of the pool and deals with adding, removing, "
"replacing, and managing disks. The <<zfs-zfs,`zfs`>> utility deals with "
"creating, destroying, and managing datasets, both <<zfs-term-filesystem,file "
"systems>> and <<zfs-term-volume,volumes>>."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:439
#, no-wrap
msgid "Creating and Destroying Storage Pools"
msgstr "建立與摧毀儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:442
msgid ""
"Creating a ZFS storage pool (_zpool_) involves making a number of decisions "
"that are relatively permanent because the structure of the pool cannot be "
"changed after the pool has been created. The most important decision is what "
"types of vdevs into which to group the physical disks. See the list of <<zfs-"
"term-vdev,vdev types>> for details about the possible options. After the "
"pool has been created, most vdev types do not allow additional disks to be "
"added to the vdev. The exceptions are mirrors, which allow additional disks "
"to be added to the vdev, and stripes, which can be upgraded to mirrors by "
"attaching an additional disk to the vdev. Although additional vdevs can be "
"added to expand a pool, the layout of the pool cannot be changed after pool "
"creation. Instead, the data must be backed up and the pool destroyed and "
"recreated."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:444
msgid "Create a simple mirror pool:"
msgstr "建立一個簡單的鏡像儲存池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:453
#, no-wrap
msgid ""
"# zpool create mypool mirror /dev/ada1 /dev/ada2\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:459
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada1    ONLINE       0     0     0\n"
"            ada2    ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:464
msgid ""
"Multiple vdevs can be created at once. Specify multiple groups of disks "
"separated by the vdev type keyword, `mirror` in this example:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:473
#, no-wrap
msgid ""
"# zpool create mypool mirror /dev/ada1 /dev/ada2 mirror /dev/ada3 /dev/ada4\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:482
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada1    ONLINE       0     0     0\n"
"            ada2    ONLINE       0     0     0\n"
"          mirror-1  ONLINE       0     0     0\n"
"            ada3    ONLINE       0     0     0\n"
"            ada4    ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:487
#, fuzzy
msgid ""
"Pools can also be constructed using partitions rather than whole disks. "
"Putting ZFS in a separate partition allows the same disk to have other "
"partitions for other purposes. In particular, partitions with bootcode and "
"file systems needed for booting can be added. This allows booting from disks "
"that are also members of a pool. There is no performance penalty on FreeBSD "
"when using a partition rather than a whole disk. Using partitions also "
"allows the administrator to _under-provision_ the disks, using less than the "
"full capacity. If a future replacement disk of the same nominal size as the "
"original actually has a slightly smaller capacity, the smaller partition "
"will still fit, and the replacement disk can still be used."
msgstr ""
"儲存池也可以不使用整個磁碟而改使用分割區 (Partition) 來建立。把 "
"<acronym>ZFS</acronym> 放到不同的分割區可讓同一個磁碟有其他的分割區可做其他用"
"途，尤其是有 Bootcode 與檔案系統要用來開機的分割區，這讓磁碟可以用來開機也同"
"樣可以做為儲存池的一部份。在 FreeBSD 用分割區來替代整個磁碟並不會對效能有影"
"響。使用分割區也讓管理者可以對磁碟容量做 <emphasis>少算的預備</emphasis>，使"
"用比完整容量少的容量，未來若要替換的磁碟號稱與原磁碟相同，但實際上卻比較小"
"時，也可符合這個較小的分割區容量，以使用替換的磁碟。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:489
msgid "Create a <<zfs-term-vdev-raidz,RAID-Z2>> pool using partitions:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:498
#, no-wrap
msgid ""
"# zpool create mypool raidz2 /dev/ada0p3 /dev/ada1p3 /dev/ada2p3 /dev/ada3p3 /dev/ada4p3 /dev/ada5p3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:508
#: documentation/content/en/books/handbook/zfs/_index.adoc:685
#: documentation/content/en/books/handbook/zfs/_index.adoc:853
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          raidz2-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
"            ada3p3  ONLINE       0     0     0\n"
"            ada4p3  ONLINE       0     0     0\n"
"            ada5p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:513
#, fuzzy
msgid ""
"A pool that is no longer needed can be destroyed so that the disks can be "
"reused. Destroying a pool involves first unmounting all of the datasets in "
"that pool. If the datasets are in use, the unmount operation will fail and "
"the pool will not be destroyed. The destruction of the pool can be forced "
"with `-f`, but this can cause undefined behavior in applications which had "
"open files on those datasets."
msgstr ""
"不需使用的儲存池可以摧毀，來讓磁碟可以再次使用。摧毀一個儲存池要先卸載所有該"
"儲存池的資料集。若資料集在使用中，卸載的操作會失敗且儲存池不會被摧毀。儲存池"
"的摧毀可以使用 <option>-f</option> 來強制執行，但這可能造成那些有開啟這些資料"
"集之中檔案的應用程式無法辨識的行為。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:515
#, no-wrap
msgid "Adding and Removing Devices"
msgstr "加入與移除裝置"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:518
msgid ""
"There are two cases for adding disks to a zpool: attaching a disk to an "
"existing vdev with `zpool attach`, or adding vdevs to the pool with `zpool "
"add`. Only some <<zfs-term-vdev,vdev types>> allow disks to be added to the "
"vdev after creation."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:520
#, fuzzy
msgid ""
"A pool created with a single disk lacks redundancy. Corruption can be "
"detected but not repaired, because there is no other copy of the data. The "
"<<zfs-term-copies,copies>> property may be able to recover from a small "
"failure such as a bad sector, but does not provide the same level of "
"protection as mirroring or RAID-Z. Starting with a pool consisting of a "
"single disk vdev, `zpool attach` can be used to add an additional disk to "
"the vdev, creating a mirror. `zpool attach` can also be used to add "
"additional disks to a mirror group, increasing redundancy and read "
"performance. If the disks being used for the pool are partitioned, replicate "
"the layout of the first disk on to the second. `gpart backup` and `gpart "
"restore` can be used to make this process easier."
msgstr ""
"由單一磁碟所建立的儲存池缺乏備援 (Redundancy) 功能，可以偵測到資料的損壞但無"
"法修復，因為資料沒有其他備份可用。備份數 (<link linkend=\"zfs-term-copies"
"\">Copies</link>) 屬性可以讓您從較小的故障中復原，如磁碟壞軌 (Bad sector)，但"
"無法提供與鏡像或 <acronym>RAID-Z</acronym> 同樣層級的保護。由單一磁碟所建立的"
"儲存池可以使用 <command>zpool attach</command> 來加入額外的磁碟到 vdev，來建"
"立鏡像。<command>zpool attach</command> 也可用來加入額外的磁碟到鏡像群組，來"
"增加備援與讀取效率。若使用的磁碟已有分割區，可以複製該磁碟的分割區配置到另一"
"個，使用 <command>gpart backup</command> 與 <command>gpart restore</command> "
"可讓這件事變的很簡單。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:522
msgid ""
"Upgrade the single disk (stripe) vdev _ada0p3_ to a mirror by attaching "
"_ada1p3_:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:530
#: documentation/content/en/books/handbook/zfs/_index.adoc:708
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:534
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          ada0p3    ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:538
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool attach mypool ada0p3 ada1p3\n"
"Make sure to wait until resilver is done before rebooting.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:541
#, no-wrap
msgid ""
"If you boot from pool 'mypool', you may need to update\n"
"boot code on newly attached disk 'ada1p3'.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:544
#: documentation/content/en/books/handbook/zfs/_index.adoc:724
#, no-wrap
msgid ""
"Assuming you use GPT partitioning and 'da0' is your new boot disk\n"
"you may use the following command:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:558
#, no-wrap
msgid ""
"        gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da0\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada1\n"
"bootcode written to ada1\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: One or more devices is currently being resilvered.  The pool will\n"
"        continue to function, possibly in a degraded state.\n"
"action: Wait for the resilver to complete.\n"
"  scan: resilver in progress since Fri May 30 08:19:19 2014\n"
"        527M scanned out of 781M at 47.9M/s, 0h0m to go\n"
"        527M resilvered, 67.53% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:564
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0  (resilvering)\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:571
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Fri May 30 08:15:58 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:577
#: documentation/content/en/books/handbook/zfs/_index.adoc:602
#: documentation/content/en/books/handbook/zfs/_index.adoc:659
#: documentation/content/en/books/handbook/zfs/_index.adoc:714
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:582
#, fuzzy
msgid ""
"When adding disks to the existing vdev is not an option, as for RAID-Z, an "
"alternative method is to add another vdev to the pool. Additional vdevs "
"provide higher performance, distributing writes across the vdevs. Each vdev "
"is responsible for providing its own redundancy. It is possible, but "
"discouraged, to mix vdev types, like `mirror` and `RAID-Z`. Adding a non-"
"redundant vdev to a pool containing mirror or RAID-Z vdevs risks the data on "
"the entire pool. Writes are distributed, so the failure of the non-redundant "
"disk will result in the loss of a fraction of every block that has been "
"written to the pool."
msgstr ""
"若不想選擇加入磁碟到既有的 vdev ，對 <acronym>RAID-Z</acronym> 來說，可選擇另"
"一種方式，便是加入另一個 vdev 到儲存池。額外的 vdev 可以提供更高的效能，分散"
"寫入資料到 vdev 之間，每個 vdev 會負責自己的備援。也可以混合使用不同的 vdev "
"型態，但並不建議，例如混合使用 <literal>mirror</literal> 與 <literal>RAID-Z</"
"literal>，加入一個無備援的 vdev 到一個含有 mirror 或 <acronym>RAID-Z</"
"acronym> vdev 的儲存池會讓資料損壞的風險擴大整個儲存池，由於會分散寫入資料，"
"若在無備援的磁碟上發生故障的結果便是遺失大半寫到儲存池的資料區塊。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:584
#, fuzzy
msgid ""
"Data is striped across each of the vdevs. For example, with two mirror "
"vdevs, this is effectively a RAID 10 that stripes writes across two sets of "
"mirrors. Space is allocated so that each vdev reaches 100% full at the same "
"time. There is a performance penalty if the vdevs have different amounts of "
"free space, as a disproportionate amount of the data is written to the less "
"full vdev."
msgstr ""
"在每個 vdev 間的資料是串連的，例如，有兩個 mirror vdev，便跟 <acronym>RAID</"
"acronym> 10 一樣在兩個 mirror 間分散寫入資料，且會做空間的分配，因此 vdev 會"
"在同時達到全滿 100% 的用量。若 vdev 間的可用空間量不同則會影響到效能，因為資"
"料量會不成比例的寫入到使用量較少的 vdev。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:586
msgid ""
"When attaching additional devices to a boot pool, remember to update the "
"bootcode."
msgstr "當連接額外的裝置到一個可以開機的儲存池，要記得更新 Bootcode。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:588
msgid ""
"Attach a second mirror group ([.filename]#ada2p3# and [.filename]#ada3p3#) "
"to the existing mirror:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:596
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Fri May 30 08:19:35 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:614
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool add mypool mirror ada2p3 ada3p3\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada2\n"
"bootcode written to ada2\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada3\n"
"bootcode written to ada3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 0h0m with 0 errors on Fri May 30 08:29:51 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:623
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
"          mirror-1  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
"            ada3p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:628
msgid ""
"Currently, vdevs cannot be removed from a pool, and disks can only be "
"removed from a mirror if there is enough remaining redundancy. If only one "
"disk in a mirror group remains, it ceases to be a mirror and reverts to "
"being a stripe, risking the entire pool if that remaining disk fails."
msgstr ""
"現在已無法從儲存池上移除 vdev，且磁碟只能夠在有足夠備援空間的情況下從 mirror "
"移除，若在 mirror 群組中只剩下一個磁碟，便會取消 mirror 然後還原為 stripe，若"
"剩下的那個磁碟故障，便會影響到整個儲存池。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:630
msgid "Remove a disk from a three-way mirror group:"
msgstr "從一個三方 mirror 群組移除一個磁碟："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:638
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 0h0m with 0 errors on Fri May 30 08:29:51 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:645
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada1p3  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:653
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool detach mypool ada2p3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 0h0m with 0 errors on Fri May 30 08:29:51 2014\n"
"config:\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:664
#, no-wrap
msgid "Checking the Status of a Pool"
msgstr "檢查儲存池狀態"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:667
#, fuzzy
msgid ""
"Pool status is important. If a drive goes offline or a read, write, or "
"checksum error is detected, the corresponding error count increases. The "
"`status` output shows the configuration and status of each device in the "
"pool and the status of the entire pool. Actions that need to be taken and "
"details about the last <<zfs-zpool-scrub,`scrub`>> are also shown."
msgstr ""
"儲存池的狀態很重要，若有磁碟機離線或偵測到讀取、寫入或校驗碼 (Checksum) 錯"
"誤，對應的錯誤計數便會增加。<command>status</command> 會顯示儲存池中每一個磁"
"碟機的設定與狀態及整個儲存池的狀態。需要處置的方式與有關最近清潔 (<link "
"linkend=\"zfs-zpool-scrub\"><command>Scrub</command></link>) 的詳細資訊也會一"
"併顯示。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:675
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub repaired 0 in 2h25m with 0 errors on Sat Sep 14 04:25:50 2013\n"
"config:\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:690
#, no-wrap
msgid "Clearing Errors"
msgstr "清除錯誤"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:693
msgid ""
"When an error is detected, the read, write, or checksum counts are "
"incremented. The error message can be cleared and the counts reset with "
"`zpool clear _mypool_`. Clearing the error state can be important for "
"automated scripts that alert the administrator when the pool encounters an "
"error. Further errors may not be reported if the old errors are not cleared."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:695
#, no-wrap
msgid "Replacing a Functioning Device"
msgstr "更換運作中的裝置"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:698
#, fuzzy
msgid ""
"There are a number of situations where it may be desirable to replace one "
"disk with a different disk. When replacing a working disk, the process keeps "
"the old disk online during the replacement. The pool never enters a <<zfs-"
"term-degraded,degraded>> state, reducing the risk of data loss. `zpool "
"replace` copies all of the data from the old disk to the new one. After the "
"operation completes, the old disk is disconnected from the vdev. If the new "
"disk is larger than the old disk, it may be possible to grow the zpool, "
"using the new space. See <<zfs-zpool-online,Growing a Pool>>."
msgstr ""
"可能有一些情況會需要更換磁碟為另一個磁碟，當要更換運作中的磁碟，此程序會維持"
"舊有的磁碟在更換的過程為上線的狀態，儲存池不會進入降級 (<link linkend=\"zfs-"
"term-degraded\">Degraded</link>) 的狀態，來減少資料遺失的風險。"
"<command>zpool replace</command> 會複製所有舊磁碟的資料到新磁碟，操作完成之後"
"舊磁碟便會與 vdev 中斷連線。若新磁碟容量較舊磁碟大，也可以會增加儲存池來使用"
"新的空間，請參考 <link linkend=\"zfs-zpool-online\">擴增儲存池</link>。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:700
msgid "Replace a functioning device in the pool:"
msgstr "更換儲存池中正在運作的狀置："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:718
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool replace mypool ada1p3 ada2p3\n"
"Make sure to wait until resilver is done before rebooting.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:721
#, no-wrap
msgid ""
"If you boot from pool 'zroot', you may need to update\n"
"boot code on newly attached disk 'ada2p3'.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:737
#, no-wrap
msgid ""
"        gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da0\n"
"# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada2\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: One or more devices is currently being resilvered.  The pool will\n"
"        continue to function, possibly in a degraded state.\n"
"action: Wait for the resilver to complete.\n"
"  scan: resilver in progress since Mon Jun  2 14:21:35 2014\n"
"        604M scanned out of 781M at 46.5M/s, 0h0m to go\n"
"        604M resilvered, 77.39% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:745
#, no-wrap
msgid ""
"        NAME             STATE     READ WRITE CKSUM\n"
"        mypool           ONLINE       0     0     0\n"
"          mirror-0       ONLINE       0     0     0\n"
"            ada0p3       ONLINE       0     0     0\n"
"            replacing-1  ONLINE       0     0     0\n"
"              ada1p3     ONLINE       0     0     0\n"
"              ada2p3     ONLINE       0     0     0  (resilvering)\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:752
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Mon Jun  2 14:21:52 2014\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:758
#: documentation/content/en/books/handbook/zfs/_index.adoc:824
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"            ada0p3  ONLINE       0     0     0\n"
"            ada2p3  ONLINE       0     0     0\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:763
#, no-wrap
msgid "Dealing with Failed Devices"
msgstr "處理故障裝置"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:766
msgid ""
"When a disk in a pool fails, the vdev to which the disk belongs enters the "
"<<zfs-term-degraded,degraded>> state. All of the data is still available, "
"but performance may be reduced because missing data must be calculated from "
"the available redundancy. To restore the vdev to a fully functional state, "
"the failed physical device must be replaced. ZFS is then instructed to begin "
"the <<zfs-term-resilver,resilver>> operation. Data that was on the failed "
"device is recalculated from available redundancy and written to the "
"replacement device. After completion, the vdev returns to <<zfs-term-online,"
"online>> status."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:768
#, fuzzy
msgid ""
"If the vdev does not have any redundancy, or if multiple devices have failed "
"and there is not enough redundancy to compensate, the pool enters the <<zfs-"
"term-faulted,faulted>> state. If a sufficient number of devices cannot be "
"reconnected to the pool, the pool becomes inoperative and data must be "
"restored from backups."
msgstr ""
"若 vdev 沒有任何備援資料或有多個裝置故障，沒有足夠的備援資料可以補償，儲存池"
"便會進入故障 (<link linkend=\"zfs-term-faulted\">Faulted</link>) 的狀態。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:770
msgid ""
"When replacing a failed disk, the name of the failed disk is replaced with "
"the GUID of the device. A new device name parameter for `zpool replace` is "
"not required if the replacement device has the same device name."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:772
msgid "Replace a failed disk using `zpool replace`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:784
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: DEGRADED\n"
"status: One or more devices could not be opened.  Sufficient replicas exist for\n"
"        the pool to continue functioning in a degraded state.\n"
"action: Attach the missing device and online it using 'zpool online'.\n"
"   see: http://illumos.org/msg/ZFS-8000-2Q\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:790
#, no-wrap
msgid ""
"        NAME                    STATE     READ WRITE CKSUM\n"
"        mypool                  DEGRADED     0     0     0\n"
"          mirror-0              DEGRADED     0     0     0\n"
"            ada0p3              ONLINE       0     0     0\n"
"            316502962686821739  UNAVAIL      0     0     0  was /dev/ada1p3\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:803
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool replace mypool 316502962686821739 ada2p3\n"
"# zpool status\n"
"  pool: mypool\n"
" state: DEGRADED\n"
"status: One or more devices is currently being resilvered.  The pool will\n"
"        continue to function, possibly in a degraded state.\n"
"action: Wait for the resilver to complete.\n"
"  scan: resilver in progress since Mon Jun  2 14:52:21 2014\n"
"        641M scanned out of 781M at 49.3M/s, 0h0m to go\n"
"        640M resilvered, 82.04% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:811
#, no-wrap
msgid ""
"        NAME                        STATE     READ WRITE CKSUM\n"
"        mypool                      DEGRADED     0     0     0\n"
"          mirror-0                  DEGRADED     0     0     0\n"
"            ada0p3                  ONLINE       0     0     0\n"
"            replacing-1             UNAVAIL      0     0     0\n"
"              15732067398082357289  UNAVAIL      0     0     0  was /dev/ada1p3/old\n"
"              ada2p3                ONLINE       0     0     0  (resilvering)\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:818
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: resilvered 781M in 0h0m with 0 errors on Mon Jun  2 14:52:38 2014\n"
"config:\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:829
#, no-wrap
msgid "Scrubbing a Pool"
msgstr "清潔儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:832
msgid ""
"It is recommended that pools be <<zfs-term-scrub,scrubbed>> regularly, "
"ideally at least once every month. The `scrub` operation is very disk-"
"intensive and will reduce performance while running. Avoid high-demand "
"periods when scheduling `scrub` or use <<zfs-advanced-tuning-scrub_delay,"
"`vfs.zfs.scrub_delay`>> to adjust the relative priority of the `scrub` to "
"prevent it interfering with other workloads."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:843
#, no-wrap
msgid ""
"# zpool scrub mypool\n"
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"  scan: scrub in progress since Wed Feb 19 20:52:54 2014\n"
"        116G scanned out of 8.60T at 649M/s, 3h48m to go\n"
"        0 repaired, 1.32% done\n"
"config:\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:858
msgid ""
"In the event that a scrub operation needs to be cancelled, issue `zpool "
"scrub -s _mypool_`."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:860
#, no-wrap
msgid "Self-Healing"
msgstr "自我修復"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:863
msgid ""
"The checksums stored with data blocks enable the file system to _self-heal_. "
"This feature will automatically repair data whose checksum does not match "
"the one recorded on another device that is part of the storage pool. For "
"example, a mirror with two disks where one drive is starting to malfunction "
"and cannot properly store the data any more. This is even worse when the "
"data has not been accessed for a long time, as with long term archive "
"storage. Traditional file systems need to run algorithms that check and "
"repair the data like man:fsck[8]. These commands take time, and in severe "
"cases, an administrator has to manually decide which repair operation must "
"be performed. When ZFS detects a data block with a checksum that does not "
"match, it tries to read the data from the mirror disk. If that disk can "
"provide the correct data, it will not only give that data to the application "
"requesting it, but also correct the wrong data on the disk that had the bad "
"checksum. This happens without any interaction from a system administrator "
"during normal pool operation."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:865
#, fuzzy
msgid ""
"The next example demonstrates this self-healing behavior. A mirrored pool of "
"disks [.filename]#/dev/ada0# and [.filename]#/dev/ada1# is created."
msgstr ""
"接下來的例子會示範自我修復會如何運作。建立一個使用磁碟 <filename>/dev/ada0</"
"filename> 及 <filename>/dev/ada1</filename> 做鏡像的儲存池。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:874
#, no-wrap
msgid ""
"# zpool create healer mirror /dev/ada0 /dev/ada1\n"
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:880
#: documentation/content/en/books/handbook/zfs/_index.adoc:1019
#, no-wrap
msgid ""
"    NAME        STATE     READ WRITE CKSUM\n"
"    healer      ONLINE       0     0     0\n"
"      mirror-0  ONLINE       0     0     0\n"
"       ada0     ONLINE       0     0     0\n"
"       ada1     ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:885
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool list\n"
"NAME     SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT\n"
"healer   960M  92.5K   960M         -         -     0%    0%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:888
#, fuzzy
msgid ""
"Some important data that have to be protected from data errors using the "
"self-healing feature are copied to the pool. A checksum of the pool is "
"created for later comparison."
msgstr ""
"將部份需要使用自我修復功能來保護的重要資料複製到該儲存池，建立一個儲存池的校"
"驗碼供稍後做比較時使用。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:898
#, no-wrap
msgid ""
"# cp /some/important/data /healer\n"
"# zfs list\n"
"NAME     SIZE  ALLOC   FREE    CAP  DEDUP  HEALTH  ALTROOT\n"
"healer   960M  67.7M   892M     7%  1.00x  ONLINE  -\n"
"# sha1 /healer > checksum.txt\n"
"# cat checksum.txt\n"
"SHA1 (/healer) = 2753eff56d77d9a536ece6694bf0a82740344d1f\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:901
#, fuzzy
msgid ""
"Data corruption is simulated by writing random data to the beginning of one "
"of the disks in the mirror. To prevent ZFS from healing the data as soon as "
"it is detected, the pool is exported before the corruption and imported "
"again afterwards."
msgstr ""
"寫入隨機的資料到鏡像的第一個磁碟來模擬資料損毀的情況。要避免 <acronym>ZFS</"
"acronym> 偵測到錯誤時馬上做修復，接著要將儲存池匯出，待模擬資料損毀之後再匯"
"入。"

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:906
msgid ""
"This is a dangerous operation that can destroy vital data. It is shown here "
"for demonstrational purposes only and should not be attempted during normal "
"operation of a storage pool. Nor should this intentional corruption example "
"be run on any disk with a different file system on it. Do not use any other "
"disk device names other than the ones that are part of the pool. Make "
"certain that proper backups of the pool are created before running the "
"command!"
msgstr ""
"這是一個危險的操作，會破壞重要的資料。在這裡使用僅為了示範用，不應在儲存池正"
"常運作時嘗試使用，也不應將這個故意損壞資料的例子用在任何其他的檔案系統上，所"
"以請勿使用任何不屬於該儲存池的其他磁碟裝置名稱並確定在執行指令前已對儲存池做"
"正確的備份！"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:916
#, no-wrap
msgid ""
"# zpool export healer\n"
"# dd if=/dev/random of=/dev/ada1 bs=1m count=200\n"
"200+0 records in\n"
"200+0 records out\n"
"209715200 bytes transferred in 62.992162 secs (3329227 bytes/sec)\n"
"# zpool import healer\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:919
msgid ""
"The pool status shows that one device has experienced an error. Note that "
"applications reading data from the pool did not receive any incorrect data. "
"ZFS provided data from the [.filename]#ada0# device with the correct "
"checksums. The device with the wrong checksum can be found easily as the "
"`CKSUM` column contains a nonzero value."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:932
#, no-wrap
msgid ""
"# zpool status healer\n"
"    pool: healer\n"
"   state: ONLINE\n"
"  status: One or more devices has experienced an unrecoverable error.  An\n"
"          attempt was made to correct the error.  Applications are unaffected.\n"
"  action: Determine if the device needs to be replaced, and clear the errors\n"
"          using 'zpool clear' or replace the device with 'zpool replace'.\n"
"     see: http://illumos.org/msg/ZFS-8000-4J\n"
"    scan: none requested\n"
"  config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:938
#, no-wrap
msgid ""
"      NAME        STATE     READ WRITE CKSUM\n"
"      healer      ONLINE       0     0     0\n"
"        mirror-0  ONLINE       0     0     0\n"
"         ada0     ONLINE       0     0     0\n"
"         ada1     ONLINE       0     0     1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:943
#, fuzzy
msgid ""
"The error was detected and handled by using the redundancy present in the "
"unaffected [.filename]#ada0# mirror disk. A checksum comparison with the "
"original one will reveal whether the pool is consistent again."
msgstr ""
"錯誤已經被偵測到並且由未被影響的 <filename>ada0</filename> 鏡像磁碟上的備援提"
"供資料。可與原來的校驗碼做比較來看儲存池是否已修復為一致。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:950
#, no-wrap
msgid ""
"# sha1 /healer >> checksum.txt\n"
"# cat checksum.txt\n"
"SHA1 (/healer) = 2753eff56d77d9a536ece6694bf0a82740344d1f\n"
"SHA1 (/healer) = 2753eff56d77d9a536ece6694bf0a82740344d1f\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:953
msgid ""
"The two checksums that were generated before and after the intentional "
"tampering with the pool data still match. This shows how ZFS is capable of "
"detecting and correcting any errors automatically when the checksums differ. "
"Note that this is only possible when there is enough redundancy present in "
"the pool. A pool consisting of a single device has no self-healing "
"capabilities. That is also the reason why checksums are so important in ZFS "
"and should not be disabled for any reason. No man:fsck[8] or similar file "
"system consistency check program is required to detect and correct this and "
"the pool was still available during the time there was a problem. A scrub "
"operation is now required to overwrite the corrupted data on [."
"filename]#ada1#."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:969
#, no-wrap
msgid ""
"# zpool scrub healer\n"
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"status: One or more devices has experienced an unrecoverable error.  An\n"
"            attempt was made to correct the error.  Applications are unaffected.\n"
"action: Determine if the device needs to be replaced, and clear the errors\n"
"            using 'zpool clear' or replace the device with 'zpool replace'.\n"
"   see: http://illumos.org/msg/ZFS-8000-4J\n"
"  scan: scrub in progress since Mon Dec 10 12:23:30 2012\n"
"        10.4M scanned out of 67.0M at 267K/s, 0h3m to go\n"
"        9.63M repaired, 15.56% done\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:975
#, no-wrap
msgid ""
"    NAME        STATE     READ WRITE CKSUM\n"
"    healer      ONLINE       0     0     0\n"
"      mirror-0  ONLINE       0     0     0\n"
"       ada0     ONLINE       0     0     0\n"
"       ada1     ONLINE       0     0   627  (repairing)\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:980
msgid ""
"The scrub operation reads data from [.filename]#ada0# and rewrites any data "
"with an incorrect checksum on [.filename]#ada1#. This is indicated by the "
"`(repairing)` output from `zpool status`. After the operation is complete, "
"the pool status changes to:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:993
#, no-wrap
msgid ""
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"status: One or more devices has experienced an unrecoverable error.  An\n"
"        attempt was made to correct the error.  Applications are unaffected.\n"
"action: Determine if the device needs to be replaced, and clear the errors\n"
"             using 'zpool clear' or replace the device with 'zpool replace'.\n"
"   see: http://illumos.org/msg/ZFS-8000-4J\n"
"  scan: scrub repaired 66.5M in 0h2m with 0 errors on Mon Dec 10 12:26:25 2012\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:999
#, no-wrap
msgid ""
"    NAME        STATE     READ WRITE CKSUM\n"
"    healer      ONLINE       0     0     0\n"
"      mirror-0  ONLINE       0     0     0\n"
"       ada0     ONLINE       0     0     0\n"
"       ada1     ONLINE       0     0 2.72K\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1004
msgid ""
"After the scrub operation completes and all the data has been synchronized "
"from [.filename]#ada0# to [.filename]#ada1#, the error messages can be <<zfs-"
"zpool-clear,cleared>> from the pool status by running `zpool clear`."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1013
#, no-wrap
msgid ""
"# zpool clear healer\n"
"# zpool status healer\n"
"  pool: healer\n"
" state: ONLINE\n"
"  scan: scrub repaired 66.5M in 0h2m with 0 errors on Mon Dec 10 12:26:25 2012\n"
"config:\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1024
msgid ""
"The pool is now back to a fully working state and all the errors have been "
"cleared."
msgstr "儲存池現在恢復完整運作的狀態且清除所有的錯誤了。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1026
#, no-wrap
msgid "Growing a Pool"
msgstr "擴增儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1029
msgid ""
"The usable size of a redundant pool is limited by the capacity of the "
"smallest device in each vdev. The smallest device can be replaced with a "
"larger device. After completing a <<zfs-zpool-replace,replace>> or <<zfs-"
"term-resilver,resilver>> operation, the pool can grow to use the capacity of "
"the new device. For example, consider a mirror of a 1 TB drive and a 2 TB "
"drive. The usable space is 1 TB. When the 1 TB drive is replaced with "
"another 2 TB drive, the resilvering process copies the existing data onto "
"the new drive. As both of the devices now have 2 TB capacity, the mirror's "
"available space can be grown to 2 TB."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1031
msgid ""
"Expansion is triggered by using `zpool online -e` on each device. After "
"expansion of all devices, the additional space becomes available to the pool."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1033
#, no-wrap
msgid "Importing and Exporting Pools"
msgstr "匯入與匯出儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1036
msgid ""
"Pools are _exported_ before moving them to another system. All datasets are "
"unmounted, and each device is marked as exported but still locked so it "
"cannot be used by other disk subsystems. This allows pools to be _imported_ "
"on other machines, other operating systems that support ZFS, and even "
"different hardware architectures (with some caveats, see man:zpool[8]). When "
"a dataset has open files, `zpool export -f` can be used to force the export "
"of a pool. Use this with caution. The datasets are forcibly unmounted, "
"potentially resulting in unexpected behavior by the applications which had "
"open files on those datasets."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1038
msgid "Export a pool that is not in use:"
msgstr "匯出未使用的儲存池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1042
#, no-wrap
msgid "# zpool export mypool\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1045
#, fuzzy
msgid ""
"Importing a pool automatically mounts the datasets. This may not be the "
"desired behavior, and can be prevented with `zpool import -N`. `zpool import "
"-o` sets temporary properties for this import only. `zpool import altroot=` "
"allows importing a pool with a base mount point instead of the root of the "
"file system. If the pool was last used on a different system and was not "
"properly exported, an import might have to be forced with `zpool import -f`. "
"`zpool import -a` imports all pools that do not appear to be in use by "
"another system."
msgstr ""
"匯入儲存池會自動掛載資料集，若不想自動掛載，可以使用 <command>zpool import -"
"N</command>。<command>zpool import -o</command> 可以設定在匯入時暫時使用的屬"
"性。<command>zpool import altroot=</command> 允許匯入時指定基礎掛載點 (Base "
"mount point) 來替換檔案系統根目錄。若儲存池先前用在不同的系統且不正常匯出，可"
"能會需要使用 <command>zpool import -f</command> 來強制匯入。<command>zpool "
"import -a</command> 會匯入所有沒有被其他系統使用的儲存池。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1047
msgid "List all available pools for import:"
msgstr "列出所有可以匯入的儲存池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1056
#, no-wrap
msgid ""
"# zpool import\n"
"   pool: mypool\n"
"     id: 9930174748043525076\n"
"  state: ONLINE\n"
" action: The pool can be imported using its name or numeric identifier.\n"
" config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1059
#, no-wrap
msgid ""
"        mypool      ONLINE\n"
"          ada2p3    ONLINE\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1062
msgid "Import the pool with an alternative root directory:"
msgstr "使用替代的根目錄匯入儲存池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1070
#, no-wrap
msgid ""
"# zpool import -o altroot=/mnt mypool\n"
"# zfs list\n"
"zfs list\n"
"NAME                 USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool               110K  47.0G    31K  /mnt/mypool\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1073
#, no-wrap
msgid "Upgrading a Storage Pool"
msgstr "升級儲存儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1076
#, fuzzy
msgid ""
"After upgrading FreeBSD, or if a pool has been imported from a system using "
"an older version of ZFS, the pool can be manually upgraded to the latest "
"version of ZFS to support newer features. Consider whether the pool may ever "
"need to be imported on an older system before upgrading. Upgrading is a one-"
"way process. Older pools can be upgraded, but pools with newer features "
"cannot be downgraded."
msgstr ""
"在升級 FreeBSD 之後或儲存池是由其他使用舊版 <acronym>ZFS</acronym> 的系統匯"
"入，儲存池可以手動升級到最新版本的 <acronym>ZFS</acronym> 來支援新的功能。在"
"升級前請評估儲存池是否還要在舊的系統做匯入，由於升級是一個單向的程序，舊的儲"
"存池可以升級，但有新功能的儲存池無法降級。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1078
msgid "Upgrade a v28 pool to support `Feature Flags`:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1091
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: The pool is formatted using a legacy on-disk format.  The pool can\n"
"        still be used, but some features are unavailable.\n"
"action: Upgrade the pool using 'zpool upgrade'.  Once this is done, the\n"
"        pool will no longer be accessible on software that does not support feat\n"
"        flags.\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1097
#: documentation/content/en/books/handbook/zfs/_index.adoc:1146
#, no-wrap
msgid ""
"        NAME        STATE     READ WRITE CKSUM\n"
"        mypool      ONLINE       0     0     0\n"
"          mirror-0  ONLINE       0     0     0\n"
"\t    ada0    ONLINE       0     0     0\n"
"\t    ada1    ONLINE       0     0     0\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1101
#: documentation/content/en/books/handbook/zfs/_index.adoc:1150
#, no-wrap
msgid ""
"errors: No known data errors\n"
"# zpool upgrade\n"
"This system supports ZFS pool feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1106
#, no-wrap
msgid ""
"The following pools are formatted with legacy version numbers and can\n"
"be upgraded to use feature flags.  After being upgraded, these pools\n"
"will no longer be accessible by software that does not support feature\n"
"flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1110
#, no-wrap
msgid ""
"VER  POOL\n"
"---  ------------\n"
"28   mypool\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1115
#, no-wrap
msgid ""
"Use 'zpool upgrade -v' for a list of available legacy versions.\n"
"Every feature flags pool has all supported features enabled.\n"
"# zpool upgrade mypool\n"
"This system supports ZFS pool feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1122
#, no-wrap
msgid ""
"Successfully upgraded 'mypool' from version 28 to feature flags.\n"
"Enabled the following features on 'mypool':\n"
"  async_destroy\n"
"  empty_bpobj\n"
"  lz4_compress\n"
"  multi_vdev_crash_dump\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1125
msgid ""
"The newer features of ZFS will not be available until `zpool upgrade` has "
"completed. `zpool upgrade -v` can be used to see what new features will be "
"provided by upgrading, as well as which features are already supported."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1127
msgid "Upgrade a pool to support additional feature flags:"
msgstr "升級儲存池支援新版的功能旗標 (Feature flags)："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1140
#, no-wrap
msgid ""
"# zpool status\n"
"  pool: mypool\n"
" state: ONLINE\n"
"status: Some supported features are not enabled on the pool. The pool can\n"
"        still be used, but some features are unavailable.\n"
"action: Enable all features using 'zpool upgrade'. Once this is done,\n"
"        the pool may no longer be accessible by software that does not support\n"
"        the features. See zpool-features(7) for details.\n"
"  scan: none requested\n"
"config:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1152
#, no-wrap
msgid "All pools are formatted using feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1156
#, no-wrap
msgid ""
"Some supported features are not enabled on the following pools. Once a\n"
"feature is enabled the pool may become incompatible with software\n"
"that does not support the feature. See zpool-features(7) for details.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1169
#, no-wrap
msgid ""
"POOL  FEATURE\n"
"---------------\n"
"zstore\n"
"      multi_vdev_crash_dump\n"
"      spacemap_histogram\n"
"      enabled_txg\n"
"      hole_birth\n"
"      extensible_dataset\n"
"      bookmarks\n"
"      filesystem_limits\n"
"# zpool upgrade mypool\n"
"This system supports ZFS pool feature flags.\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1177
#, no-wrap
msgid ""
"Enabled the following features on 'mypool':\n"
"  spacemap_histogram\n"
"  enabled_txg\n"
"  hole_birth\n"
"  extensible_dataset\n"
"  bookmarks\n"
"  filesystem_limits\n"
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1183
msgid ""
"The boot code on systems that boot from a pool must be updated to support "
"the new pool version. Use `gpart bootcode` on the partition that contains "
"the boot code. There are two types of bootcode available, depending on way "
"the system boots: GPT (the most common option) and EFI (for more modern "
"systems)."
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1185
msgid "For legacy boot using GPT, use the following command:"
msgstr "針對傳統使用 GPT 開機的系統，可以使用以下指令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1189
#, no-wrap
msgid "# gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1192
msgid "For systems using EFI to boot, execute the following command:"
msgstr "針對使用 EFI 開機的系統可以執行以下指令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1196
#, no-wrap
msgid "# gpart bootcode -p /boot/boot1.efifat -i 1 ada1\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1199
msgid ""
"Apply the bootcode to all bootable disks in the pool. See man:gpart[8] for "
"more information."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1202
#, no-wrap
msgid "Displaying Recorded Pool History"
msgstr "顯示已記錄的儲存池歷史日誌"

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1205
#, fuzzy
msgid ""
"Commands that modify the pool are recorded. Recorded actions include the "
"creation of datasets, changing properties, or replacement of a disk. This "
"history is useful for reviewing how a pool was created and which user "
"performed a specific action and when. History is not kept in a log file, but "
"is part of the pool itself. The command to review this history is aptly "
"named `zpool history`:"
msgstr ""
"修改儲存池的指令會被記錄下來，會記錄的動作包含資料集的建立，屬性更改或更換磁"
"碟。這個歷史記錄用來查看儲存池是如何建立、由誰執行、什麼動作及何時。歷史記錄"
"並非儲存在日誌檔 (Log file)，而是儲存在儲存池。查看這個歷史記錄的指令名稱為 "
"<command>zpool history</command>："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1214
#, no-wrap
msgid ""
"# zpool history\n"
"History for 'tank':\n"
"2013-02-26.23:02:35 zpool create tank mirror /dev/ada0 /dev/ada1\n"
"2013-02-27.18:50:58 zfs set atime=off tank\n"
"2013-02-27.18:51:09 zfs set checksum=fletcher4 tank\n"
"2013-02-27.18:51:18 zfs create tank/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1217
#, fuzzy
msgid ""
"The output shows `zpool` and `zfs` commands that were executed on the pool "
"along with a timestamp. Only commands that alter the pool in some way are "
"recorded. Commands like `zfs list` are not included. When no pool name is "
"specified, the history of all pools is displayed."
msgstr ""
"輸出結果顯示曾在該儲存池上執行的 <command>zpool</command> 與 <command>zfs</"
"command> 指令以及時間戳記。只有會修改儲存池或類似的指令會被記錄下來，像是 "
"<command>zfs list</command> 這種指令並不會被記錄。當不指定儲存池名稱時，會列"
"出所有儲存池的歷史記錄。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1219
msgid ""
"`zpool history` can show even more information when the options `-i` or `-l` "
"are provided. `-i` displays user-initiated events as well as internally "
"logged ZFS events."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1231
#, no-wrap
msgid ""
"# zpool history -i\n"
"History for 'tank':\n"
"2013-02-26.23:02:35 [internal pool create txg:5] pool spa 28; zfs spa 28; zpl 5;uts  9.1-RELEASE 901000 amd64\n"
"2013-02-27.18:50:53 [internal property set txg:50] atime=0 dataset = 21\n"
"2013-02-27.18:50:58 zfs set atime=off tank\n"
"2013-02-27.18:51:04 [internal property set txg:53] checksum=7 dataset = 21\n"
"2013-02-27.18:51:09 zfs set checksum=fletcher4 tank\n"
"2013-02-27.18:51:13 [internal create txg:55] dataset = 39\n"
"2013-02-27.18:51:18 zfs create tank/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1234
#, fuzzy
msgid ""
"More details can be shown by adding `-l`. History records are shown in a "
"long format, including information like the name of the user who issued the "
"command and the hostname on which the change was made."
msgstr ""
"更多詳細的資訊可加上 <option>-l</option> 來取得，歷史記錄會以較長的格式顯示，"
"包含的資訊有執行指令的使用者名稱、主機名稱以及更改的項目。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1243
#, no-wrap
msgid ""
"# zpool history -l\n"
"History for 'tank':\n"
"2013-02-26.23:02:35 zpool create tank mirror /dev/ada0 /dev/ada1 [user 0 (root) on :global]\n"
"2013-02-27.18:50:58 zfs set atime=off tank [user 0 (root) on myzfsbox:global]\n"
"2013-02-27.18:51:09 zfs set checksum=fletcher4 tank [user 0 (root) on myzfsbox:global]\n"
"2013-02-27.18:51:18 zfs create tank/backup [user 0 (root) on myzfsbox:global]\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1246
msgid ""
"The output shows that the `root` user created the mirrored pool with disks [."
"filename]#/dev/ada0# and [.filename]#/dev/ada1#. The hostname `myzfsbox` is "
"also shown in the commands after the pool's creation. The hostname display "
"becomes important when the pool is exported from one system and imported on "
"another. The commands that are issued on the other system can clearly be "
"distinguished by the hostname that is recorded for each command."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1248
#, fuzzy
msgid ""
"Both options to `zpool history` can be combined to give the most detailed "
"information possible for any given pool. Pool history provides valuable "
"information when tracking down the actions that were performed or when more "
"detailed output is needed for debugging."
msgstr ""
"兩個 <command>zpool history</command> 選項可以合併使用來取得最完整的儲存池詳"
"細資訊。儲存池歷史記錄在追蹤執行什麼動作或要取得除錯所需的輸出結果提供了非常"
"有用的資訊。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1250
#, no-wrap
msgid "Performance Monitoring"
msgstr "監視效能"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1253
#, fuzzy
msgid ""
"A built-in monitoring system can display pool I/O statistics in real time. "
"It shows the amount of free and used space on the pool, how many read and "
"write operations are being performed per second, and how much I/O bandwidth "
"is currently being utilized. By default, all pools in the system are "
"monitored and displayed. A pool name can be provided to limit monitoring to "
"just that pool. A basic example:"
msgstr ""
"內建的監視系統可以即時顯示儲存池的 <acronym>I/O</acronym> 統計資訊。它會顯示"
"儲存池剩餘的空間與使用的空間，每秒執行了多少讀取與寫入的操作，有多少 "
"<acronym>I/O</acronym> 頻寬被使用。預設會監視所有在系統中的儲存池都並顯示出"
"來，可以提供儲存池名稱來只顯示該儲存池的監視資訊。舉一個簡單的例子："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1261
#, no-wrap
msgid ""
"# zpool iostat\n"
"               capacity     operations    bandwidth\n"
"pool        alloc   free   read  write   read  write\n"
"----------  -----  -----  -----  -----  -----  -----\n"
"data         288G  1.53T      2     11  11.3K  57.1K\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1264
msgid ""
"To continuously monitor I/O activity, a number can be specified as the last "
"parameter, indicating a interval in seconds to wait between updates. The "
"next statistic line is printed after each interval. Press kbd:[Ctrl+C] to "
"stop this continuous monitoring. Alternatively, give a second number on the "
"command line after the interval to specify the total number of statistics to "
"display."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1266
#, fuzzy
msgid ""
"Even more detailed I/O statistics can be displayed with `-v`. Each device in "
"the pool is shown with a statistics line. This is useful in seeing how many "
"read and write operations are being performed on each device, and can help "
"determine if any individual device is slowing down the pool. This example "
"shows a mirrored pool with two devices:"
msgstr ""
"使用 <option>-v</option> 可以顯示更詳細的 <acronym>I/O</acronym> 統計資訊。每"
"個在儲存池中的裝置會以一行統計資訊顯示。這可以幫助了解每一個裝置做了多少讀取"
"與寫入的操作，並可協助確認是否有各別裝置拖慢了整個儲存池的速度。以下範例會顯"
"示有兩個裝置的鏡像儲存池："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1278
#, no-wrap
msgid ""
"# zpool iostat -v \n"
"                            capacity     operations    bandwidth\n"
"pool                     alloc   free   read  write   read  write\n"
"-----------------------  -----  -----  -----  -----  -----  -----\n"
"data                      288G  1.53T      2     12  9.23K  61.5K\n"
"  mirror                  288G  1.53T      2     12  9.23K  61.5K\n"
"    ada1                     -      -      0      4  5.61K  61.7K\n"
"    ada2                     -      -      1      4  5.04K  61.7K\n"
"-----------------------  -----  -----  -----  -----  -----  -----\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1281
#, no-wrap
msgid "Splitting a Storage Pool"
msgstr "分割儲存儲存池"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1284
#, fuzzy
msgid ""
"A pool consisting of one or more mirror vdevs can be split into two pools. "
"Unless otherwise specified, the last member of each mirror is detached and "
"used to create a new pool containing the same data. The operation should "
"first be attempted with `-n`. The details of the proposed operation are "
"displayed without it actually being performed. This helps confirm that the "
"operation will do what the user intends."
msgstr ""
"由一個或多個鏡像 vdev 所組成的儲存池可以切分開成兩個儲存池。除非有另外指定，"
"否則每個鏡像的最後一個成員會被分離來然用來建立一個含有相同資料的新儲存池。在"
"做這個操作的第一次應先使用 <option>-n</option>，會顯示預計會做的操作而不會真"
"的執行，這可以協助確認操作是否與使用者所要的相同。"

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:1286
#, no-wrap
msgid "`zfs` Administration"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1289
msgid ""
"The `zfs` utility is responsible for creating, destroying, and managing all "
"ZFS datasets that exist within a pool. The pool is managed using <<zfs-zpool,"
"`zpool`>>."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1291
#, no-wrap
msgid "Creating and Destroying Datasets"
msgstr "建立與摧毀資料集"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1294
#, fuzzy
msgid ""
"Unlike traditional disks and volume managers, space in ZFS is _not_ "
"preallocated. With traditional file systems, after all of the space is "
"partitioned and assigned, there is no way to add an additional file system "
"without adding a new disk. With ZFS, new file systems can be created at any "
"time. Each <<zfs-term-dataset,_dataset_>> has properties including features "
"like compression, deduplication, caching, and quotas, as well as other "
"useful properties like readonly, case sensitivity, network file sharing, and "
"a mount point. Datasets can be nested inside each other, and child datasets "
"will inherit properties from their parents. Each dataset can be "
"administered, <<zfs-zfs-allow,delegated>>, <<zfs-zfs-send,replicated>>, "
"<<zfs-zfs-snapshot,snapshotted>>, <<zfs-zfs-jail,jailed>>, and destroyed as "
"a unit. There are many advantages to creating a separate dataset for each "
"different type or set of files. The only drawbacks to having an extremely "
"large number of datasets is that some commands like `zfs list` will be "
"slower, and the mounting of hundreds or even thousands of datasets can slow "
"the FreeBSD boot process."
msgstr ""
"不同於傳統的磁碟與磁碟區管理程式 (Volume manager) ，在 <acronym>ZFS</"
"acronym> 中的空間並<emphasis>不</emphasis>會預先分配。傳統的檔案系統在分割與"
"分配空間完後，若沒有增加新的磁碟便無法再增加額外的檔案系統。在 <acronym>ZFS</"
"acronym>，可以隨時建立新的檔案系統，每個資料集 (<link linkend=\"zfs-term-"
"dataset\"><emphasis>Dataset</emphasis></link>) 都有自己的屬性，包含壓縮 "
"(Compression)、去重複 (Deduplication)、快取 (Caching) 與配額 (Quota) 功能以及"
"其他有用的屬性如唯讀 (Readonly)、區分大小寫 (Case sensitivity)、網路檔案分享 "
"(Network file sharing) 以及掛載點 (Mount point)。資料集可以存在於其他資料集"
"中，且子資料集會繼承其父資料集的屬性。每個資料集都可以作為一個單位來管理、委"
"託 (<link linkend=\"zfs-zfs-allow\">Delegate</link>)、備份 (<link linkend="
"\"zfs-zfs-send\">Replicate</link>)、快照 (<link linkend=\"zfs-zfs-snapshot"
"\">Snapshot</link>)、監禁 (<link linkend=\"zfs-zfs-jail\">Jail</link>) 與摧"
"毀 (Destroy)，替每種不同類型或集合的檔案建立各別的資料集還有許多的好處。唯一"
"的缺點是在當有非常大數量的資料集時，部份指令例如 <command>zfs list</command> "
"會變的較緩慢，且掛載上百個或其至上千個資料集可能會使 FreeBSD 的開機程序變慢。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1296
msgid ""
"Create a new dataset and enable <<zfs-term-compression-lz4,LZ4 compression>> "
"on it:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1331
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                  USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                781M  93.2G   144K  none\n"
"mypool/ROOT           777M  93.2G   144K  none\n"
"mypool/ROOT/default   777M  93.2G   777M  /\n"
"mypool/tmp            176K  93.2G   176K  /tmp\n"
"mypool/usr            616K  93.2G   144K  /usr\n"
"mypool/usr/home       184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports      144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src        144K  93.2G   144K  /usr/src\n"
"mypool/var           1.20M  93.2G   608K  /var\n"
"mypool/var/crash      148K  93.2G   148K  /var/crash\n"
"mypool/var/log        178K  93.2G   178K  /var/log\n"
"mypool/var/mail       144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp        152K  93.2G   152K  /var/tmp\n"
"# zfs create -o compress=lz4 mypool/usr/mydataset\n"
"# zfs list\n"
"NAME                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                 781M  93.2G   144K  none\n"
"mypool/ROOT            777M  93.2G   144K  none\n"
"mypool/ROOT/default    777M  93.2G   777M  /\n"
"mypool/tmp             176K  93.2G   176K  /tmp\n"
"mypool/usr             704K  93.2G   144K  /usr\n"
"mypool/usr/home        184K  93.2G   184K  /usr/home\n"
"mypool/usr/mydataset  87.5K  93.2G  87.5K  /usr/mydataset\n"
"mypool/usr/ports       144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src         144K  93.2G   144K  /usr/src\n"
"mypool/var            1.20M  93.2G   610K  /var\n"
"mypool/var/crash       148K  93.2G   148K  /var/crash\n"
"mypool/var/log         178K  93.2G   178K  /var/log\n"
"mypool/var/mail        144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp         152K  93.2G   152K  /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1334
msgid ""
"Destroying a dataset is much quicker than deleting all of the files that "
"reside on the dataset, as it does not involve scanning all of the files and "
"updating all of the corresponding metadata."
msgstr ""
"摧毀資料集會比刪除所有在資料集上所殘留的檔案來的快，由於摧毀資料集並不會掃描"
"所有檔案並更新所有相關的 Metadata。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1336
msgid "Destroy the previously-created dataset:"
msgstr "摧毀先前建立的資料集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1371
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                 880M  93.1G   144K  none\n"
"mypool/ROOT            777M  93.1G   144K  none\n"
"mypool/ROOT/default    777M  93.1G   777M  /\n"
"mypool/tmp             176K  93.1G   176K  /tmp\n"
"mypool/usr             101M  93.1G   144K  /usr\n"
"mypool/usr/home        184K  93.1G   184K  /usr/home\n"
"mypool/usr/mydataset   100M  93.1G   100M  /usr/mydataset\n"
"mypool/usr/ports       144K  93.1G   144K  /usr/ports\n"
"mypool/usr/src         144K  93.1G   144K  /usr/src\n"
"mypool/var            1.20M  93.1G   610K  /var\n"
"mypool/var/crash       148K  93.1G   148K  /var/crash\n"
"mypool/var/log         178K  93.1G   178K  /var/log\n"
"mypool/var/mail        144K  93.1G   144K  /var/mail\n"
"mypool/var/tmp         152K  93.1G   152K  /var/tmp\n"
"# zfs destroy mypool/usr/mydataset\n"
"# zfs list\n"
"NAME                  USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                781M  93.2G   144K  none\n"
"mypool/ROOT           777M  93.2G   144K  none\n"
"mypool/ROOT/default   777M  93.2G   777M  /\n"
"mypool/tmp            176K  93.2G   176K  /tmp\n"
"mypool/usr            616K  93.2G   144K  /usr\n"
"mypool/usr/home       184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports      144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src        144K  93.2G   144K  /usr/src\n"
"mypool/var           1.21M  93.2G   612K  /var\n"
"mypool/var/crash      148K  93.2G   148K  /var/crash\n"
"mypool/var/log        178K  93.2G   178K  /var/log\n"
"mypool/var/mail       144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp        152K  93.2G   152K  /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1374
msgid ""
"In modern versions of ZFS, `zfs destroy` is asynchronous, and the free space "
"might take several minutes to appear in the pool. Use `zpool get freeing "
"_poolname_` to see the `freeing` property, indicating how many datasets are "
"having their blocks freed in the background. If there are child datasets, "
"like <<zfs-term-snapshot,snapshots>> or other datasets, then the parent "
"cannot be destroyed. To destroy a dataset and all of its children, use `-r` "
"to recursively destroy the dataset and all of its children. Use `-n -v` to "
"list datasets and snapshots that would be destroyed by this operation, but "
"do not actually destroy anything. Space that would be reclaimed by "
"destruction of snapshots is also shown."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1376
#, no-wrap
msgid "Creating and Destroying Volumes"
msgstr "建立與摧毀磁碟區"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1379
msgid ""
"A volume is a special type of dataset. Rather than being mounted as a file "
"system, it is exposed as a block device under [.filename]#/dev/zvol/poolname/"
"dataset#. This allows the volume to be used for other file systems, to back "
"the disks of a virtual machine, or to be exported using protocols like iSCSI "
"or HAST."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1381
msgid ""
"A volume can be formatted with any file system, or used without a file "
"system to store raw data. To the user, a volume appears to be a regular "
"disk. Putting ordinary file systems on these _zvols_ provides features that "
"ordinary disks or file systems do not normally have. For example, using the "
"compression property on a 250 MB volume allows creation of a compressed FAT "
"file system."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1395
#, no-wrap
msgid ""
"# zfs create -V 250m -o compression=on tank/fat32\n"
"# zfs list tank\n"
"NAME USED AVAIL REFER MOUNTPOINT\n"
"tank 258M  670M   31K /tank\n"
"# newfs_msdos -F32 /dev/zvol/tank/fat32\n"
"# mount -t msdosfs /dev/zvol/tank/fat32 /mnt\n"
"# df -h /mnt | grep fat32\n"
"Filesystem           Size Used Avail Capacity Mounted on\n"
"/dev/zvol/tank/fat32 249M  24k  249M     0%   /mnt\n"
"# mount | grep fat32\n"
"/dev/zvol/tank/fat32 on /mnt (msdosfs, local)\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1398
msgid ""
"Destroying a volume is much the same as destroying a regular file system "
"dataset. The operation is nearly instantaneous, but it may take several "
"minutes for the free space to be reclaimed in the background."
msgstr ""
"摧毀一個磁碟區與摧毀一個一般的檔案系統資料集差不多。操作上幾乎是即時的，但在"
"背景會需要花費數分鐘來讓釋放空間再次可用。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1400
#, no-wrap
msgid "Renaming a Dataset"
msgstr "重新命名資料集"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1403
#, fuzzy
msgid ""
"The name of a dataset can be changed with `zfs rename`. The parent of a "
"dataset can also be changed with this command. Renaming a dataset to be "
"under a different parent dataset will change the value of those properties "
"that are inherited from the parent dataset. When a dataset is renamed, it is "
"unmounted and then remounted in the new location (which is inherited from "
"the new parent dataset). This behavior can be prevented with `-u`."
msgstr ""
"資料集的名稱可以使用 <command>zfs rename</command> 更改。父資料集也同樣可以使"
"用這個指令來更改名稱。重新命名一個資料集到另一個父資料集也會更改自父資料集繼"
"承的屬性值。重新命名資料集後，會被卸載然後重新掛載到新的位置 (依繼承的新父資"
"料集而定)，可使用 <option>-u</option> 來避免重新掛載。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1405
msgid "Rename a dataset and move it to be under a different parent dataset:"
msgstr "重新命名一個資料集並移動該資料集到另一個父資料集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1441
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                 780M  93.2G   144K  none\n"
"mypool/ROOT            777M  93.2G   144K  none\n"
"mypool/ROOT/default    777M  93.2G   777M  /\n"
"mypool/tmp             176K  93.2G   176K  /tmp\n"
"mypool/usr             704K  93.2G   144K  /usr\n"
"mypool/usr/home        184K  93.2G   184K  /usr/home\n"
"mypool/usr/mydataset  87.5K  93.2G  87.5K  /usr/mydataset\n"
"mypool/usr/ports       144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src         144K  93.2G   144K  /usr/src\n"
"mypool/var            1.21M  93.2G   614K  /var\n"
"mypool/var/crash       148K  93.2G   148K  /var/crash\n"
"mypool/var/log         178K  93.2G   178K  /var/log\n"
"mypool/var/mail        144K  93.2G   144K  /var/mail\n"
"mypool/var/tmp         152K  93.2G   152K  /var/tmp\n"
"# zfs rename mypool/usr/mydataset mypool/var/newname\n"
"# zfs list\n"
"NAME                  USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                780M  93.2G   144K  none\n"
"mypool/ROOT           777M  93.2G   144K  none\n"
"mypool/ROOT/default   777M  93.2G   777M  /\n"
"mypool/tmp            176K  93.2G   176K  /tmp\n"
"mypool/usr            616K  93.2G   144K  /usr\n"
"mypool/usr/home       184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports      144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src        144K  93.2G   144K  /usr/src\n"
"mypool/var           1.29M  93.2G   614K  /var\n"
"mypool/var/crash      148K  93.2G   148K  /var/crash\n"
"mypool/var/log        178K  93.2G   178K  /var/log\n"
"mypool/var/mail       144K  93.2G   144K  /var/mail\n"
"mypool/var/newname   87.5K  93.2G  87.5K  /var/newname\n"
"mypool/var/tmp        152K  93.2G   152K  /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1444
msgid ""
"Snapshots can also be renamed like this. Due to the nature of snapshots, "
"they cannot be renamed into a different parent dataset. To rename a "
"recursive snapshot, specify `-r`, and all snapshots with the same name in "
"child datasets will also be renamed."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1454
#, no-wrap
msgid ""
"# zfs list -t snapshot\n"
"NAME                                USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/newname@first_snapshot      0      -  87.5K  -\n"
"# zfs rename mypool/var/newname@first_snapshot new_snapshot_name\n"
"# zfs list -t snapshot\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/newname@new_snapshot_name      0      -  87.5K  -\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1457
#, no-wrap
msgid "Setting Dataset Properties"
msgstr "設定資料集屬性"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1460
msgid ""
"Each ZFS dataset has a number of properties that control its behavior. Most "
"properties are automatically inherited from the parent dataset, but can be "
"overridden locally. Set a property on a dataset with `zfs set "
"_property=value dataset_`. Most properties have a limited set of valid "
"values, `zfs get` will display each possible property and valid values. Most "
"properties can be reverted to their inherited values using `zfs inherit`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1462
msgid ""
"User-defined properties can also be set. They become part of the dataset "
"configuration and can be used to provide additional information about the "
"dataset or its contents. To distinguish these custom properties from the "
"ones supplied as part of ZFS, a colon (`:`) is used to create a custom "
"namespace for the property."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1469
#, no-wrap
msgid ""
"# zfs set custom:costcenter=1234 tank\n"
"# zfs get custom:costcenter tank\n"
"NAME PROPERTY           VALUE SOURCE\n"
"tank custom:costcenter  1234  local\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1472
msgid ""
"To remove a custom property, use `zfs inherit` with `-r`. If the custom "
"property is not defined in any of the parent datasets, it will be removed "
"completely (although the changes are still recorded in the pool's history)."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1481
#, no-wrap
msgid ""
"# zfs inherit -r custom:costcenter tank\n"
"# zfs get custom:costcenter tank\n"
"NAME    PROPERTY           VALUE              SOURCE\n"
"tank    custom:costcenter  -                  -\n"
"# zfs get all tank | grep custom:costcenter\n"
"#\n"
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1484
#, no-wrap
msgid "Getting and Setting Share Properties"
msgstr "取得與設定共享屬性"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1487
msgid ""
"Two commonly used and useful dataset properties are the NFS and SMB share "
"options. Setting these define if and how ZFS datasets may be shared on the "
"network. At present, only setting sharing via NFS is supported on FreeBSD. "
"To get the current status of a share, enter:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1496
#, no-wrap
msgid ""
"# zfs get sharenfs mypool/usr/home\n"
"NAME             PROPERTY  VALUE    SOURCE\n"
"mypool/usr/home  sharenfs  on       local\n"
"# zfs get sharesmb mypool/usr/home\n"
"NAME             PROPERTY  VALUE    SOURCE\n"
"mypool/usr/home  sharesmb  off      local\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1499
msgid "To enable sharing of a dataset, enter:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1503
#, no-wrap
msgid "#  zfs set sharenfs=on mypool/usr/home\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1506
msgid ""
"It is also possible to set additional options for sharing datasets through "
"NFS, such as `-alldirs`, `-maproot` and `-network`. To set additional "
"options to a dataset shared through NFS, enter:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1510
#, no-wrap
msgid "#  zfs set sharenfs=\"-alldirs,-maproot=root,-network=192.168.1.0/24\" mypool/usr/home\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1513
#, no-wrap
msgid "Managing Snapshots"
msgstr "管理快照 (Snapshot)"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1516
#, fuzzy
msgid ""
"<<zfs-term-snapshot,Snapshots>> are one of the most powerful features of "
"ZFS. A snapshot provides a read-only, point-in-time copy of the dataset. "
"With Copy-On-Write (COW), snapshots can be created quickly by preserving the "
"older version of the data on disk. If no snapshots exist, space is reclaimed "
"for future use when data is rewritten or deleted. Snapshots preserve disk "
"space by recording only the differences between the current dataset and a "
"previous version. Snapshots are allowed only on whole datasets, not on "
"individual files or directories. When a snapshot is created from a dataset, "
"everything contained in it is duplicated. This includes the file system "
"properties, files, directories, permissions, and so on. Snapshots use no "
"additional space when they are first created, only consuming space as the "
"blocks they reference are changed. Recursive snapshots taken with `-r` "
"create a snapshot with the same name on the dataset and all of its children, "
"providing a consistent moment-in-time snapshot of all of the file systems. "
"This can be important when an application has files on multiple datasets "
"that are related or dependent upon each other. Without snapshots, a backup "
"would have copies of the files from different points in time."
msgstr ""
"快照 (<link linkend=\"zfs-term-snapshot\">Snapshot</link>) 是 <acronym>ZFS</"
"acronym> 最強大的功能之一。快照提供了資料集唯讀、單一時間點 (Point-in-Time) "
"的複製功能，使用了寫入時複製 (Copy-On-Write, <acronym>COW</acronym>) 的技術，"
"可以透過保存在磁碟上的舊版資料快速的建立快照。若沒有快照存在，在資料被覆蓋或"
"刪除時，便回收空間供未來使用。由於只記錄前一個版本與目前資料集的差異，因此快"
"照可節省磁碟空間。快照只允許在整個資料集上使用，無法在各別檔案或目錄。當建立"
"了一個資料集的快照時，便備份了所有內含的資料，這包含了檔案系統屬性、檔案、目"
"錄、權限等等。第一次建立快照時只會使用到更改參照到資料區塊的空間，不會用到其"
"他額外的空間。使用 <option>-r</option> 可以對使用同名的資料集及其所有子資料集"
"的建立一個遞迴快照，提供一致且即時 (Moment-in-time) 的完整檔案系統快照功能，"
"這對於那些彼此有相關或相依檔案存放在不同資料集的應用程式非常重要。不使用快照"
"所備份的資料其實是分散不同時間點的。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1518
#, fuzzy
msgid ""
"Snapshots in ZFS provide a variety of features that even other file systems "
"with snapshot functionality lack. A typical example of snapshot use is to "
"have a quick way of backing up the current state of the file system when a "
"risky action like a software installation or a system upgrade is performed. "
"If the action fails, the snapshot can be rolled back and the system has the "
"same state as when the snapshot was created. If the upgrade was successful, "
"the snapshot can be deleted to free up space. Without snapshots, a failed "
"upgrade often requires a restore from backup, which is tedious, time "
"consuming, and may require downtime during which the system cannot be used. "
"Snapshots can be rolled back quickly, even while the system is running in "
"normal operation, with little or no downtime. The time savings are enormous "
"with multi-terabyte storage systems and the time required to copy the data "
"from backup. Snapshots are not a replacement for a complete backup of a "
"pool, but can be used as a quick and easy way to store a copy of the dataset "
"at a specific point in time."
msgstr ""
"<acronym>ZFS</acronym> 中的快照提供了多種功能，即使是在其他缺乏快照功能的檔案"
"系統上。一個使用快照的典型例子是在安裝軟體或執行系統升級這種有風險的動作時，"
"能有一個快速的方式可以備份檔案系統目前的狀態，若動作失敗，可以使用快照還原 "
"(Roll back) 到與快照建立時相同的系統狀態，若升級成功，便可刪除快照來釋放空"
"間。若沒有快照功能，升級失敗通常會需要使用備份來恢復 (Restore) 系統，而這個動"
"作非常繁瑣、耗時且可能會需要停機一段時間系統無法使用。使用快照可以快速的還"
"原，即使系統正在執行一般的運作，只而要短暫或甚至不需停機。能夠節省大量在有數 "
"TB 的儲存系統上從備份複製所需資料的時間。快照並非要用來取代儲存池的完整備份，"
"但可以用在快速且簡單的保存某個特定時間點的資料集。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1520
#, no-wrap
msgid "Creating Snapshots"
msgstr "建立快照"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1523
msgid ""
"Snapshots are created with `zfs snapshot _dataset_@_snapshotname_`. Adding `-"
"r` creates a snapshot recursively, with the same name on all child datasets."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1525
msgid "Create a recursive snapshot of the entire pool:"
msgstr "建立一個整個儲存池的遞迴快照："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1563
#, no-wrap
msgid ""
"# zfs list -t all\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool                                 780M  93.2G   144K  none\n"
"mypool/ROOT                            777M  93.2G   144K  none\n"
"mypool/ROOT/default                    777M  93.2G   777M  /\n"
"mypool/tmp                             176K  93.2G   176K  /tmp\n"
"mypool/usr                             616K  93.2G   144K  /usr\n"
"mypool/usr/home                        184K  93.2G   184K  /usr/home\n"
"mypool/usr/ports                       144K  93.2G   144K  /usr/ports\n"
"mypool/usr/src                         144K  93.2G   144K  /usr/src\n"
"mypool/var                            1.29M  93.2G   616K  /var\n"
"mypool/var/crash                       148K  93.2G   148K  /var/crash\n"
"mypool/var/log                         178K  93.2G   178K  /var/log\n"
"mypool/var/mail                        144K  93.2G   144K  /var/mail\n"
"mypool/var/newname                    87.5K  93.2G  87.5K  /var/newname\n"
"mypool/var/newname@new_snapshot_name      0      -  87.5K  -\n"
"mypool/var/tmp                         152K  93.2G   152K  /var/tmp\n"
"# zfs snapshot -r mypool@my_recursive_snapshot\n"
"# zfs list -t snapshot\n"
"NAME                                        USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool@my_recursive_snapshot                   0      -   144K  -\n"
"mypool/ROOT@my_recursive_snapshot              0      -   144K  -\n"
"mypool/ROOT/default@my_recursive_snapshot      0      -   777M  -\n"
"mypool/tmp@my_recursive_snapshot               0      -   176K  -\n"
"mypool/usr@my_recursive_snapshot               0      -   144K  -\n"
"mypool/usr/home@my_recursive_snapshot          0      -   184K  -\n"
"mypool/usr/ports@my_recursive_snapshot         0      -   144K  -\n"
"mypool/usr/src@my_recursive_snapshot           0      -   144K  -\n"
"mypool/var@my_recursive_snapshot               0      -   616K  -\n"
"mypool/var/crash@my_recursive_snapshot         0      -   148K  -\n"
"mypool/var/log@my_recursive_snapshot           0      -   178K  -\n"
"mypool/var/mail@my_recursive_snapshot          0      -   144K  -\n"
"mypool/var/newname@new_snapshot_name           0      -  87.5K  -\n"
"mypool/var/newname@my_recursive_snapshot       0      -  87.5K  -\n"
"mypool/var/tmp@my_recursive_snapshot           0      -   152K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1566
msgid ""
"Snapshots are not shown by a normal `zfs list` operation. To list snapshots, "
"`-t snapshot` is appended to `zfs list`. `-t all` displays both file systems "
"and snapshots."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1568
msgid ""
"Snapshots are not mounted directly, so no path is shown in the `MOUNTPOINT` "
"column. There is no mention of available disk space in the `AVAIL` column, "
"as snapshots cannot be written to after they are created. Compare the "
"snapshot to the original dataset from which it was created:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1575
#, no-wrap
msgid ""
"# zfs list -rt all mypool/usr/home\n"
"NAME                                    USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/usr/home                         184K  93.2G   184K  /usr/home\n"
"mypool/usr/home@my_recursive_snapshot      0      -   184K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1578
msgid ""
"Displaying both the dataset and the snapshot together reveals how snapshots "
"work in <<zfs-term-cow,COW>> fashion. They save only the changes (_delta_) "
"that were made and not the complete file system contents all over again. "
"This means that snapshots take little space when few changes are made. Space "
"usage can be made even more apparent by copying a file to the dataset, then "
"making a second snapshot:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1588
#, no-wrap
msgid ""
"# cp /etc/passwd /var/tmp\n"
"# zfs snapshot mypool/var/tmp@after_cp\n"
"# zfs list -rt all mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp                         206K  93.2G   118K  /var/tmp\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp                   0      -   118K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1591
msgid ""
"The second snapshot contains only the changes to the dataset after the copy "
"operation. This yields enormous space savings. Notice that the size of the "
"snapshot `_mypool/var/tmp@my_recursive_snapshot_` also changed in the `USED` "
"column to indicate the changes between itself and the snapshot taken "
"afterwards."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1593
#, no-wrap
msgid "Comparing Snapshots"
msgstr "比對快照"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1596
#, fuzzy
msgid ""
"ZFS provides a built-in command to compare the differences in content "
"between two snapshots. This is helpful when many snapshots were taken over "
"time and the user wants to see how the file system has changed over time. "
"For example, `zfs diff` lets a user find the latest snapshot that still "
"contains a file that was accidentally deleted. Doing this for the two "
"snapshots that were created in the previous section yields this output:"
msgstr ""
"ZFS 提供了內建指令可以用來比對兩個快照 (Snapshot) 之間的差異，在使用者想要查"
"看一段時間之間檔案系統所的變更時非常有用。例如 <command>zfs diff</command> 可"
"以讓使用者在最後一次快照中找到意外刪除的檔案。對前面一節所做的兩個快照使用這"
"個指令會產生以下結果："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1607
#, no-wrap
msgid ""
"# zfs list -rt all mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp                         206K  93.2G   118K  /var/tmp\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp                   0      -   118K  -\n"
"# zfs diff mypool/var/tmp@my_recursive_snapshot\n"
"M       /var/tmp/\n"
"+       /var/tmp/passwd\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1610
msgid ""
"The command lists the changes between the specified snapshot (in this case "
"`_mypool/var/tmp@my_recursive_snapshot_`) and the live file system. The "
"first column shows the type of change:"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:1626
#, no-wrap
msgid ""
"|+\n"
"|The path or file was added.\n"
"\n"
"|-\n"
"|The path or file was deleted.\n"
"\n"
"|M\n"
"|The path or file was modified.\n"
"\n"
"|R\n"
"|The path or file was renamed.\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1629
msgid ""
"Comparing the output with the table, it becomes clear that [."
"filename]#passwd# was added after the snapshot `_mypool/var/"
"tmp@my_recursive_snapshot_` was created. This also resulted in a "
"modification to the parent directory mounted at `_/var/tmp_`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1631
msgid ""
"Comparing two snapshots is helpful when using the ZFS replication feature to "
"transfer a dataset to a different host for backup purposes."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1633
msgid ""
"Compare two snapshots by providing the full dataset name and snapshot name "
"of both datasets:"
msgstr "比對兩個快照需要提供兩個資料集的完整資料集名稱與快照名稱："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1645
#, no-wrap
msgid ""
"# cp /var/tmp/passwd /var/tmp/passwd.copy\n"
"# zfs snapshot mypool/var/tmp@diff_snapshot\n"
"# zfs diff mypool/var/tmp@my_recursive_snapshot mypool/var/tmp@diff_snapshot\n"
"M       /var/tmp/\n"
"+       /var/tmp/passwd\n"
"+       /var/tmp/passwd.copy\n"
"# zfs diff mypool/var/tmp@my_recursive_snapshot mypool/var/tmp@after_cp\n"
"M       /var/tmp/\n"
"+       /var/tmp/passwd\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1648
#, fuzzy
msgid ""
"A backup administrator can compare two snapshots received from the sending "
"host and determine the actual changes in the dataset. See the <<zfs-zfs-send,"
"Replication>> section for more information."
msgstr ""
"備份管理者可以比對兩個自傳送主機所接收到的兩個快照並查看實際在資料集中的變"
"更。請參考 <link linkend=\"zfs-zfs-send\">備份</link> 一節來取得更多資訊。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1650
#, no-wrap
msgid "Snapshot Rollback"
msgstr "使用快照還原"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1653
#, fuzzy
msgid ""
"When at least one snapshot is available, it can be rolled back to at any "
"time. Most of the time this is the case when the current state of the "
"dataset is no longer required and an older version is preferred. Scenarios "
"such as local development tests have gone wrong, botched system updates "
"hampering the system's overall functionality, or the requirement to restore "
"accidentally deleted files or directories are all too common occurrences. "
"Luckily, rolling back a snapshot is just as easy as typing `zfs rollback "
"_snapshotname_`. Depending on how many changes are involved, the operation "
"will finish in a certain amount of time. During that time, the dataset "
"always remains in a consistent state, much like a database that conforms to "
"ACID principles is performing a rollback. This is happening while the "
"dataset is live and accessible without requiring a downtime. Once the "
"snapshot has been rolled back, the dataset has the same state as it had when "
"the snapshot was originally taken. All other data in that dataset that was "
"not part of the snapshot is discarded. Taking a snapshot of the current "
"state of the dataset before rolling back to a previous one is a good idea "
"when some data is required later. This way, the user can roll back and forth "
"between snapshots without losing data that is still valuable."
msgstr ""
"只要至少有一個可用的快照便可以隨時還原。大多數在已不需要目前資料集，想要改用"
"較舊版的資料的情況，例如，本地開發的測試發生錯誤、不良的系統更新破壞了系統的"
"整體功能或需要還原意外刪除檔案或目錄 ... 等，都是非常常見的情形。幸運的，要還"
"原到某個快照只需要簡單輸入 <command>zfs rollback <replaceable>snapshotname</"
"replaceable></command>。會依快照所做的變更數量來決定處理的時間，還原的操作會"
"在一段時間後完成。在這段時間中，資料集會一直保持一致的狀態，類似一個符合 "
"ACID 原則的資料庫在做還原。還原可在資料集處於上線及可存取的情況下完成，不需要"
"停機。還原到快照之後，資料集便回到當初執行快照時相同的狀態，所有沒有在快照中"
"的其他資料便會被丟棄，因此往後若還有可能需要部份資料時，建議在還原到前一個快"
"照之前先對目前的資料集做快照，這樣一來，使用者便可以在快照之間來回快換，而不"
"會遺失重要的資料。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1655
msgid ""
"In the first example, a snapshot is rolled back because of a careless `rm` "
"operation that removes too much data than was intended."
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1669
#, no-wrap
msgid ""
"# zfs list -rt all mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp                         262K  93.2G   120K  /var/tmp\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp               53.5K      -   118K  -\n"
"mypool/var/tmp@diff_snapshot              0      -   120K  -\n"
"# ls /var/tmp\n"
"passwd          passwd.copy     vi.recover\n"
"# rm /var/tmp/passwd*\n"
"# ls /var/tmp\n"
"vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1672
#, fuzzy
msgid ""
"At this point, the user realized that too many files were deleted and wants "
"them back. ZFS provides an easy way to get them back using rollbacks, but "
"only when snapshots of important data are performed on a regular basis. To "
"get the files back and start over from the last snapshot, issue the command:"
msgstr ""
"在此時，使用者發現到刪除了太多檔案並希望能夠還原。<acronym>ZFS</acronym> 提供"
"了簡單的方可以取回檔案，便是使用還原 (Rollback)，但這只在有定期對重要的資料使"
"用快照時可用。要拿回檔案並從最後一次快照重新開始，可執行以下指令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1678
#, no-wrap
msgid ""
"# zfs rollback mypool/var/tmp@diff_snapshot\n"
"# ls /var/tmp\n"
"passwd          passwd.copy     vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1681
#, fuzzy
msgid ""
"The rollback operation restored the dataset to the state of the last "
"snapshot. It is also possible to roll back to a snapshot that was taken much "
"earlier and has other snapshots that were created after it. When trying to "
"do this, ZFS will issue this warning:"
msgstr ""
"還原操作會將資料集還原為最後一次快照的狀態。這也可以還原到更早之前，有其他在"
"其之後建立的快照。要這麼做時，<acronym>ZFS</acronym> 會發出這個警告："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1694
#, no-wrap
msgid ""
"# zfs list -rt snapshot mypool/var/tmp\n"
"AME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -\n"
"mypool/var/tmp@after_cp               53.5K      -   118K  -\n"
"mypool/var/tmp@diff_snapshot              0      -   120K  -\n"
"# zfs rollback mypool/var/tmp@my_recursive_snapshot\n"
"cannot rollback to 'mypool/var/tmp@my_recursive_snapshot': more recent snapshots exist\n"
"use '-r' to force deletion of the following snapshots:\n"
"mypool/var/tmp@after_cp\n"
"mypool/var/tmp@diff_snapshot\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1697
#, fuzzy
msgid ""
"This warning means that snapshots exist between the current state of the "
"dataset and the snapshot to which the user wants to roll back. To complete "
"the rollback, these snapshots must be deleted. ZFS cannot track all the "
"changes between different states of the dataset, because snapshots are read-"
"only. ZFS will not delete the affected snapshots unless the user specifies `-"
"r` to indicate that this is the desired action. If that is the intention, "
"and the consequences of losing all intermediate snapshots is understood, the "
"command can be issued:"
msgstr ""
"這個警告是因在該快照與資料集的目前狀態之間有其他快照存在，然而使用者想要還原"
"到該快照。要完成這樣的還原動作，必須刪除在這之間的快照，因為 <acronym>ZFS</"
"acronym> 無法追蹤不同資料集狀態間的變更。在使用者未指定 <option>-r</option> "
"來確認這個動作前，<acronym>ZFS</acronym> 不會刪除受影響的快照。若確定要這麼"
"做，那麼必須要知道會遺失所有在這之間的快照，然後可執行以下指令："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1706
#, no-wrap
msgid ""
"# zfs rollback -r mypool/var/tmp@my_recursive_snapshot\n"
"# zfs list -rt snapshot mypool/var/tmp\n"
"NAME                                   USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool/var/tmp@my_recursive_snapshot     8K      -   152K  -\n"
"# ls /var/tmp\n"
"vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1709
msgid ""
"The output from `zfs list -t snapshot` confirms that the intermediate "
"snapshots were removed as a result of `zfs rollback -r`."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1711
#, no-wrap
msgid "Restoring Individual Files from Snapshots"
msgstr "從快照還原個別檔案"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1714
#, fuzzy
msgid ""
"Snapshots are mounted in a hidden directory under the parent dataset: [."
"filename]#.zfs/snapshots/snapshotname#. By default, these directories will "
"not be displayed even when a standard `ls -a` is issued. Although the "
"directory is not displayed, it is there nevertheless and can be accessed "
"like any normal directory. The property named `snapdir` controls whether "
"these hidden directories show up in a directory listing. Setting the "
"property to `visible` allows them to appear in the output of `ls` and other "
"commands that deal with directory contents."
msgstr ""
"快照會掛載在父資料集下的隱藏目錄：<filename>.zfs/snapshots/"
"<replaceable>snapshotname</replaceable></filename>。預設不會顯示這些目錄，即"
"使是用 <command>ls -a</command> 指令。雖然該目錄不會顯示，但該目錄實際存在，"
"而且可以像一般的目錄一樣存取。一個名稱為 <literal>snapdir</literal> 的屬性可"
"以控制是否在目錄清單中顯示這些隱藏目錄，設定該屬性為可見 (<literal>visible</"
"literal>) 可以讓這些目錄出現在 <command>ls</command> 以及其他處理目錄內容的指"
"令中。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1725
#, no-wrap
msgid ""
"# zfs get snapdir mypool/var/tmp\n"
"NAME            PROPERTY  VALUE    SOURCE\n"
"mypool/var/tmp  snapdir   hidden   default\n"
"# ls -a /var/tmp\n"
".               ..              passwd          vi.recover\n"
"# zfs set snapdir=visible mypool/var/tmp\n"
"# ls -a /var/tmp\n"
".               ..              .zfs            passwd          vi.recover\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1728
#, fuzzy
msgid ""
"Individual files can easily be restored to a previous state by copying them "
"from the snapshot back to the parent dataset. The directory structure below "
"[.filename]#.zfs/snapshot# has a directory named exactly like the snapshots "
"taken earlier to make it easier to identify them. In the next example, it is "
"assumed that a file is to be restored from the hidden [.filename]#.zfs# "
"directory by copying it from the snapshot that contained the latest version "
"of the file:"
msgstr ""
"要還原個別檔案到先前的狀態非常簡單，只要從快照中複製檔案到父資料集。在 "
"<filename>.zfs/snapshot</filename> 目錄結構下有一個與先前所做的快照名稱相同的"
"目錄，可以很容易的找到。在下個範例中，我們會示範從隱藏的 <filename>.zfs</"
"filename> 目錄還原一個檔案，透過從含有該檔案的最新版快照複製："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1739
#, no-wrap
msgid ""
"# rm /var/tmp/passwd\n"
"# ls -a /var/tmp\n"
".               ..              .zfs            vi.recover\n"
"# ls /var/tmp/.zfs/snapshot\n"
"after_cp                my_recursive_snapshot\n"
"# ls /var/tmp/.zfs/snapshot/after_cp\n"
"passwd          vi.recover\n"
"# cp /var/tmp/.zfs/snapshot/after_cp/passwd /var/tmp\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1742
#, fuzzy
msgid ""
"When `ls .zfs/snapshot` was issued, the `snapdir` property might have been "
"set to hidden, but it would still be possible to list the contents of that "
"directory. It is up to the administrator to decide whether these directories "
"will be displayed. It is possible to display these for certain datasets and "
"prevent it for others. Copying files or directories from this hidden [."
"filename]#.zfs/snapshot# is simple enough. Trying it the other way around "
"results in this error:"
msgstr ""
"執行 <command>ls .zfs/snapshot</command> 時，雖然 <literal>snapdir</literal> "
"可能已經設為隱藏，但仍可能可以顯示該目錄中的內容，這取決於管理者是否要顯示這"
"些目錄，可以只顯示特定的資料集，而其他的則不顯示。從這個隱藏的 <filename>."
"zfs/snapshot</filename> 複製檔案或目錄非常簡單，除此之外，嘗試其他的動作則會"
"出現以下錯誤："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1747
#, no-wrap
msgid ""
"# cp /etc/rc.conf /var/tmp/.zfs/snapshot/after_cp/\n"
"cp: /var/tmp/.zfs/snapshot/after_cp/rc.conf: Read-only file system\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1750
msgid ""
"The error reminds the user that snapshots are read-only and cannot be "
"changed after creation. Files cannot be copied into or removed from snapshot "
"directories because that would change the state of the dataset they "
"represent."
msgstr ""
"這個錯誤用來提醒使用者快照是唯讀的，在建立之後不能更改。無法複製檔案進去或從"
"該快照目錄中移除，因為這會變更該資料集所代表的狀態。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1752
msgid ""
"Snapshots consume space based on how much the parent file system has changed "
"since the time of the snapshot. The `written` property of a snapshot tracks "
"how much space is being used by the snapshot."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1754
msgid ""
"Snapshots are destroyed and the space reclaimed with `zfs destroy "
"_dataset_@_snapshot_`. Adding `-r` recursively removes all snapshots with "
"the same name under the parent dataset. Adding `-n -v` to the command "
"displays a list of the snapshots that would be deleted and an estimate of "
"how much space would be reclaimed without performing the actual destroy "
"operation."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1756
#, no-wrap
msgid "Managing Clones"
msgstr "管理複本 (Clone)"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1759
#, fuzzy
msgid ""
"A clone is a copy of a snapshot that is treated more like a regular dataset. "
"Unlike a snapshot, a clone is not read only, is mounted, and can have its "
"own properties. Once a clone has been created using `zfs clone`, the "
"snapshot it was created from cannot be destroyed. The child/parent "
"relationship between the clone and the snapshot can be reversed using `zfs "
"promote`. After a clone has been promoted, the snapshot becomes a child of "
"the clone, rather than of the original parent dataset. This will change how "
"the space is accounted, but not actually change the amount of space "
"consumed. The clone can be mounted at any point within the ZFS file system "
"hierarchy, not just below the original location of the snapshot."
msgstr ""
"複本 (Clone) 是快照的複製，但更像是一般的資料集，與快照不同的是，複本是非唯讀"
"的 (可寫)，且可掛載，可以有自己的屬性。使用 <command>zfs clone</command> 建立"
"複本之後，便無法再摧毀用來建立複本的快照。複本與快照的父/子關係可以使用 "
"<command>zfs promote</command> 來對換。提升複本之後 ，快照便會成為複本的子資"
"料集，而不是原來的父資料集，這個動作會改變空間計算的方式，但並不會實際改變空"
"間的使用量。複本可以被掛載到 <acronym>ZFS</acronym> 檔案系統階層中的任何一"
"點，並非只能位於原來快照的位置底下。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1761
msgid "To demonstrate the clone feature, this example dataset is used:"
msgstr "要示範複本功能會用到這個範例資料集："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1769
#, no-wrap
msgid ""
"# zfs list -rt all camino/home/joe\n"
"NAME                    USED  AVAIL  REFER  MOUNTPOINT\n"
"camino/home/joe         108K   1.3G    87K  /usr/home/joe\n"
"camino/home/joe@plans    21K      -  85.5K  -\n"
"camino/home/joe@backup    0K      -    87K  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1772
msgid ""
"A typical use for clones is to experiment with a specific dataset while "
"keeping the snapshot around to fall back to in case something goes wrong. "
"Since snapshots cannot be changed, a read/write clone of a snapshot is "
"created. After the desired result is achieved in the clone, the clone can be "
"promoted to a dataset and the old file system removed. This is not strictly "
"necessary, as the clone and dataset can coexist without problems."
msgstr ""
"會使用到複本一般是要在可以保留快照以便出錯時可還原的情況下使用指定的資料集做"
"實驗，由於快照並無法做更改，所以會建立一個可以讀/寫的快照複本。當在複本中做完"
"想要執行的動作後，便可以提升複本成資料集，然後移除舊的檔案系統。嚴格來說這並"
"非必要，因為複本與資料集可同時存在，不會有任何問題。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1779
#, no-wrap
msgid ""
"# zfs clone camino/home/joe@backup camino/home/joenew\n"
"# ls /usr/home/joe*\n"
"/usr/home/joe:\n"
"backup.txz     plans.txt\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1786
#, no-wrap
msgid ""
"/usr/home/joenew:\n"
"backup.txz     plans.txt\n"
"# df -h /usr/home\n"
"Filesystem          Size    Used   Avail Capacity  Mounted on\n"
"usr/home/joe        1.3G     31k    1.3G     0%    /usr/home/joe\n"
"usr/home/joenew     1.3G     31k    1.3G     0%    /usr/home/joenew\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1789
msgid ""
"After a clone is created it is an exact copy of the state the dataset was in "
"when the snapshot was taken. The clone can now be changed independently from "
"its originating dataset. The only connection between the two is the "
"snapshot. ZFS records this connection in the property `origin`. Once the "
"dependency between the snapshot and the clone has been removed by promoting "
"the clone using `zfs promote`, the `origin` of the clone is removed as it is "
"now an independent dataset. This example demonstrates it:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1799
#, no-wrap
msgid ""
"# zfs get origin camino/home/joenew\n"
"NAME                  PROPERTY  VALUE                     SOURCE\n"
"camino/home/joenew    origin    camino/home/joe@backup    -\n"
"# zfs promote camino/home/joenew\n"
"# zfs get origin camino/home/joenew\n"
"NAME                  PROPERTY  VALUE   SOURCE\n"
"camino/home/joenew    origin    -       -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1802
#, fuzzy
msgid ""
"After making some changes like copying [.filename]#loader.conf# to the "
"promoted clone, for example, the old directory becomes obsolete in this "
"case. Instead, the promoted clone can replace it. This can be achieved by "
"two consecutive commands: `zfs destroy` on the old dataset and `zfs rename` "
"on the clone to name it like the old dataset (it could also get an entirely "
"different name)."
msgstr ""
"做為部份更改之後，例如複製 <filename>loader.conf</filename> 到提升後的複本，"
"這個例子中的舊目錄便無須保留，取而代之的是提升後的複本，這個動作可以用兩個連"
"續的指令來完成：在舊資料集上執行 <command>zfs destroy</command> 並在與舊資料"
"相似名稱 (也可能用完全不同的名稱) 的複本上執行 <command>zfs rename</"
"command>。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1813
#, no-wrap
msgid ""
"# cp /boot/defaults/loader.conf /usr/home/joenew\n"
"# zfs destroy -f camino/home/joe\n"
"# zfs rename camino/home/joenew camino/home/joe\n"
"# ls /usr/home/joe\n"
"backup.txz     loader.conf     plans.txt\n"
"# df -h /usr/home\n"
"Filesystem          Size    Used   Avail Capacity  Mounted on\n"
"usr/home/joe        1.3G    128k    1.3G     0%    /usr/home/joe\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1816
#, fuzzy
msgid ""
"The cloned snapshot is now handled like an ordinary dataset. It contains all "
"the data from the original snapshot plus the files that were added to it "
"like [.filename]#loader.conf#. Clones can be used in different scenarios to "
"provide useful features to ZFS users. For example, jails could be provided "
"as snapshots containing different sets of installed applications. Users can "
"clone these snapshots and add their own applications as they see fit. Once "
"they are satisfied with the changes, the clones can be promoted to full "
"datasets and provided to end users to work with like they would with a real "
"dataset. This saves time and administrative overhead when providing these "
"jails."
msgstr ""
"快照的複本現在可以如同一般資料集一樣使用，它的內容包含了所有來自原始快照的資"
"料以及後來加入的檔案，例如 <filename>loader.conf</filename>。複本可以在許多不"
"同的情境下使用提供 ZFS 的使用者有用的功能，例如，Jail 可以透過含有已安裝了各"
"種應用程式集的快照來提供，使用者可以複製這些快照然後加入自己想要嘗試的應用程"
"式，一但更改可以滿足需求，便可提升複本為完整的資料集然後提供給終端使用者，讓"
"終端使用者可以如同實際擁有資料集一般的使用，這個以節省提供這些 Jail 的時間與"
"管理成本。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1818
#, no-wrap
msgid "Replication"
msgstr "備份 (Replication)"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1821
#, fuzzy
msgid ""
"Keeping data on a single pool in one location exposes it to risks like theft "
"and natural or human disasters. Making regular backups of the entire pool is "
"vital. ZFS provides a built-in serialization feature that can send a stream "
"representation of the data to standard output. Using this technique, it is "
"possible to not only store the data on another pool connected to the local "
"system, but also to send it over a network to another system. Snapshots are "
"the basis for this replication (see the section on <<zfs-zfs-snapshot,ZFS "
"snapshots>>). The commands used for replicating data are `zfs send` and `zfs "
"receive`."
msgstr ""
"將資料保存在單一地點的單一儲存池上會讓資料暴露在盜竊、自然或人為的風險之下，"
"定期備份整個儲存池非常重要，<acronym>ZFS</acronym> 提供了內建的序列化 "
"(Serialization) 功能可以將資料以串流傳送到標準輸出。使用這項技術，不僅可以將"
"資料儲存到另一個已連結到本地系統的儲存池，也可以透過網路將資料傳送到另一個系"
"統，這種備份方式以快照為基礎 (請參考章節 <link linkend=\"zfs-zfs-snapshot"
"\"><acronym>ZFS</acronym> 快照(Snapshot)</link>)。用來備份資料的指令為 "
"<command>zfs send</command> 及 <command>zfs receive</command>。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1823
msgid "These examples demonstrate ZFS replication with these two pools:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1830
#, no-wrap
msgid ""
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M    77K   896M         -         -     0%    0%  1.00x  ONLINE  -\n"
"mypool  984M  43.7M   940M         -         -     0%    4%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1833
#, fuzzy
msgid ""
"The pool named _mypool_ is the primary pool where data is written to and "
"read from on a regular basis. A second pool, _backup_ is used as a standby "
"in case the primary pool becomes unavailable. Note that this fail-over is "
"not done automatically by ZFS, but must be manually done by a system "
"administrator when needed. A snapshot is used to provide a consistent "
"version of the file system to be replicated. Once a snapshot of _mypool_ has "
"been created, it can be copied to the _backup_ pool. Only snapshots can be "
"replicated. Changes made since the most recent snapshot will not be included."
msgstr ""
"名為 <replaceable>mypool</replaceable> 的儲存池為主要的儲存池，資料會定期寫入"
"與讀取的位置。第二個儲存池 <replaceable>backup</replaceable> 用來待命 "
"(Standby)，萬一主要儲存池無法使用時可替換。注意，<acronym>ZFS</acronym> 並不"
"會自動做容錯移轉 (Fail-over)，必須要由系統管理者在需要的時候手動完成。快照會"
"用來提供一個與檔系統一致的版本來做備份，<replaceable>mypool</replaceable> 的"
"快照建立之後，便可以複製到 <replaceable>backup</replaceable> 儲存池，只有快照"
"可以做備份，最近一次快照之後所做的變更不會含在內容裡面。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1840
#, no-wrap
msgid ""
"# zfs snapshot mypool@backup1\n"
"# zfs list -t snapshot\n"
"NAME                    USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool@backup1             0      -  43.6M  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1843
#, fuzzy
msgid ""
"Now that a snapshot exists, `zfs send` can be used to create a stream "
"representing the contents of the snapshot. This stream can be stored as a "
"file or received by another pool. The stream is written to standard output, "
"but must be redirected to a file or pipe or an error is produced:"
msgstr ""
"快照存在以後，便可以使用 <command>zfs send</command> 來建立一個代表快照內容的"
"串流，這個串流可以儲存成檔案或由其他儲存池接收。串流會寫入到標準輸出，但是必"
"須要重新導向到一個檔案或轉接到其他地方，否則會錯誤："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1849
#, no-wrap
msgid ""
"# zfs send mypool@backup1\n"
"Error: Stream can not be written to a terminal.\n"
"You must redirect standard output.\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1852
#, fuzzy
msgid ""
"To back up a dataset with `zfs send`, redirect to a file located on the "
"mounted backup pool. Ensure that the pool has enough free space to "
"accommodate the size of the snapshot being sent, which means all of the data "
"contained in the snapshot, not just the changes from the previous snapshot."
msgstr ""
"要使用 <command>zfs send</command> 備份一個資料集，可重新導向到一個位於在已掛"
"載到備份儲存池上的檔案。確定該儲存池有足夠的空間容納要傳送的快照，這裡指的是"
"該快照中內含的所有資料，並非只有上次快照到該快照間的變更。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1860
#, no-wrap
msgid ""
"# zfs send mypool@backup1 > /backup/backup1\n"
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  63.7M   896M         -         -     0%     6%  1.00x  ONLINE  -\n"
"mypool  984M  43.7M   940M         -         -     0%     4%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1863
msgid ""
"The `zfs send` transferred all the data in the snapshot called _backup1_ to "
"the pool named _backup_. Creating and sending these snapshots can be done "
"automatically with a man:cron[8] job."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1865
#, fuzzy
msgid ""
"Instead of storing the backups as archive files, ZFS can receive them as a "
"live file system, allowing the backed up data to be accessed directly. To "
"get to the actual data contained in those streams, `zfs receive` is used to "
"transform the streams back into files and directories. The example below "
"combines `zfs send` and `zfs receive` using a pipe to copy the data from one "
"pool to another. The data can be used directly on the receiving pool after "
"the transfer is complete. A dataset can only be replicated to an empty "
"dataset."
msgstr ""
"若不想將備份以封存檔案儲存，<acronym>ZFS</acronym> 可用實際的檔案系統來接收資"
"料，讓備份的資料可以直接被存取。要取得實際包含在串流中的資料可以用 "
"<command>zfs receive</command> 將串流轉換回檔案與目錄。以下例子會以管線符號連"
"接 <command>zfs send</command> 及 <command>zfs receive</command>，將資料從一"
"個儲存池複製到另一個，傳輸完成後可以直接使用接收儲存池上的資料。一個資料集只"
"可以被複製到另一個空的資料集。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1873
#, no-wrap
msgid ""
"# zfs snapshot mypool@replica1\n"
"# zfs send -v mypool@replica1 | zfs receive backup/mypool\n"
"send from @ to mypool@replica1 estimated size is 50.1M\n"
"total estimated size is 50.1M\n"
"TIME        SENT   SNAPSHOT\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1878
#, no-wrap
msgid ""
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  63.7M   896M         -         -     0%     6%  1.00x  ONLINE  -\n"
"mypool  984M  43.7M   940M         -         -     0%     4%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1881
#, no-wrap
msgid "Incremental Backups"
msgstr "漸進式備份"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1884
#, fuzzy
msgid ""
"`zfs send` can also determine the difference between two snapshots and send "
"only the differences between the two. This saves disk space and transfer "
"time. For example:"
msgstr ""
"<command>zfs send</command> 也可以比較兩個快照之間的差異，並且只傳送兩者之間"
"的差異，這麼做可以節省磁碟空間及傳輸時間。例如："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1896
#, no-wrap
msgid ""
"# zfs snapshot mypool@replica2\n"
"# zfs list -t snapshot\n"
"NAME                    USED  AVAIL  REFER  MOUNTPOINT\n"
"mypool@replica1         5.72M      -  43.6M  -\n"
"mypool@replica2             0      -  44.1M  -\n"
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  61.7M   898M         -         -     0%    6%  1.00x  ONLINE  -\n"
"mypool  960M  50.2M   910M         -         -     0%    5%  1.00x  ONLINE  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1899
#, fuzzy
msgid ""
"A second snapshot called _replica2_ was created. This second snapshot "
"contains only the changes that were made to the file system between now and "
"the previous snapshot, _replica1_. Using `zfs send -i` and indicating the "
"pair of snapshots generates an incremental replica stream containing only "
"the data that has changed. This can only succeed if the initial snapshot "
"already exists on the receiving side."
msgstr ""
"會建立一個名為 <replaceable>replica2</replaceable> 的第二個快照，這個快照只中"
"只會含有目前與前次快照 <replaceable>replica1</replaceable> 之間檔案系統所做的"
"變更。使用 <command>zfs send -i</command> 並指定要用來產生漸進備份串流的快"
"照，串流中只會含有做過更改的資料。這個動作只在接收端已經有初始快照時才可用。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1906
#, no-wrap
msgid ""
"# zfs send -v -i mypool@replica1 mypool@replica2 | zfs receive /backup/mypool\n"
"send from @replica1 to mypool@replica2 estimated size is 5.02M\n"
"total estimated size is 5.02M\n"
"TIME        SENT   SNAPSHOT\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1911
#, no-wrap
msgid ""
"# zpool list\n"
"NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG  CAP  DEDUP  HEALTH  ALTROOT\n"
"backup  960M  80.8M   879M         -         -     0%   8%  1.00x  ONLINE  -\n"
"mypool  960M  50.2M   910M         -         -     0%   5%  1.00x  ONLINE  -\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1917
#, no-wrap
msgid ""
"# zfs list\n"
"NAME                         USED  AVAIL  REFER  MOUNTPOINT\n"
"backup                      55.4M   240G   152K  /backup\n"
"backup/mypool               55.3M   240G  55.2M  /backup/mypool\n"
"mypool                      55.6M  11.6G  55.0M  /mypool\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1924
#, no-wrap
msgid ""
"# zfs list -t snapshot\n"
"NAME                                         USED  AVAIL  REFER  MOUNTPOINT\n"
"backup/mypool@replica1                       104K      -  50.2M  -\n"
"backup/mypool@replica2                          0      -  55.2M  -\n"
"mypool@replica1                             29.9K      -  50.0M  -\n"
"mypool@replica2                                 0      -  55.0M  -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1927
#, fuzzy
msgid ""
"The incremental stream was successfully transferred. Only the data that had "
"changed was replicated, rather than the entirety of _replica1_. Only the "
"differences were sent, which took much less time to transfer and saved disk "
"space by not copying the complete pool each time. This is useful when having "
"to rely on slow networks or when costs per transferred byte must be "
"considered."
msgstr ""
"如此一來，便成功傳輸漸進式的串流，只有做過更改的資料會被備份，不會傳送完整的 "
"<replaceable>replica1</replaceable>。由於不會備份完整的儲存池，只傳送差異的部"
"份，所以可以減少傳輸的時間並節省磁碟空間，特別是在網路緩慢或需要考量每位元傳"
"輸成本時非常有用。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1929
#, fuzzy
msgid ""
"A new file system, _backup/mypool_, is available with all of the files and "
"data from the pool _mypool_. If `-P` is specified, the properties of the "
"dataset will be copied, including compression settings, quotas, and mount "
"points. When `-R` is specified, all child datasets of the indicated dataset "
"will be copied, along with all of their properties. Sending and receiving "
"can be automated so that regular backups are created on the second pool."
msgstr ""
"從儲存池 <replaceable>mypool</replaceable> 複製所有檔案與資料的新檔案系統 "
"<replaceable>backup/mypool</replaceable> 便可以使用。若指定 <option>-P</"
"option>，會一併複製資料集的屬性，這包含壓縮 (Compression) 設定，配額 (Quota) "
"及掛載點 (Mount point)。若指定 <option>-R</option>，會複製所有指定資料集的子"
"資料集，及這些子資料集的所有屬性。可將傳送與接收自動化來定期使用第二個儲存池"
"做備份。"

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:1931
#, no-wrap
msgid "Sending Encrypted Backups over SSH"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1934
msgid ""
"Sending streams over the network is a good way to keep a remote backup, but "
"it does come with a drawback. Data sent over the network link is not "
"encrypted, allowing anyone to intercept and transform the streams back into "
"data without the knowledge of the sending user. This is undesirable, "
"especially when sending the streams over the internet to a remote host. SSH "
"can be used to securely encrypt data send over a network connection. Since "
"ZFS only requires the stream to be redirected from standard output, it is "
"relatively easy to pipe it through SSH. To keep the contents of the file "
"system encrypted in transit and on the remote system, consider using https://"
"wiki.freebsd.org/PEFS[PEFS]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1936
msgid ""
"A few settings and security precautions must be completed first. Only the "
"necessary steps required for the `zfs send` operation are shown here. For "
"more information on SSH, see crossref:security[openssh,\"OpenSSH\"]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1938
msgid "This configuration is required:"
msgstr "必要的環境設定："

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1940
msgid ""
"Passwordless SSH access between sending and receiving host using SSH keys"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1941
msgid ""
"Normally, the privileges of the `root` user are needed to send and receive "
"streams. This requires logging in to the receiving system as `root`. "
"However, logging in as `root` is disabled by default for security reasons. "
"The <<zfs-zfs-allow,ZFS Delegation>> system can be used to allow a non-"
"`root` user on each system to perform the respective send and receive "
"operations."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1942
msgid "On the sending system:"
msgstr "在傳送端系統上："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1946
#, no-wrap
msgid "# zfs allow -u someuser send,snapshot mypool\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1949
msgid ""
"To mount the pool, the unprivileged user must own the directory, and regular "
"users must be allowed to mount file systems. On the receiving system:"
msgstr ""
"要掛載儲存池，無權限的使用者必須擁有該目錄且必須允許一般的使用者掛載檔案系"
"統。在接收端系統上："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1958
#, no-wrap
msgid ""
"# sysctl vfs.usermount=1\n"
"vfs.usermount: 0 -> 1\n"
"# echo vfs.usermount=1 >> /etc/sysctl.conf\n"
"# zfs create recvpool/backup\n"
"# zfs allow -u someuser create,mount,receive recvpool/backup\n"
"# chown someuser /recvpool/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1961
msgid ""
"The unprivileged user now has the ability to receive and mount datasets, and "
"the _home_ dataset can be replicated to the remote system:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1966
#, no-wrap
msgid ""
"% zfs snapshot -r mypool/home@monday\n"
"% zfs send -R mypool/home@monday | ssh someuser@backuphost zfs recv -dvu recvpool/backup\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1969
msgid ""
"A recursive snapshot called _monday_ is made of the file system dataset "
"_home_ that resides on the pool _mypool_. Then it is sent with `zfs send -R` "
"to include the dataset, all child datasets, snapshots, clones, and settings "
"in the stream. The output is piped to the waiting `zfs receive` on the "
"remote host _backuphost_ through SSH. Using a fully qualified domain name or "
"IP address is recommended. The receiving machine writes the data to the "
"_backup_ dataset on the _recvpool_ pool. Adding `-d` to `zfs recv` "
"overwrites the name of the pool on the receiving side with the name of the "
"snapshot. `-u` causes the file systems to not be mounted on the receiving "
"side. When `-v` is included, more detail about the transfer is shown, "
"including elapsed time and the amount of data transferred."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:1971
#, no-wrap
msgid "Dataset, User, and Group Quotas"
msgstr "資料集、使用者以及群組配額"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1974
#, fuzzy
msgid ""
"<<zfs-term-quota,Dataset quotas>> are used to restrict the amount of space "
"that can be consumed by a particular dataset. <<zfs-term-refquota,Reference "
"Quotas>> work in very much the same way, but only count the space used by "
"the dataset itself, excluding snapshots and child datasets. Similarly, <<zfs-"
"term-userquota,user>> and <<zfs-term-groupquota,group>> quotas can be used "
"to prevent users or groups from using all of the space in the pool or "
"dataset."
msgstr ""
"資料集配額 (<link linkend=\"zfs-term-quota\">Dataset quota</link>) 可用來限制"
"特定資料集可以使用的的空間量。參考配額 (<link linkend=\"zfs-term-refquota"
"\">Reference Quota</link>) 的功能也非常相似，差在參考配額只會計算資料集自己使"
"用的空間，不含快照與子資料集。類似的，使用者 (<link linkend=\"zfs-term-"
"userquota\">User</link>) 與群組 (<link linkend=\"zfs-term-groupquota"
"\">Group</link>) 配額可以用來避免使用者或群組用掉儲存池或資料集的所有空間。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1976
msgid ""
"The following examples assume that the users already exist in the system. "
"Before adding a user to the system, make sure to create their home dataset "
"first and set the `mountpoint` to `/home/_bob_`. Then, create the user and "
"make the home directory point to the dataset's `mountpoint` location. This "
"will properly set owner and group permissions without shadowing any pre-"
"existing home directory paths that might exist."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1978
msgid "To enforce a dataset quota of 10 GB for [.filename]#storage/home/bob#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1982
#, no-wrap
msgid "# zfs set quota=10G storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1985
msgid ""
"To enforce a reference quota of 10 GB for [.filename]#storage/home/bob#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1989
#, no-wrap
msgid "# zfs set refquota=10G storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1992
msgid "To remove a quota of 10 GB for [.filename]#storage/home/bob#:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:1996
#, no-wrap
msgid "# zfs set quota=none storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:1999
msgid ""
"The general format is `userquota@_user_=_size_`, and the user's name must be "
"in one of these formats:"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2001
msgid "POSIX compatible name such as _joe_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2002
msgid "POSIX numeric ID such as _789_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2003
msgid "SID name such as _joe.bloggs@example.com_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2004
msgid "SID numeric ID such as _S-1-123-456-789_."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2006
msgid "For example, to enforce a user quota of 50 GB for the user named _joe_:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2010
#, no-wrap
msgid "# zfs set userquota@joe=50G\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2013
msgid "To remove any quota:"
msgstr "要移除所有配額："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2017
#, no-wrap
msgid "# zfs set userquota@joe=none\n"
msgstr ""

#. type: delimited block = 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2022
msgid ""
"User quota properties are not displayed by `zfs get all`. Non-`root` users "
"can only see their own quotas unless they have been granted the `userquota` "
"privilege. Users with this privilege are able to view and set everyone's "
"quota."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2025
msgid ""
"The general format for setting a group quota is: `groupquota@_group_=_size_`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2027
msgid "To set the quota for the group _firstgroup_ to 50 GB, use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2031
#, no-wrap
msgid "# zfs set groupquota@firstgroup=50G\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2034
msgid ""
"To remove the quota for the group _firstgroup_, or to make sure that one is "
"not set, instead use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2038
#, no-wrap
msgid "# zfs set groupquota@firstgroup=none\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2041
msgid ""
"As with the user quota property, non-`root` users can only see the quotas "
"associated with the groups to which they belong. However, `root` or a user "
"with the `groupquota` privilege can view and set all quotas for all groups."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2043
msgid ""
"To display the amount of space used by each user on a file system or "
"snapshot along with any quotas, use `zfs userspace`. For group information, "
"use `zfs groupspace`. For more information about supported options or how to "
"display only specific options, refer to man:zfs[1]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2045
msgid ""
"Users with sufficient privileges, and `root`, can list the quota for [."
"filename]#storage/home/bob# using:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2049
#, no-wrap
msgid "# zfs get quota storage/home/bob\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2052
#, no-wrap
msgid "Reservations"
msgstr "保留空間"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2055
#, fuzzy
msgid ""
"<<zfs-term-reservation,Reservations>> guarantee a minimum amount of space "
"will always be available on a dataset. The reserved space will not be "
"available to any other dataset. This feature can be especially useful to "
"ensure that free space is available for an important dataset or log files."
msgstr ""
"保留空間 (<link linkend=\"zfs-term-reservation\">Reservation</link>) 可以確保"
"資料集最少可用的空間量，其他任何資料集無法使用保留的空間，這個功能在要確保有"
"足夠的可用空間來存放重要的資料集或日誌檔時特別有用。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2057
msgid ""
"The general format of the `reservation` property is `reservation=_size_`, so "
"to set a reservation of 10 GB on [.filename]#storage/home/bob#, use:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2061
#, no-wrap
msgid "# zfs set reservation=10G storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2064
msgid "To clear any reservation:"
msgstr "要清除任何保留空間："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2068
#, no-wrap
msgid "# zfs set reservation=none storage/home/bob\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2071
msgid ""
"The same principle can be applied to the `refreservation` property for "
"setting a <<zfs-term-refreservation,Reference Reservation>>, with the "
"general format `refreservation=_size_`."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2073
#, fuzzy
msgid ""
"This command shows any reservations or refreservations that exist on [."
"filename]#storage/home/bob#:"
msgstr ""
"這個指令會顯示任何已設定於 <filename>storage/home/bob</filename> 的 "
"reservation 或 refreservation："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2078
#, no-wrap
msgid ""
"# zfs get reservation storage/home/bob\n"
"# zfs get refreservation storage/home/bob\n"
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2081
#, no-wrap
msgid "Compression"
msgstr "壓縮 (Compression)"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2084
msgid ""
"ZFS provides transparent compression. Compressing data at the block level as "
"it is written not only saves space, but can also increase disk throughput. "
"If data is compressed by 25%, but the compressed data is written to the disk "
"at the same rate as the uncompressed version, resulting in an effective "
"write speed of 125%. Compression can also be a great alternative to <<zfs-"
"zfs-deduplication,Deduplication>> because it does not require additional "
"memory."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2086
msgid ""
"ZFS offers several different compression algorithms, each with different "
"trade-offs. With the introduction of LZ4 compression in ZFS v5000, it is "
"possible to enable compression for the entire pool without the large "
"performance trade-off of other algorithms. The biggest advantage to LZ4 is "
"the _early abort_ feature. If LZ4 does not achieve at least 12.5% "
"compression in the first part of the data, the block is written uncompressed "
"to avoid wasting CPU cycles trying to compress data that is either already "
"compressed or uncompressible. For details about the different compression "
"algorithms available in ZFS, see the <<zfs-term-compression,Compression>> "
"entry in the terminology section."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2088
msgid ""
"The administrator can monitor the effectiveness of compression using a "
"number of dataset properties."
msgstr "管理者可以使用資料集的屬性來監視壓縮的效果。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2097
#, no-wrap
msgid ""
"# zfs get used,compressratio,compression,logicalused mypool/compressed_dataset\n"
"NAME        PROPERTY          VALUE     SOURCE\n"
"mypool/compressed_dataset  used              449G      -\n"
"mypool/compressed_dataset  compressratio     1.11x     -\n"
"mypool/compressed_dataset  compression       lz4       local\n"
"mypool/compressed_dataset  logicalused       496G      -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2100
msgid ""
"The dataset is currently using 449 GB of space (the used property). Without "
"compression, it would have taken 496 GB of space (the `logicalused` "
"property). This results in the 1.11:1 compression ratio."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2102
msgid ""
"Compression can have an unexpected side effect when combined with <<zfs-term-"
"userquota,User Quotas>>. User quotas restrict how much space a user can "
"consume on a dataset, but the measurements are based on how much space is "
"used _after compression_. So if a user has a quota of 10 GB, and writes 10 "
"GB of compressible data, they will still be able to store additional data. "
"If they later update a file, say a database, with more or less compressible "
"data, the amount of space available to them will change. This can result in "
"the odd situation where a user did not increase the actual amount of data "
"(the `logicalused` property), but the change in compression caused them to "
"reach their quota limit."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2104
msgid ""
"Compression can have a similar unexpected interaction with backups. Quotas "
"are often used to limit how much data can be stored to ensure there is "
"sufficient backup space available. However since quotas do not consider "
"compression, more data may be written than would fit with uncompressed "
"backups."
msgstr ""
"壓縮功能在與備份功能一起使用時也可能會有類似的問題，通常會使用配額功能來限制"
"能夠儲存的資料量來確保有足夠的備份空間可用。但是由於配額功能並不會考量壓縮狀"
"況，可能會有比未壓縮版本備份更多的資料量會被寫入到資料集。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2106
#, no-wrap
msgid "Zstandard Compression"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2109
msgid ""
"In OpenZFS 2.0, a new compression algorithm was added. Zstandard (Zstd) "
"offers higher compression ratios than the default LZ4 while offering much "
"greater speeds than the alternative, gzip. OpenZFS 2.0 is available starting "
"with FreeBSD 12.1-RELEASE via package:sysutils/openzfs[] and has been the "
"default in FreeBSD 13-CURRENT since September 2020, and will by in FreeBSD "
"13.0-RELEASE."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2111
msgid ""
"Zstd provides a large selection of compression levels, providing fine-"
"grained control over performance versus compression ratio. One of the main "
"advantages of Zstd is that the decompression speed is independent of the "
"compression level. For data that is written once but read many times, Zstd "
"allows the use of the highest compression levels without a read performance "
"penalty."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2113
msgid ""
"Even when data is updated frequently, there are often performance gains that "
"come from enabling compression. One of the biggest advantages comes from the "
"compressed ARC feature. ZFS's Adaptive Replacement Cache (ARC) caches the "
"compressed version of the data in RAM, decompressing it each time it is "
"needed. This allows the same amount of RAM to store more data and metadata, "
"increasing the cache hit ratio."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2115
msgid ""
"ZFS offers 19 levels of Zstd compression, each offering incrementally more "
"space savings in exchange for slower compression. The default level is "
"`zstd-3` and offers greater compression than LZ4 without being significantly "
"slower. Levels above 10 require significant amounts of memory to compress "
"each block, so they are discouraged on systems with less than 16 GB of RAM. "
"ZFS also implements a selection of the Zstd_fast_ levels, which get "
"correspondingly faster but offer lower compression ratios. ZFS supports "
"`zstd-fast-1` through `zstd-fast-10`, `zstd-fast-20` through `zstd-fast-100` "
"in increments of 10, and finally `zstd-fast-500` and `zstd-fast-1000` which "
"provide minimal compression, but offer very high performance."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2117
msgid ""
"If ZFS is not able to allocate the required memory to compress a block with "
"Zstd, it will fall back to storing the block uncompressed. This is unlikely "
"to happen outside of the highest levels of Zstd on systems that are memory "
"constrained. The sysctl `kstat.zfs.misc.zstd.compress_alloc_fail` counts how "
"many times this has occurred since the ZFS module was loaded."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2119
#, no-wrap
msgid "Deduplication"
msgstr "去重複 (Deduplication)"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2122
#, fuzzy
msgid ""
"When enabled, <<zfs-term-deduplication,deduplication>> uses the checksum of "
"each block to detect duplicate blocks. When a new block is a duplicate of an "
"existing block, ZFS writes an additional reference to the existing data "
"instead of the whole duplicate block. Tremendous space savings are possible "
"if the data contains many duplicated files or repeated information. Be "
"warned: deduplication requires an extremely large amount of memory, and most "
"of the space savings can be had without the extra cost by enabling "
"compression instead."
msgstr ""
"當開啟，去重複 (<link linkend=\"zfs-term-deduplication\">Deduplication</"
"link>) 功能會使用每個資料區塊的校驗碼 (Checksum) 來偵測重複的資料區塊，當新的"
"資料區塊與現有的資料區塊重複，<acronym>ZFS</acronym> 便會寫入連接到現有資料的"
"參考來替代寫入重複的資料區塊，這在資料中有大量重複的檔案或資訊時可以節省大量"
"的空間，要注意的是：去重複功能需要使用大量的記憶體且大部份可節省的空間可改開"
"啟壓縮功能來達成，而壓縮功能不需要使用額外的記憶體。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2124
msgid "To activate deduplication, set the `dedup` property on the target pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2128
#, no-wrap
msgid "# zfs set dedup=on pool\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2131
msgid ""
"Only new data being written to the pool will be deduplicated. Data that has "
"already been written to the pool will not be deduplicated merely by "
"activating this option. A pool with a freshly activated deduplication "
"property will look like this example:"
msgstr ""
"只有要被寫入到儲存池的新資料才會做去重複的動作，先前已被寫入到儲存池的資料不"
"會因此啟動了這個選項而做去重複。查看已開啟去重複屬性的儲存池會如下："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2137
#, no-wrap
msgid ""
"# zpool list\n"
"NAME  SIZE ALLOC  FREE   CKPOINT  EXPANDSZ   FRAG   CAP   DEDUP   HEALTH   ALTROOT\n"
"pool 2.84G 2.19M 2.83G         -         -     0%    0%   1.00x   ONLINE   -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2140
#, fuzzy
msgid ""
"The `DEDUP` column shows the actual rate of deduplication for the pool. A "
"value of `1.00x` shows that data has not been deduplicated yet. In the next "
"example, the ports tree is copied three times into different directories on "
"the deduplicated pool created above."
msgstr ""
"<literal>DEDUP</literal> 欄位會顯示儲存池的實際去重複率，數值為 "
"<literal>1.00x</literal> 代表資料尚未被去重複。在下一個例子會在前面所建立的去"
"重複儲存池中複製三份 Port 樹到不同的目錄中。"

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2146
#, no-wrap
msgid ""
"# for d in dir1 dir2 dir3; do\n"
"> mkdir $d && cp -R /usr/ports $d &\n"
"> done\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2149
msgid "Redundant data is detected and deduplicated:"
msgstr "已經偵測到重複的資料並做去重複："

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2155
#, no-wrap
msgid ""
"# zpool list\n"
"NAME SIZE  ALLOC  FREE   CKPOINT  EXPANDSZ   FRAG  CAP   DEDUP   HEALTH   ALTROOT\n"
"pool 2.84G 20.9M 2.82G         -         -     0%   0%   3.00x   ONLINE   -\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2158
#, fuzzy
msgid ""
"The `DEDUP` column shows a factor of `3.00x`. Multiple copies of the ports "
"tree data was detected and deduplicated, using only a third of the space. "
"The potential for space savings can be enormous, but comes at the cost of "
"having enough memory to keep track of the deduplicated blocks."
msgstr ""
"<literal>DEDUP</literal> 欄位顯示有 <literal>3.00x</literal> 的去重複率，這代"
"表已偵測到多份複製的 Port 樹資料並做了去重複的動作，且只會使用第三份資料所佔"
"的空間。去重複能節省空間的潛力可以非常巨大，但會需要消耗大量的記憶體來持續追"
"蹤去重複的資料區塊。"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2160
msgid ""
"Deduplication is not always beneficial, especially when the data on a pool "
"is not redundant. ZFS can show potential space savings by simulating "
"deduplication on an existing pool:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2165
#, no-wrap
msgid ""
"# zdb -S pool\n"
"Simulated DDT histogram:\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2181
#, no-wrap
msgid ""
"bucket              allocated                       referenced\n"
"______   ______________________________   ______________________________\n"
"refcnt   blocks   LSIZE   PSIZE   DSIZE   blocks   LSIZE   PSIZE   DSIZE\n"
"------   ------   -----   -----   -----   ------   -----   -----   -----\n"
"     1    2.58M    289G    264G    264G    2.58M    289G    264G    264G\n"
"     2     206K   12.6G   10.4G   10.4G     430K   26.4G   21.6G   21.6G\n"
"     4    37.6K    692M    276M    276M     170K   3.04G   1.26G   1.26G\n"
"     8    2.18K   45.2M   19.4M   19.4M    20.0K    425M    176M    176M\n"
"    16      174   2.83M   1.20M   1.20M    3.33K   48.4M   20.4M   20.4M\n"
"    32       40   2.17M    222K    222K    1.70K   97.2M   9.91M   9.91M\n"
"    64        9     56K   10.5K   10.5K      865   4.96M    948K    948K\n"
"   128        2   9.50K      2K      2K      419   2.11M    438K    438K\n"
"   256        5   61.5K     12K     12K    1.90K   23.0M   4.47M   4.47M\n"
"    1K        2      1K      1K      1K    2.98K   1.49M   1.49M   1.49M\n"
" Total    2.82M    303G    275G    275G    3.20M    319G    287G    287G\n"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2183
#, no-wrap
msgid "dedup = 1.05, compress = 1.11, copies = 1.00, dedup * compress / copies = 1.16\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2186
msgid ""
"After `zdb -S` finishes analyzing the pool, it shows the space reduction "
"ratio that would be achieved by activating deduplication. In this case, "
"`1.16` is a very poor space saving ratio that is mostly provided by "
"compression. Activating deduplication on this pool would not save any "
"significant amount of space, and is not worth the amount of memory required "
"to enable deduplication. Using the formula _ratio = dedup * compress / "
"copies_, system administrators can plan the storage allocation, deciding "
"whether the workload will contain enough duplicate blocks to justify the "
"memory requirements. If the data is reasonably compressible, the space "
"savings may be very good. Enabling compression first is recommended, and "
"compression can also provide greatly increased performance. Only enable "
"deduplication in cases where the additional savings will be considerable and "
"there is sufficient memory for the <<zfs-term-deduplication,DDT>>."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2188
#, no-wrap
msgid "ZFS and Jails"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2191
msgid ""
"`zfs jail` and the corresponding `jailed` property are used to delegate a "
"ZFS dataset to a crossref:jails[jails,Jail]. `zfs jail _jailid_` attaches a "
"dataset to the specified jail, and `zfs unjail` detaches it. For the dataset "
"to be controlled from within a jail, the `jailed` property must be set. Once "
"a dataset is jailed, it can no longer be mounted on the host because it may "
"have mount points that would compromise the security of the host."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2193
#, no-wrap
msgid "Delegated Administration"
msgstr "委託管理"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2196
#, fuzzy
msgid ""
"A comprehensive permission delegation system allows unprivileged users to "
"perform ZFS administration functions. For example, if each user's home "
"directory is a dataset, users can be given permission to create and destroy "
"snapshots of their home directories. A backup user can be given permission "
"to use replication features. A usage statistics script can be allowed to run "
"with access only to the space utilization data for all users. It is even "
"possible to delegate the ability to delegate permissions. Permission "
"delegation is possible for each subcommand and most properties."
msgstr ""
"一個全面性的權限委託系統可能無權限的使用者執行 <acronym>ZFS</acronym> 的管理"
"功能。例如，若每個使用者的家目錄均為一個資料集，便可以給予使用者權限建立與摧"
"毀它們家目錄中的快照。可以給予備份使用者使用備份功能的權限。一個使用量統計的 "
"Script 可以允許其在執行時能存取所有使用者的空間利用率資料。甚至可以將委託權限"
"委託給其他人，每個子指令與大多數屬性都可使用權限委託。"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2198
#, no-wrap
msgid "Delegating Dataset Creation"
msgstr "委託資料集建立"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2201
msgid ""
"`zfs allow _someuser_ create _mydataset_` gives the specified user "
"permission to create child datasets under the selected parent dataset. There "
"is a caveat: creating a new dataset involves mounting it. That requires "
"setting the FreeBSD `vfs.usermount` man:sysctl[8] to `1` to allow non-root "
"users to mount a file system. There is another restriction aimed at "
"preventing abuse: non-`root` users must own the mountpoint where the file "
"system is to be mounted."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2203
#, no-wrap
msgid "Delegating Permission Delegation"
msgstr "委託權限委託"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2206
msgid ""
"`zfs allow _someuser_ allow _mydataset_` gives the specified user the "
"ability to assign any permission they have on the target dataset, or its "
"children, to other users. If a user has the `snapshot` permission and the "
"`allow` permission, that user can then grant the `snapshot` permission to "
"other users."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2208
#, no-wrap
msgid "Advanced Topics"
msgstr "進階主題"

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2211
#, no-wrap
msgid "Tuning"
msgstr "調校"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2214
msgid ""
"There are a number of tunables that can be adjusted to make ZFS perform best "
"for different workloads."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2216
msgid ""
"[[zfs-advanced-tuning-arc_max]] `_vfs.zfs.arc_max_` - Maximum size of the "
"<<zfs-term-arc,ARC>>. The default is all RAM but 1 GB, or 5/8 of all RAM, "
"whichever is more. However, a lower value should be used if the system will "
"be running any other daemons or processes that may require memory. This "
"value can be adjusted at runtime with man:sysctl[8] and can be set in [."
"filename]#/boot/loader.conf# or [.filename]#/etc/sysctl.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2217
msgid ""
"[[zfs-advanced-tuning-arc_meta_limit]] `_vfs.zfs.arc_meta_limit_` - Limit "
"the portion of the <<zfs-term-arc,ARC>> that can be used to store metadata. "
"The default is one fourth of `vfs.zfs.arc_max`. Increasing this value will "
"improve performance if the workload involves operations on a large number of "
"files and directories, or frequent metadata operations, at the cost of less "
"file data fitting in the <<zfs-term-arc,ARC>>. This value can be adjusted at "
"runtime with man:sysctl[8] and can be set in [.filename]#/boot/loader.conf# "
"or [.filename]#/etc/sysctl.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2218
msgid ""
"[[zfs-advanced-tuning-arc_min]] `_vfs.zfs.arc_min_` - Minimum size of the "
"<<zfs-term-arc,ARC>>. The default is one half of `vfs.zfs.arc_meta_limit`. "
"Adjust this value to prevent other applications from pressuring out the "
"entire <<zfs-term-arc,ARC>>. This value can be adjusted at runtime with man:"
"sysctl[8] and can be set in [.filename]#/boot/loader.conf# or [.filename]#/"
"etc/sysctl.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2219
msgid ""
"[[zfs-advanced-tuning-vdev-cache-size]] `_vfs.zfs.vdev.cache.size_` - A "
"preallocated amount of memory reserved as a cache for each device in the "
"pool. The total amount of memory used will be this value multiplied by the "
"number of devices. This value can only be adjusted at boot time, and is set "
"in [.filename]#/boot/loader.conf#."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2220
msgid ""
"[[zfs-advanced-tuning-min-auto-ashift]] `_vfs.zfs.min_auto_ashift_` - "
"Minimum `ashift` (sector size) that will be used automatically at pool "
"creation time. The value is a power of two. The default value of `9` "
"represents `2^9 = 512`, a sector size of 512 bytes. To avoid _write "
"amplification_ and get the best performance, set this value to the largest "
"sector size used by a device in the pool."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2222
msgid ""
"  Many drives have 4 KB sectors. Using the default `ashift` of `9` with "
"these drives results in write amplification on these devices. Data that "
"could be contained in a single 4 KB write must instead be written in eight "
"512-byte writes. ZFS tries to read the native sector size from all devices "
"when creating a pool, but many drives with 4 KB sectors report that their "
"sectors are 512 bytes for compatibility. Setting `vfs.zfs.min_auto_ashift` "
"to `12` (`2^12 = 4096`) before creating a pool forces ZFS to use 4 KB blocks "
"for best performance on these drives."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2224
msgid ""
"  Forcing 4 KB blocks is also useful on pools where disk upgrades are "
"planned. Future disks are likely to use 4 KB sectors, and `ashift` values "
"cannot be changed after a pool is created."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2226
msgid ""
"  In some specific cases, the smaller 512-byte block size might be "
"preferable. When used with 512-byte disks for databases, or as storage for "
"virtual machines, less data is transferred during small random reads. This "
"can provide better performance, especially when using a smaller ZFS record "
"size."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2227
msgid ""
"[[zfs-advanced-tuning-prefetch_disable]] `_vfs.zfs.prefetch_disable_` - "
"Disable prefetch. A value of `0` is enabled and `1` is disabled. The default "
"is `0`, unless the system has less than 4 GB of RAM. Prefetch works by "
"reading larger blocks than were requested into the <<zfs-term-arc,ARC>> in "
"hopes that the data will be needed soon. If the workload has a large number "
"of random reads, disabling prefetch may actually improve performance by "
"reducing unnecessary reads. This value can be adjusted at any time with man:"
"sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2228
msgid ""
"[[zfs-advanced-tuning-vdev-trim_on_init]] `_vfs.zfs.vdev.trim_on_init_` - "
"Control whether new devices added to the pool have the `TRIM` command run on "
"them. This ensures the best performance and longevity for SSDs, but takes "
"extra time. If the device has already been secure erased, disabling this "
"setting will make the addition of the new device faster. This value can be "
"adjusted at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2229
msgid ""
"[[zfs-advanced-tuning-vdev-max_pending]] `_vfs.zfs.vdev.max_pending_` - "
"Limit the number of pending I/O requests per device. A higher value will "
"keep the device command queue full and may give higher throughput. A lower "
"value will reduce latency. This value can be adjusted at any time with man:"
"sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2230
msgid ""
"[[zfs-advanced-tuning-top_maxinflight]] `_vfs.zfs.top_maxinflight_` - "
"Maximum number of outstanding I/Os per top-level <<zfs-term-vdev,vdev>>. "
"Limits the depth of the command queue to prevent high latency. The limit is "
"per top-level vdev, meaning the limit applies to each <<zfs-term-vdev-mirror,"
"mirror>>, <<zfs-term-vdev-raidz,RAID-Z>>, or other vdev independently. This "
"value can be adjusted at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2231
msgid ""
"[[zfs-advanced-tuning-l2arc_write_max]] `_vfs.zfs.l2arc_write_max_` - Limit "
"the amount of data written to the <<zfs-term-l2arc,L2ARC>> per second. This "
"tunable is designed to extend the longevity of SSDs by limiting the amount "
"of data written to the device. This value can be adjusted at any time with "
"man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2232
msgid ""
"[[zfs-advanced-tuning-l2arc_write_boost]] `_vfs.zfs.l2arc_write_boost_` - "
"The value of this tunable is added to <<zfs-advanced-tuning-l2arc_write_max,"
"`vfs.zfs.l2arc_write_max`>> and increases the write speed to the SSD until "
"the first block is evicted from the <<zfs-term-l2arc,L2ARC>>. This \"Turbo "
"Warmup Phase\" is designed to reduce the performance loss from an empty "
"<<zfs-term-l2arc,L2ARC>> after a reboot. This value can be adjusted at any "
"time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2233
msgid ""
"[[zfs-advanced-tuning-scrub_delay]]`_vfs.zfs.scrub_delay_` - Number of ticks "
"to delay between each I/O during a <<zfs-term-scrub,`scrub`>>. To ensure "
"that a `scrub` does not interfere with the normal operation of the pool, if "
"any other I/O is happening the `scrub` will delay between each command. This "
"value controls the limit on the total IOPS (I/Os Per Second) generated by "
"the `scrub`. The granularity of the setting is determined by the value of "
"`kern.hz` which defaults to 1000 ticks per second. This setting may be "
"changed, resulting in a different effective IOPS limit. The default value is "
"`4`, resulting in a limit of: 1000 ticks/sec / 4 = 250 IOPS. Using a value "
"of _20_ would give a limit of: 1000 ticks/sec / 20 = 50 IOPS. The speed of "
"`scrub` is only limited when there has been recent activity on the pool, as "
"determined by <<zfs-advanced-tuning-scan_idle,`vfs.zfs.scan_idle`>>. This "
"value can be adjusted at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2234
msgid ""
"[[zfs-advanced-tuning-resilver_delay]] `_vfs.zfs.resilver_delay_` - Number "
"of milliseconds of delay inserted between each I/O during a <<zfs-term-"
"resilver,resilver>>. To ensure that a resilver does not interfere with the "
"normal operation of the pool, if any other I/O is happening the resilver "
"will delay between each command. This value controls the limit of total IOPS "
"(I/Os Per Second) generated by the resilver. The granularity of the setting "
"is determined by the value of `kern.hz` which defaults to 1000 ticks per "
"second. This setting may be changed, resulting in a different effective IOPS "
"limit. The default value is 2, resulting in a limit of: 1000 ticks/sec / 2 = "
"500 IOPS. Returning the pool to an <<zfs-term-online,Online>> state may be "
"more important if another device failing could <<zfs-term-faulted,Fault>> "
"the pool, causing data loss. A value of 0 will give the resilver operation "
"the same priority as other operations, speeding the healing process. The "
"speed of resilver is only limited when there has been other recent activity "
"on the pool, as determined by <<zfs-advanced-tuning-scan_idle,`vfs.zfs."
"scan_idle`>>. This value can be adjusted at any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2235
msgid ""
"[[zfs-advanced-tuning-scan_idle]] `_vfs.zfs.scan_idle_` - Number of "
"milliseconds since the last operation before the pool is considered idle. "
"When the pool is idle the rate limiting for <<zfs-term-scrub,`scrub`>> and "
"<<zfs-term-resilver,resilver>> are disabled. This value can be adjusted at "
"any time with man:sysctl[8]."
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2236
msgid ""
"[[zfs-advanced-tuning-txg-timeout]] `_vfs.zfs.txg.timeout_` - Maximum number "
"of seconds between <<zfs-term-txg,transaction group>>s. The current "
"transaction group will be written to the pool and a fresh transaction group "
"started if this amount of time has elapsed since the previous transaction "
"group. A transaction group my be triggered earlier if enough data is "
"written. The default value is 5 seconds. A larger value may improve read "
"performance by delaying asynchronous writes, but this may cause uneven "
"performance when the transaction group is written. This value can be "
"adjusted at any time with man:sysctl[8]."
msgstr ""

#. type: Title ===
#: documentation/content/en/books/handbook/zfs/_index.adoc:2238
#, no-wrap
msgid "ZFS on i386"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2241
msgid ""
"Some of the features provided by ZFS are memory intensive, and may require "
"tuning for maximum efficiency on systems with limited RAM."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2242
#, no-wrap
msgid "Memory"
msgstr "記憶體"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2245
msgid ""
"As a bare minimum, the total system memory should be at least one gigabyte. "
"The amount of recommended RAM depends upon the size of the pool and which "
"ZFS features are used. A general rule of thumb is 1 GB of RAM for every 1 TB "
"of storage. If the deduplication feature is used, a general rule of thumb is "
"5 GB of RAM per TB of storage to be deduplicated. While some users "
"successfully use ZFS with less RAM, systems under heavy load may panic due "
"to memory exhaustion. Further tuning may be required for systems with less "
"than the recommended RAM requirements."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2246
#, no-wrap
msgid "Kernel Configuration"
msgstr "核心設定"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2249
msgid ""
"Due to the address space limitations of the i386(TM) platform, ZFS users on "
"the i386(TM) architecture must add this option to a custom kernel "
"configuration file, rebuild the kernel, and reboot:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2253
#, no-wrap
msgid "options        KVA_PAGES=512\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2256
msgid ""
"This expands the kernel address space, allowing the `vm.kvm_size` tunable to "
"be pushed beyond the currently imposed limit of 1 GB, or the limit of 2 GB "
"for PAE. To find the most suitable value for this option, divide the desired "
"address space in megabytes by four. In this example, it is `512` for 2 GB."
msgstr ""

#. type: Title ====
#: documentation/content/en/books/handbook/zfs/_index.adoc:2257
#, no-wrap
msgid "Loader Tunables"
msgstr "載入程式可調參數"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2260
msgid ""
"The [.filename]#kmem# address space can be increased on all FreeBSD "
"architectures. On a test system with 1 GB of physical memory, success was "
"achieved with these options added to [.filename]#/boot/loader.conf#, and the "
"system restarted:"
msgstr ""

#. type: delimited block . 4
#: documentation/content/en/books/handbook/zfs/_index.adoc:2267
#, no-wrap
msgid ""
"vm.kmem_size=\"330M\"\n"
"vm.kmem_size_max=\"330M\"\n"
"vfs.zfs.arc_max=\"40M\"\n"
"vfs.zfs.vdev.cache.size=\"5M\"\n"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2270
msgid ""
"For a more detailed list of recommendations for ZFS-related tuning, see "
"https://wiki.freebsd.org/ZFSTuningGuide[]."
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2272
#, no-wrap
msgid "Additional Resources"
msgstr "其他資源"

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2275
msgid "http://open-zfs.org[OpenZFS]"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2276
msgid "https://wiki.freebsd.org/ZFSTuningGuide[FreeBSD Wiki - ZFS Tuning]"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2277
msgid ""
"http://docs.oracle.com/cd/E19253-01/819-5461/index.html[Oracle Solaris ZFS "
"Administration Guide]"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2278
msgid ""
"https://calomel.org/zfs_raid_speed_capacity.html[Calomel Blog - ZFS Raidz "
"Performance, Capacity and Integrity]"
msgstr ""

#. type: Title ==
#: documentation/content/en/books/handbook/zfs/_index.adoc:2280
#, no-wrap
msgid "ZFS Features and Terminology"
msgstr ""

#. type: Plain text
#: documentation/content/en/books/handbook/zfs/_index.adoc:2283
#, fuzzy
msgid ""
"ZFS is a fundamentally different file system because it is more than just a "
"file system. ZFS combines the roles of file system and volume manager, "
"enabling additional storage devices to be added to a live system and having "
"the new space available on all of the existing file systems in that pool "
"immediately. By combining the traditionally separate roles, ZFS is able to "
"overcome previous limitations that prevented RAID groups being able to grow. "
"Each top level device in a pool is called a _vdev_, which can be a simple "
"disk or a RAID transformation such as a mirror or RAID-Z array. ZFS file "
"systems (called _datasets_) each have access to the combined free space of "
"the entire pool. As blocks are allocated from the pool, the space available "
"to each file system decreases. This approach avoids the common pitfall with "
"extensive partitioning where free space becomes fragmented across the "
"partitions."
msgstr ""
"<acronym>ZFS</acronym> 是一個從本質上與眾不同的檔案系統，由於它並非只是一個檔"
"案系統，<acronym>ZFS</acronym> 結合了檔案系統及磁碟區管理程式，讓額外的儲存裝"
"置可以即時的加入到系統並可讓既有的檔案系統立即使用這些在儲存池中空間。透過結"
"合傳統區分為二的兩個角色，<acronym>ZFS</acronym> 能夠克服以往 <acronym>RAID</"
"acronym> 磁碟群組無法擴充的限制。每個在儲存池頂層的裝置稱作 <emphasis>vdev</"
"emphasis>，其可以是一個簡單的磁碟或是一個 <acronym>RAID</acronym> 如鏡像或 "
"<acronym>RAID-Z</acronym> 陣列。<acronym>ZFS</acronym> 的檔案系統 (稱作 "
"<emphasis>資料集 (Dataset)</emphasis>) 每一個資料集均可存取整個存池所共通的可"
"用空間，隨著使用儲存池來配置空間區塊，儲存池能給每個檔案系統使用的可用空間就"
"會減少，這個方法可以避免擴大分割區會使的可用空間分散分割區之間的常見問題。"

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2294
#, no-wrap
msgid ""
"|[[zfs-term-pool]]pool\n"
"|A storage _pool_ is the most basic building block of ZFS. A pool is made up of one or more vdevs, the underlying devices that store the data. A pool is then used to create one or more file systems (datasets) or block devices (volumes). These datasets and volumes share the pool of remaining free space. Each pool is uniquely identified by a name and a GUID. The features available are determined by the ZFS version number on the pool.\n"
"\n"
"|[[zfs-term-vdev]]vdev Types\n"
"a|A pool is made up of one or more vdevs, which themselves can be a single disk or a group of disks, in the case of a RAID transform. When multiple vdevs are used, ZFS spreads data across the vdevs to increase performance and maximize usable space. \n"
"\n"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2295
#, no-wrap
msgid "[[zfs-term-vdev-disk]] _Disk_ - The most basic type of vdev is a standard block device. This can be an entire disk (such as [.filename]#/dev/ada0# or [.filename]#/dev/da0#) or a partition ([.filename]#/dev/ada0p3#). On FreeBSD, there is no performance penalty for using a partition rather than the entire disk. This differs from recommendations made by the Solaris documentation.\n"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2297
#: documentation/content/en/books/handbook/zfs/_index.adoc:2306
#: documentation/content/en/books/handbook/zfs/_index.adoc:2393
#, no-wrap
msgid "====\n"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2300
#, no-wrap
msgid ""
"Using an entire disk as part of a bootable pool is strongly discouraged, as this may render the pool unbootable. Likewise, you should not use an entire disk as part of a mirror or RAID-Z vdev. These are because it is impossible to reliably determine the size of an unpartitioned disk at boot time and because there's no place to put in boot code.\n"
"====\n"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2303
msgid ""
"[[zfs-term-vdev-file]] _File_ - In addition to disks, ZFS pools can be "
"backed by regular files, this is especially useful for testing and "
"experimentation. Use the full path to the file as the device path in `zpool "
"create`. All vdevs must be at least 128 MB in size."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2304
msgid ""
"[[zfs-term-vdev-mirror]] _Mirror_ - When creating a mirror, specify the "
"`mirror` keyword followed by the list of member devices for the mirror. A "
"mirror consists of two or more devices, all data will be written to all "
"member devices. A mirror vdev will only hold as much data as its smallest "
"member. A mirror vdev can withstand the failure of all but one of its "
"members without losing any data."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2308
#, no-wrap
msgid ""
"A regular single disk vdev can be upgraded to a mirror vdev at any time with `zpool <<zfs-zpool-attach,attach>>`.\n"
"====\n"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2311
msgid ""
"[[zfs-term-vdev-raidz]] _RAID-Z_ - ZFS implements RAID-Z, a variation on "
"standard RAID-5 that offers better distribution of parity and eliminates the "
"\"RAID-5 write hole\" in which the data and parity information become "
"inconsistent after an unexpected restart. ZFS supports three levels of RAID-"
"Z which provide varying levels of redundancy in exchange for decreasing "
"levels of usable storage. The types are named RAID-Z1 through RAID-Z3 based "
"on the number of parity devices in the array and the number of disks which "
"can fail while the pool remains operational."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2313
msgid ""
"  In a RAID-Z1 configuration with four disks, each 1 TB, usable storage is 3 "
"TB and the pool will still be able to operate in degraded mode with one "
"faulted disk. If an additional disk goes offline before the faulted disk is "
"replaced and resilvered, all data in the pool can be lost."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2315
msgid ""
"  In a RAID-Z3 configuration with eight disks of 1 TB, the volume will "
"provide 5 TB of usable space and still be able to operate with three faulted "
"disks. Sun(TM) recommends no more than nine disks in a single vdev. If the "
"configuration has more disks, it is recommended to divide them into separate "
"vdevs and the pool data will be striped across them."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2317
msgid ""
"  A configuration of two RAID-Z2 vdevs consisting of 8 disks each would "
"create something similar to a RAID-60 array. A RAID-Z group's storage "
"capacity is approximately the size of the smallest disk multiplied by the "
"number of non-parity disks. Four 1 TB disks in RAID-Z1 has an effective size "
"of approximately 3 TB, and an array of eight 1 TB disks in RAID-Z3 will "
"yield 5 TB of usable space."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2318
msgid ""
"[[zfs-term-vdev-spare]] _Spare_ - ZFS has a special pseudo-vdev type for "
"keeping track of available hot spares. Note that installed hot spares are "
"not deployed automatically; they must manually be configured to replace the "
"failed device using `zfs replace`."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2319
msgid ""
"[[zfs-term-vdev-log]] _Log_ - ZFS Log Devices, also known as ZFS Intent Log "
"(<<zfs-term-zil,ZIL>>) move the intent log from the regular pool devices to "
"a dedicated device, typically an SSD. Having a dedicated log device can "
"significantly improve the performance of applications with a high volume of "
"synchronous writes, especially databases. Log devices can be mirrored, but "
"RAID-Z is not supported. If multiple log devices are used, writes will be "
"load balanced across them."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2324
msgid ""
"[[zfs-term-vdev-cache]] _Cache_ - Adding a cache vdev to a pool will add the "
"storage of the cache to the <<zfs-term-l2arc,L2ARC>>. Cache devices cannot "
"be mirrored. Since a cache device only stores additional copies of existing "
"data, there is no risk of data loss.  |[[zfs-term-txg]] Transaction Group "
"(TXG)  |Transaction Groups are the way changed blocks are grouped together "
"and eventually written to the pool. Transaction groups are the atomic unit "
"that ZFS uses to assert consistency. Each transaction group is assigned a "
"unique 64-bit consecutive identifier. There can be up to three active "
"transaction groups at a time, one in each of these three states:"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2325
msgid ""
"_Open_ - When a new transaction group is created, it is in the open state, "
"and accepts new writes. There is always a transaction group in the open "
"state, however the transaction group may refuse new writes if it has reached "
"a limit. Once the open transaction group has reached a limit, or the <<zfs-"
"advanced-tuning-txg-timeout,`vfs.zfs.txg.timeout`>> has been reached, the "
"transaction group advances to the next state."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2326
msgid ""
"_Quiescing_ - A short state that allows any pending operations to finish "
"while not blocking the creation of a new open transaction group. Once all of "
"the transactions in the group have completed, the transaction group advances "
"to the final state."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2327
#, fuzzy
msgid ""
"_Syncing_ - All of the data in the transaction group is written to stable "
"storage. This process will in turn modify other data, such as metadata and "
"space maps, that will also need to be written to stable storage. The process "
"of syncing involves multiple passes. The first, all of the changed data "
"blocks, is the biggest, followed by the metadata, which may take multiple "
"passes to complete. Since allocating space for the data blocks generates new "
"metadata, the syncing state cannot finish until a pass completes that does "
"not allocate any additional space. The syncing state is also where "
"_synctasks_ are completed. Synctasks are administrative operations, such as "
"creating or destroying snapshots and datasets, that modify the uberblock are "
"completed. Once the sync state is complete, the transaction group in the "
"quiescing state is advanced to the syncing state."
msgstr ""
"<emphasis>同步中 (Syncing)</emphasis> - 所有在交易群組中的資料會被寫任到穩定"
"的儲存空間，這個程序會依序修改其他也需同樣寫入到穩定儲存空間的資料，如 "
"Metadata 與空間對應表。同步的程多會牽涉多個循環，首先是同步所有更改的資料區"
"塊，也是最大的部份，接著是 Metadata，這可能會需要多個循環來完成。由於要配置空"
"間供資料區塊使用會產生新的 Metadata，同步中狀態在到達循環完成而不再需要分配任"
"何額外空間的狀態前無法結束。同步中狀態也是完成 <emphasis>synctask</emphasis> "
"的地方，Synctask 是指管理操作，如：建立或摧毀快照與資料集，會修改 uberblock，"
"也會在此時完成。同步狀態完成後，其他處於狀態中狀態的交易群組便會進入同步中狀"
"態。"

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2359
msgid ""
"All administrative functions, such as <<zfs-term-snapshot,`snapshot`>> are "
"written as part of the transaction group. When a synctask is created, it is "
"added to the currently open transaction group, and that group is advanced as "
"quickly as possible to the syncing state to reduce the latency of "
"administrative commands.  |[[zfs-term-arc]]Adaptive Replacement Cache (ARC)  "
"|ZFS uses an Adaptive Replacement Cache (ARC), rather than a more "
"traditional Least Recently Used (LRU) cache. An LRU cache is a simple list "
"of items in the cache, sorted by when each object was most recently used. "
"New items are added to the top of the list. When the cache is full, items "
"from the bottom of the list are evicted to make room for more active "
"objects. An ARC consists of four lists; the Most Recently Used (MRU) and "
"Most Frequently Used (MFU) objects, plus a ghost list for each. These ghost "
"lists track recently evicted objects to prevent them from being added back "
"to the cache. This increases the cache hit ratio by avoiding objects that "
"have a history of only being used occasionally. Another advantage of using "
"both an MRU and MFU is that scanning an entire file system would normally "
"evict all data from an MRU or LRU cache in favor of this freshly accessed "
"content. With ZFS, there is also an MFU that only tracks the most frequently "
"used objects, and the cache of the most commonly accessed blocks remains.  |"
"[[zfs-term-l2arc]]L2ARC |L2ARC is the second level of the ZFS caching "
"system. The primary ARC is stored in RAM. Since the amount of available RAM "
"is often limited, ZFS can also use <<zfs-term-vdev-cache,cache vdevs>>. "
"Solid State Disks (SSDs) are often used as these cache devices due to their "
"higher speed and lower latency compared to traditional spinning disks. L2ARC "
"is entirely optional, but having one will significantly increase read speeds "
"for files that are cached on the SSD instead of having to be read from the "
"regular disks. L2ARC can also speed up <<zfs-term-deduplication,"
"deduplication>> because a DDT that does not fit in RAM but does fit in the "
"L2ARC will be much faster than a DDT that must be read from disk. The rate "
"at which data is added to the cache devices is limited to prevent "
"prematurely wearing out SSDs with too many writes. Until the cache is full "
"(the first block has been evicted to make room), writing to the L2ARC is "
"limited to the sum of the write limit and the boost limit, and afterwards "
"limited to the write limit. A pair of man:sysctl[8] values control these "
"rate limits. <<zfs-advanced-tuning-l2arc_write_max,`vfs.zfs."
"l2arc_write_max`>> controls how many bytes are written to the cache per "
"second, while <<zfs-advanced-tuning-l2arc_write_boost,`vfs.zfs."
"l2arc_write_boost`>> adds to this limit during the \"Turbo Warmup Phase"
"\" (Write Boost).  |[[zfs-term-zil]]ZIL |ZIL accelerates synchronous "
"transactions by using storage devices like SSDs that are faster than those "
"used in the main storage pool. When an application requests a synchronous "
"write (a guarantee that the data has been safely stored to disk rather than "
"merely cached to be written later), the data is written to the faster ZIL "
"storage, then later flushed out to the regular disks. This greatly reduces "
"latency and improves performance. Only synchronous workloads like databases "
"will benefit from a ZIL. Regular asynchronous writes such as copying files "
"will not use the ZIL at all.  |[[zfs-term-cow]]Copy-On-Write |Unlike a "
"traditional file system, when data is overwritten on ZFS, the new data is "
"written to a different block rather than overwriting the old data in place. "
"Only when this write is complete is the metadata then updated to point to "
"the new location. In the event of a shorn write (a system crash or power "
"loss in the middle of writing a file), the entire original contents of the "
"file are still available and the incomplete write is discarded. This also "
"means that ZFS does not require a man:fsck[8] after an unexpected shutdown.  "
"|[[zfs-term-dataset]]Dataset |_Dataset_ is the generic term for a ZFS file "
"system, volume, snapshot or clone. Each dataset has a unique name in the "
"format _poolname/path@snapshot_. The root of the pool is technically a "
"dataset as well. Child datasets are named hierarchically like directories. "
"For example, _mypool/home_, the home dataset, is a child of _mypool_ and "
"inherits properties from it. This can be expanded further by creating "
"_mypool/home/user_. This grandchild dataset will inherit properties from the "
"parent and grandparent. Properties on a child can be set to override the "
"defaults inherited from the parents and grandparents. Administration of "
"datasets and their children can be <<zfs-zfs-allow,delegated>>.  |[[zfs-term-"
"filesystem]]File system |A ZFS dataset is most often used as a file system. "
"Like most other file systems, a ZFS file system is mounted somewhere in the "
"systems directory hierarchy and contains files and directories of its own "
"with permissions, flags, and other metadata.  |[[zfs-term-volume]]Volume |In "
"addition to regular file system datasets, ZFS can also create volumes, which "
"are block devices. Volumes have many of the same features, including copy-on-"
"write, snapshots, clones, and checksumming. Volumes can be useful for "
"running other file system formats on top of ZFS, such as UFS virtualization, "
"or exporting iSCSI extents.  |[[zfs-term-snapshot]]Snapshot |The <<zfs-term-"
"cow,copy-on-write>> (COW) design of ZFS allows for nearly instantaneous, "
"consistent snapshots with arbitrary names. After taking a snapshot of a "
"dataset, or a recursive snapshot of a parent dataset that will include all "
"child datasets, new data is written to new blocks, but the old blocks are "
"not reclaimed as free space. The snapshot contains the original version of "
"the file system, and the live file system contains any changes made since "
"the snapshot was taken. No additional space is used. As new data is written "
"to the live file system, new blocks are allocated to store this data. The "
"apparent size of the snapshot will grow as the blocks are no longer used in "
"the live file system, but only in the snapshot. These snapshots can be "
"mounted read only to allow for the recovery of previous versions of files. "
"It is also possible to <<zfs-zfs-snapshot,rollback>> a live file system to a "
"specific snapshot, undoing any changes that took place after the snapshot "
"was taken. Each block in the pool has a reference counter which keeps track "
"of how many snapshots, clones, datasets, or volumes make use of that block. "
"As files and snapshots are deleted, the reference count is decremented. When "
"a block is no longer referenced, it is reclaimed as free space. Snapshots "
"can also be marked with a <<zfs-zfs-snapshot,hold>>. When a snapshot is "
"held, any attempt to destroy it will return an `EBUSY` error. Each snapshot "
"can have multiple holds, each with a unique name. The <<zfs-zfs-snapshot,"
"release>> command removes the hold so the snapshot can deleted. Snapshots "
"can be taken on volumes, but they can only be cloned or rolled back, not "
"mounted independently.  |[[zfs-term-clone]]Clone |Snapshots can also be "
"cloned. A clone is a writable version of a snapshot, allowing the file "
"system to be forked as a new dataset. As with a snapshot, a clone initially "
"consumes no additional space. As new data is written to a clone and new "
"blocks are allocated, the apparent size of the clone grows. When blocks are "
"overwritten in the cloned file system or volume, the reference count on the "
"previous block is decremented. The snapshot upon which a clone is based "
"cannot be deleted because the clone depends on it. The snapshot is the "
"parent, and the clone is the child. Clones can be _promoted_, reversing this "
"dependency and making the clone the parent and the previous parent the "
"child. This operation requires no additional space. Since the amount of "
"space used by the parent and child is reversed, existing quotas and "
"reservations might be affected.  |[[zfs-term-checksum]]Checksum |Every block "
"that is allocated is also checksummed. The checksum algorithm used is a per-"
"dataset property, see <<zfs-zfs-set,`set`>>. The checksum of each block is "
"transparently validated as it is read, allowing ZFS to detect silent "
"corruption. If the data that is read does not match the expected checksum, "
"ZFS will attempt to recover the data from any available redundancy, like "
"mirrors or RAID-Z. Validation of all checksums can be triggered with <<zfs-"
"term-scrub,`scrub`>>. Checksum algorithms include:"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2360
msgid "`fletcher2`"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2361
msgid "`fletcher4`"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2362
msgid "`sha256`"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2367
msgid ""
"The `fletcher` algorithms are faster, but `sha256` is a strong cryptographic "
"hash and has a much lower chance of collisions at the cost of some "
"performance. Checksums can be disabled, but it is not recommended.  |[[zfs-"
"term-compression]]Compression |Each dataset has a compression property, "
"which defaults to off. This property can be set to one of a number of "
"compression algorithms. This will cause all new data that is written to the "
"dataset to be compressed. Beyond a reduction in space used, read and write "
"throughput often increases because fewer blocks are read or written."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2369
msgid ""
"_LZ4_ - Added in ZFS pool version 5000 (feature flags), LZ4 is now the "
"recommended compression algorithm. LZ4 compresses approximately 50% faster "
"than LZJB when operating on compressible data, and is over three times "
"faster when operating on uncompressible data. LZ4 also decompresses "
"approximately 80% faster than LZJB. On modern CPUs, LZ4 can often compress "
"at over 500 MB/s, and decompress at over 1.5 GB/s (per single CPU core)."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2371
msgid ""
"_LZJB_ - The default compression algorithm. Created by Jeff Bonwick (one of "
"the original creators of ZFS). LZJB offers good compression with less CPU "
"overhead compared to GZIP. In the future, the default compression algorithm "
"will likely change to LZ4."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2373
msgid ""
"_GZIP_ - A popular stream compression algorithm available in ZFS. One of the "
"main advantages of using GZIP is its configurable level of compression. When "
"setting the `compress` property, the administrator can choose the level of "
"compression, ranging from `gzip1`, the lowest level of compression, to "
"`gzip9`, the highest level of compression. This gives the administrator "
"control over how much CPU time to trade for saved disk space."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2392
msgid ""
"_ZLE_ - Zero Length Encoding is a special compression algorithm that only "
"compresses continuous runs of zeros. This compression algorithm is only "
"useful when the dataset contains large blocks of zeros.  |[[zfs-term-"
"copies]]Copies |When set to a value greater than 1, the `copies` property "
"instructs ZFS to maintain multiple copies of each block in the <<zfs-term-"
"filesystem,File System>> or <<zfs-term-volume,Volume>>. Setting this "
"property on important datasets provides additional redundancy from which to "
"recover a block that does not match its checksum. In pools without "
"redundancy, the copies feature is the only form of redundancy. The copies "
"feature can recover from a single bad sector or other forms of minor "
"corruption, but it does not protect the pool from the loss of an entire "
"disk.  |[[zfs-term-deduplication]]Deduplication |Checksums make it possible "
"to detect duplicate blocks of data as they are written. With deduplication, "
"the reference count of an existing, identical block is increased, saving "
"storage space. To detect duplicate blocks, a deduplication table (DDT) is "
"kept in memory. The table contains a list of unique checksums, the location "
"of those blocks, and a reference count. When new data is written, the "
"checksum is calculated and compared to the list. If a match is found, the "
"existing block is used. The SHA256 checksum algorithm is used with "
"deduplication to provide a secure cryptographic hash. Deduplication is "
"tunable. If `dedup` is `on`, then a matching checksum is assumed to mean "
"that the data is identical. If `dedup` is set to `verify`, then the data in "
"the two blocks will be checked byte-for-byte to ensure it is actually "
"identical. If the data is not identical, the hash collision will be noted "
"and the two blocks will be stored separately. As DDT must store the hash of "
"each unique block, it consumes a very large amount of memory. A general rule "
"of thumb is 5-6 GB of ram per 1 TB of deduplicated data). In situations "
"where it is not practical to have enough RAM to keep the entire DDT in "
"memory, performance will suffer greatly as the DDT must be read from disk "
"before each new block is written. Deduplication can use L2ARC to store the "
"DDT, providing a middle ground between fast system memory and slower disks. "
"Consider using compression instead, which often provides nearly as much "
"space savings without the additional memory requirement.  |[[zfs-term-"
"scrub]]Scrub |Instead of a consistency check like man:fsck[8], ZFS has "
"`scrub`. `scrub` reads all data blocks stored on the pool and verifies their "
"checksums against the known good checksums stored in the metadata. A "
"periodic check of all the data stored on the pool ensures the recovery of "
"any corrupted blocks before they are needed. A scrub is not required after "
"an unclean shutdown, but is recommended at least once every three months. "
"The checksum of each block is verified as blocks are read during normal use, "
"but a scrub makes certain that even infrequently used blocks are checked for "
"silent corruption. Data security is improved, especially in archival storage "
"situations. The relative priority of `scrub` can be adjusted with <<zfs-"
"advanced-tuning-scrub_delay,`vfs.zfs.scrub_delay`>> to prevent the scrub "
"from degrading the performance of other workloads on the pool.  |[[zfs-term-"
"quota]]Dataset Quota a|ZFS provides very fast and accurate dataset, user, "
"and group space accounting in addition to quotas and space reservations. "
"This gives the administrator fine grained control over how space is "
"allocated and allows space to be reserved for critical file systems.  ZFS "
"supports different types of quotas: the dataset quota, the <<zfs-term-"
"refquota,reference quota (refquota)>>, the <<zfs-term-userquota,user "
"quota>>, and the <<zfs-term-groupquota,group quota>>.  Quotas limit the "
"amount of space that a dataset and all of its descendants, including "
"snapshots of the dataset, child datasets, and the snapshots of those "
"datasets, can consume."
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2395
#, no-wrap
msgid ""
"Quotas cannot be set on volumes, as the `volsize` property acts as an implicit quota.\n"
"====\n"
msgstr ""

#. type: Table
#: documentation/content/en/books/handbook/zfs/_index.adoc:2428
msgid ""
"|[[zfs-term-refquota]]Reference Quota |A reference quota limits the amount "
"of space a dataset can consume by enforcing a hard limit. However, this hard "
"limit includes only space that the dataset references and does not include "
"space used by descendants, such as file systems or snapshots.  |[[zfs-term-"
"userquota]]User Quota |User quotas are useful to limit the amount of space "
"that can be used by the specified user.  |[[zfs-term-groupquota]]Group Quota "
"|The group quota limits the amount of space that a specified group can "
"consume.  |[[zfs-term-reservation]]Dataset Reservation |The `reservation` "
"property makes it possible to guarantee a minimum amount of space for a "
"specific dataset and its descendants. If a 10 GB reservation is set on [."
"filename]#storage/home/bob#, and another dataset tries to use all of the "
"free space, at least 10 GB of space is reserved for this dataset. If a "
"snapshot is taken of [.filename]#storage/home/bob#, the space used by that "
"snapshot is counted against the reservation. The <<zfs-term-refreservation,"
"`refreservation`>> property works in a similar way, but it _excludes_ "
"descendants like snapshots.  Reservations of any sort are useful in many "
"situations, such as planning and testing the suitability of disk space "
"allocation in a new system, or ensuring that enough space is available on "
"file systems for audio logs or system recovery procedures and files.  |[[zfs-"
"term-refreservation]]Reference Reservation |The `refreservation` property "
"makes it possible to guarantee a minimum amount of space for the use of a "
"specific dataset _excluding_ its descendants. This means that if a 10 GB "
"reservation is set on [.filename]#storage/home/bob#, and another dataset "
"tries to use all of the free space, at least 10 GB of space is reserved for "
"this dataset. In contrast to a regular <<zfs-term-reservation,reservation>>, "
"space used by snapshots and descendant datasets is not counted against the "
"reservation. For example, if a snapshot is taken of [.filename]#storage/home/"
"bob#, enough disk space must exist outside of the `refreservation` amount "
"for the operation to succeed. Descendants of the main data set are not "
"counted in the `refreservation` amount and so do not encroach on the space "
"set.  |[[zfs-term-resilver]]Resilver |When a disk fails and is replaced, the "
"new disk must be filled with the data that was lost. The process of using "
"the parity information distributed across the remaining drives to calculate "
"and write the missing data to the new drive is called _resilvering_.  |[[zfs-"
"term-online]]Online |A pool or vdev in the `Online` state has all of its "
"member devices connected and fully operational. Individual devices in the "
"`Online` state are functioning normally.  |[[zfs-term-offline]]Offline |"
"Individual devices can be put in an `Offline` state by the administrator if "
"there is sufficient redundancy to avoid putting the pool or vdev into a "
"<<zfs-term-faulted,Faulted>> state. An administrator may choose to offline a "
"disk in preparation for replacing it, or to make it easier to identify.  |"
"[[zfs-term-degraded]]Degraded |A pool or vdev in the `Degraded` state has "
"one or more disks that have been disconnected or have failed. The pool is "
"still usable, but if additional devices fail, the pool could become "
"unrecoverable. Reconnecting the missing devices or replacing the failed "
"disks will return the pool to an <<zfs-term-online,Online>> state after the "
"reconnected or new device has completed the <<zfs-term-resilver,Resilver>> "
"process.  |[[zfs-term-faulted]]Faulted |A pool or vdev in the `Faulted` "
"state is no longer operational. The data on it can no longer be accessed. A "
"pool or vdev enters the `Faulted` state when the number of missing or failed "
"devices exceeds the level of redundancy in the vdev. If missing devices can "
"be reconnected, the pool will return to an <<zfs-term-online,Online>> state. "
"If there is insufficient redundancy to compensate for the number of failed "
"disks, then the contents of the pool are lost and must be restored from "
"backups."
msgstr ""
